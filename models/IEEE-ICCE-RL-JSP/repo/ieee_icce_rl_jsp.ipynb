{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafd9eb4-414a-444a-b18c-5cbf736939bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555db40c-710d-4a02-a1df-0c7bfa53bd35",
   "metadata": {},
   "source": [
    "# IEEE-ICCE-RL-JSP\n",
    "\n",
    "In this paper, authors use Graph Neural Network to determine which heuristics to choose. Heuristics considered in the following experiment are FIFO, MOR, SPT, and MWKR.\n",
    "\n",
    "## Model\n",
    "\n",
    "I had to train my own models using the script ['train_dqn.py'](train_dqn.py) provided by the owner of the repository. Models were trained on random instances with size up to 10x10. To check if my trained models are valid, I compared the experimental result presented in the paper with my results on the same instances. The results from the paper are\n",
    "\n",
    "|        | IEEE-ICCE-RL-JSP  | ScheduleNet | L2D   | MOR   | FIFO  | SPT   | MWKR  |\n",
    "| ------ | ----- |:----------- |:----- |:----- |:----- |:----- |:----- |\n",
    "| Gap(S) | 20.0% | 17.7%       | 30.7% | 22.7% | 29.0% | 31.2% | 22.7% |\n",
    "| Gap(L) | 10.5% | 11.3%       | 20.8% | 14.8% | 19.4% | 21.3% | 14.5% |\n",
    "| Time   | 1.55s | N/A         | 5.10s | 1.18s | 1.12s | 1.01s | 1.13s |\n",
    "\n",
    "Results of my 3 trained models are (on average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c1a742-e1ea-4692-a184-c9e7900fee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time is 11.87\n",
      "Average gap of small instances is 20.89%\n",
      "Average gap of large instances is 11.44%\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('eval_dqn.csv')\n",
    "large = df[(df['J'] >= 50) & (df['M'] >= 15)]\n",
    "small = df[~(df['J'] >= 50) & (df['M'] >= 15)]\n",
    "\n",
    "print(f\"Average time is {-df['Time'].mean().round(2)}\")\n",
    "print(f\"Average gap of small instances is {small['Gap'].mean().round(4) * 100}%\")\n",
    "print(f\"Average gap of large instances is {large['Gap'].mean().round(4) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9007b-69e0-40ec-b10f-5f35a47f68c6",
   "metadata": {},
   "source": [
    "The time is much higher, because I used `cpu` instead of `cuda`. Average gaps approximately match the results of the paper, so I decided my trained model is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12d98ac-898e-42f7-97da-b83ef408f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.env import JSP_Env\n",
    "from agent.DQN.agent import DQN_Agent\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "def eval_dqn(model, instance_path, args, partial_plan=None):\n",
    "    '''Solve the JSSP instance in file instance_path using given model\n",
    "    \n",
    "      Args:\n",
    "        model - path of model to use\n",
    "        instance_path - path of instance to solve\n",
    "        args - args from argparser\n",
    "        partial_plan - steps to execute at start instead of using the agent\n",
    "\n",
    "      Return:\n",
    "        makespan\n",
    "        start_times - start time of operations executed in given order\n",
    "        plan - sequence of actions\n",
    "    '''\n",
    "    # load env\n",
    "    env = JSP_Env(args)\n",
    "    avai_ops = env.load_instance(instance_path)\n",
    "    state = env.get_graph_data(args.device)\n",
    "\n",
    "    # load agent\n",
    "    agent = DQN_Agent(args, out_dim=len(env.rules))\n",
    "    agent.load(model)\n",
    "\n",
    "    # run the model\n",
    "    plan = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        # choose action from partial plan if given\n",
    "        if partial_plan is not None and i < len(partial_plan):\n",
    "            action = partial_plan[i] \n",
    "        else:\n",
    "            action = agent.select_action(state, random=False, test_only=True)\n",
    "            \n",
    "        state, reward, done, info = env.step(action)\n",
    "        plan.append(action)\n",
    "        i += 1\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    makespan = env.get_makespan()\n",
    "    start_times = [op['start_time'] for op in env.jsp_instance.logger.history]\n",
    "    return makespan, start_times, plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d6c2e-c4f4-4159-b38f-8e9be27e3bc3",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "This model processes instances given in [Standard specifiation](http://jobshop.jjvh.nl/explanation.php#standard_def). I have our benchmarks also in Standard Specification, but for the sake of being consistent, I will consider only instances in [Taillard specification](http://jobshop.jjvh.nl/explanation.php#taillard_def). Therefore I have to write a function, which converts problem in taillard specification to standard specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8297af8c-1e62-44eb-a18b-153c945f9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = np.empty((J, M), dtype=int)\n",
    "        orders_of_machines = np.empty((J, M), dtype=int)\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times[i] = list(map(int, f.readline().split()))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines[i] = list(map(int, f.readline().split()))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def taillard_to_standard(taillard_instance):\n",
    "    # parse taillard instance\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(taillard_instance)\n",
    "\n",
    "    # save as standard instance\n",
    "    standard_instance = \"/tmp/standard_\" + taillard_instance.split(\"/\")[-1]\n",
    "    with open(standard_instance, 'w') as f:\n",
    "        # save number of jobs and machines\n",
    "        f.write(f\"{J}\\t{M}\\n\")\n",
    "\n",
    "        for job in range(J):\n",
    "            for machine in range(M):\n",
    "                f.write(f'{orders_of_machines[job][machine] - 1}\\t{processor_times[job][machine]} ')\n",
    "\n",
    "            f.write('\\n')\n",
    "\n",
    "    return standard_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bed55b-572f-4b1e-b3bc-871cdab564fd",
   "metadata": {},
   "source": [
    "## Static experiment on our benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e322e613-37ec-41c8-b2ce-634857c71de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DQN_ep1670, instance: ta41.txt, makespan: 2591\n",
      "Model: DQN_ep1670, instance: ta42.txt, makespan: 2411\n",
      "Model: DQN_ep1670, instance: ta43.txt, makespan: 2246\n",
      "Model: DQN_ep1670, instance: ta44.txt, makespan: 2386\n",
      "Model: DQN_ep1670, instance: ta45.txt, makespan: 2450\n",
      "Model: DQN_ep1670, instance: ta46.txt, makespan: 2499\n",
      "Model: DQN_ep1670, instance: ta47.txt, makespan: 2246\n",
      "Model: DQN_ep1670, instance: ta48.txt, makespan: 2447\n",
      "Model: DQN_ep1670, instance: ta49.txt, makespan: 2402\n",
      "Model: DQN_ep1670, instance: ta50.txt, makespan: 2370\n"
     ]
    }
   ],
   "source": [
    "# import some stuff and define helper functions\n",
    "import os, argparse, time\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/jssp/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "# need command line arguments for the model\n",
    "parser = argparse.ArgumentParser(description=__doc__)\n",
    "parser.add_argument('-d', '--device', default='cpu')\n",
    "# arguments for DQN\n",
    "parser.add_argument('--warmup', default=10000, type=int)\n",
    "parser.add_argument('--episode', default=100000, type=int)\n",
    "parser.add_argument('--capacity', default=10000, type=int)\n",
    "parser.add_argument('--batch_size', default=32, type=int)\n",
    "parser.add_argument('--lr', default=.01, type=float)\n",
    "parser.add_argument('--eps', default=0.0, type=float)\n",
    "parser.add_argument('--eps_decay', default=.995, type=float)\n",
    "parser.add_argument('--eps_min', default=.01, type=float)\n",
    "parser.add_argument('--gamma', default=1.0, type=float)\n",
    "parser.add_argument('--freq', default=4, type=int)\n",
    "parser.add_argument('--target_freq', default=1000, type=int)\n",
    "parser.add_argument('--double', action='store_true')\n",
    "parser.add_argument(\n",
    "    '--max_process_time',\n",
    "    type=int,\n",
    "    default=100,\n",
    "    help='Maximum Process Time of an Operation')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# load models and instances\n",
    "MODEL = 'agent/DQN/weight/DQN_ep1400'\n",
    "models = os.listdir(MODELS_PATH)\n",
    "BENCHMARKS_PATH = \"../../../benchmarks/jssp/ta_instances/Taillard_specification/\"\n",
    "# instances = sorted(get_all_instances_in_taillard_specification())\n",
    "instances = [\n",
    "    'ta41.txt',\n",
    "    'ta42.txt',\n",
    "    'ta43.txt',\n",
    "    'ta44.txt',\n",
    "    'ta45.txt',\n",
    "    'ta46.txt',\n",
    "    'ta47.txt',\n",
    "    'ta48.txt',\n",
    "    'ta49.txt',\n",
    "    'ta50.txt',\n",
    "]\n",
    "\n",
    "# run experiments\n",
    "# for model in models[:1]:\n",
    "for instance in instances:\n",
    "    model_path = os.path.join(MODELS_PATH, model)\n",
    "    makespan, _, _ = eval_dqn(model_path, taillard_to_standard(os.path.join(BENCHMARKS_PATH, instance)), args)\n",
    "    print(f\"Model: {model}, instance: {instance.split('/')[-1]}, makespan: {makespan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25aa49-1e1a-4b17-9d57-2c7c6df7f06d",
   "metadata": {},
   "source": [
    "# Dynamic JSSP\n",
    "\n",
    "In dynamic JSSP, only a subset of jobs is known at the beginning. The rest of jobs arrives dynamically online.\n",
    "\n",
    "The following attempt to expand L2D to being dynamic is inspired by paper [Large-scale Dynamic Scheduling for Flexible Job-shop with Random Arrivals of New Jobs by Hierarchical Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114974), where authors schedule newly incoming jobs and reschedule not yet executed operations, already executed operations can not be rescheduled. During each rescheduling, they formulate static FJSP and solve it. They use cache for incoming jobs and an agent choosing either to add jobs from cache to scheduling problem, or keep them in cache. I will skip this agent and always add new jobs to scheduling problem.\n",
    "\n",
    "Similarly to the paper, I will model the arrival of new jobs as poisson process with average arrival time following an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb565853-9642-4a52-adf4-c92da217b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_dynamics_jssp(instance):\n",
    "    '''Turns static JSSP instance to dynamic\n",
    "\n",
    "      Args:\n",
    "        filename of static JSSP instance\n",
    "\n",
    "      Returns:\n",
    "        list of jobs known at the beginning\n",
    "        dictionary of arriving jobs as  as {time_of_arrival: (operations, machines)} \n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "\n",
    "    indices = np.arange(J)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # separate jobs into known jobs and arriving jobs\n",
    "    jobs_known_at_the_beginning = [(processor_times[i], orders_of_machines[i]) for i in indices[J//2:]]\n",
    "    arriving_jobs_indeces = indices[:J//2]\n",
    "\n",
    "    # calculate beta = 1/lambda\n",
    "    average_time_between_arrivals = (processor_times.mean() * len(processor_times[0])) / M\n",
    "    \n",
    "    t = 0\n",
    "    arriving_jobs = {}\n",
    "    for index in arriving_jobs_indeces:\n",
    "        t += int(np.random.exponential(scale=average_time_between_arrivals))\n",
    "        arriving_jobs[t] = (processor_times[index], orders_of_machines[index])\n",
    "\n",
    "    return jobs_known_at_the_beginning, arriving_jobs\n",
    "\n",
    "def save_static_jssp_taillard(jobs):\n",
    "    '''Saves list of jobs as static JSSP instance in taillards specification\n",
    "        \n",
    "      Args:\n",
    "        list of jobs to save\n",
    "\n",
    "      Returns:\n",
    "        filename where JSSP instance was saved to\n",
    "    '''\n",
    "    J, M = len(jobs), len(jobs[0][0])\n",
    "    formatted_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    with open(f\"/tmp/{J}_{M}_{formatted_datetime}.txt\", 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{J} {M}\\n\")\n",
    "        for job in jobs:\n",
    "            times, _ = job\n",
    "            f.write(\" \".join(map(str, times)) + '\\n')\n",
    "        for job in jobs:\n",
    "            _, orders = job\n",
    "            f.write(\" \".join(map(str, orders)) + '\\n')  \n",
    "\n",
    "    return f\"/tmp/{J}_{M}_{formatted_datetime}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae96371-2e25-44dd-982e-6740e09483e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance=ta41.txt, known_jobs=15, arriving_jobs=14\n",
      "Latest job arrives at 698 and has total makespan 99\n",
      "12\n",
      "51\n",
      "163\n",
      "228\n",
      "281\n",
      "349\n",
      "422\n",
      "423\n",
      "491\n",
      "567\n",
      "575\n",
      "655\n",
      "693\n",
      "698\n",
      "Makespan: 2467\n",
      "Makespan of instance 'ta41.txt': 2467\n",
      "instance=ta42.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 784 and has total makespan 99\n",
      "66\n",
      "137\n",
      "303\n",
      "335\n",
      "342\n",
      "377\n",
      "429\n",
      "431\n",
      "435\n",
      "442\n",
      "483\n",
      "597\n",
      "692\n",
      "719\n",
      "784\n",
      "Makespan: 2347\n",
      "Makespan of instance 'ta42.txt': 2347\n",
      "instance=ta43.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 763 and has total makespan 99\n",
      "19\n",
      "24\n",
      "37\n",
      "91\n",
      "188\n",
      "210\n",
      "246\n",
      "282\n",
      "377\n",
      "481\n",
      "588\n",
      "661\n",
      "700\n",
      "737\n",
      "763\n",
      "Makespan: 2325\n",
      "Makespan of instance 'ta43.txt': 2325\n",
      "instance=ta44.txt, known_jobs=15, arriving_jobs=14\n",
      "Latest job arrives at 800 and has total makespan 95\n",
      "20\n",
      "49\n",
      "147\n",
      "155\n",
      "210\n",
      "237\n",
      "340\n",
      "396\n",
      "577\n",
      "581\n",
      "617\n",
      "676\n",
      "724\n",
      "800\n",
      "Makespan: 2413\n",
      "Makespan of instance 'ta44.txt': 2413\n",
      "instance=ta45.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 1057 and has total makespan 91\n",
      "7\n",
      "37\n",
      "40\n",
      "108\n",
      "339\n",
      "389\n",
      "411\n",
      "489\n",
      "538\n",
      "605\n",
      "619\n",
      "633\n",
      "880\n",
      "934\n",
      "1057\n",
      "Makespan: 2339\n",
      "Makespan of instance 'ta45.txt': 2339\n",
      "instance=ta46.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 1488 and has total makespan 98\n",
      "114\n",
      "211\n",
      "398\n",
      "582\n",
      "606\n",
      "736\n",
      "909\n",
      "1036\n",
      "1049\n",
      "1144\n",
      "1227\n",
      "1301\n",
      "1315\n",
      "1463\n",
      "1488\n",
      "Makespan: 2467\n",
      "Makespan of instance 'ta46.txt': 2467\n",
      "instance=ta47.txt, known_jobs=15, arriving_jobs=13\n",
      "Latest job arrives at 691 and has total makespan 98\n",
      "28\n",
      "39\n",
      "44\n",
      "125\n",
      "211\n",
      "235\n",
      "290\n",
      "300\n",
      "365\n",
      "444\n",
      "456\n",
      "584\n",
      "691\n",
      "Makespan: 2187\n",
      "Makespan of instance 'ta47.txt': 2187\n",
      "instance=ta48.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 584 and has total makespan 90\n",
      "33\n",
      "173\n",
      "279\n",
      "337\n",
      "399\n",
      "407\n",
      "425\n",
      "479\n",
      "480\n",
      "491\n",
      "493\n",
      "514\n",
      "525\n",
      "552\n",
      "584\n",
      "Makespan: 2512\n",
      "Makespan of instance 'ta48.txt': 2512\n",
      "instance=ta49.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 602 and has total makespan 84\n",
      "30\n",
      "64\n",
      "79\n",
      "133\n",
      "167\n",
      "220\n",
      "324\n",
      "334\n",
      "475\n",
      "486\n",
      "495\n",
      "500\n",
      "561\n",
      "586\n",
      "602\n",
      "Makespan: 2415\n",
      "Makespan of instance 'ta49.txt': 2415\n",
      "instance=ta50.txt, known_jobs=15, arriving_jobs=15\n",
      "Latest job arrives at 716 and has total makespan 95\n",
      "13\n",
      "67\n",
      "211\n",
      "246\n",
      "284\n",
      "320\n",
      "325\n",
      "328\n",
      "394\n",
      "481\n",
      "500\n",
      "509\n",
      "668\n",
      "691\n",
      "716\n",
      "Makespan: 2373\n",
      "Makespan of instance 'ta50.txt': 2373\n"
     ]
    }
   ],
   "source": [
    "def solve_dynamic_jssp(instance, model):\n",
    "    '''Turns static JSSP in Taillard specification instance to dynamic and solves it\n",
    "\n",
    "      Args: \n",
    "        instance to solve\n",
    "        model to use\n",
    "\n",
    "      Returns: \n",
    "        makespan\n",
    "    '''\n",
    "    # turn static JSSP instance to dynamic\n",
    "    known_jobs, arriving_jobs = get_dynamics_jssp(instance)\n",
    "    print(f\"instance={instance.split('/')[-1]}, known_jobs={len(known_jobs)}, arriving_jobs={len(arriving_jobs)}\")\n",
    "    latest_time_of_arrival = max(arriving_jobs)\n",
    "    print(f\"Latest job arrives at {latest_time_of_arrival} and has total makespan {arriving_jobs[latest_time_of_arrival][0].max()}\")\n",
    "    \n",
    "    # solve static JSSP with jobs known initially\n",
    "    makespan, start_times, plan = eval_dqn(model, taillard_to_standard(save_static_jssp_taillard(known_jobs)), args)\n",
    "    t = 0\n",
    "    while True:\n",
    "        t += 1\n",
    "        \n",
    "        # no jobs left\n",
    "        if not arriving_jobs:\n",
    "            break\n",
    "    \n",
    "        # no job arrived\n",
    "        if not t in arriving_jobs:\n",
    "            continue\n",
    "        print(t)\n",
    "\n",
    "        # new job arrived, remove not yet executed operations from the plan\n",
    "        partial_plan = []\n",
    "        for i, action in enumerate(plan):\n",
    "            if start_times[i] < t:\n",
    "                partial_plan.append(action)\n",
    " \n",
    "        # add new job to the plan, with times shifted to current time t\n",
    "        new_job = arriving_jobs.pop(t)\n",
    "        known_jobs.append(new_job)\n",
    "        \n",
    "        # create new schedule WHILE REUSING THE ALREADY EXECUTED PLAN\n",
    "        makespan, start_times, plan = eval_dqn(model, taillard_to_standard(save_static_jssp_taillard(known_jobs)), args, partial_plan=partial_plan) \n",
    "\n",
    "    print(f\"Makespan: {makespan}\")\n",
    "    return makespan\n",
    "\n",
    "MODEL = 'agent/DQN/weight/DQN_ep1400'\n",
    "BENCHMARKS_PATH = \"../../../benchmarks/jssp/ta_instances/Taillard_specification/\"\n",
    "INSTANCES = [\n",
    "    'ta41.txt',\n",
    "    'ta42.txt',\n",
    "    'ta43.txt',\n",
    "    'ta44.txt',\n",
    "    'ta45.txt',\n",
    "    'ta46.txt',\n",
    "    'ta47.txt',\n",
    "    'ta48.txt',\n",
    "    'ta49.txt',\n",
    "    'ta50.txt',\n",
    "]\n",
    "\n",
    "for instance in INSTANCES:\n",
    "    makespan = solve_dynamic_jssp(BENCHMARKS_PATH + instance, MODEL)\n",
    "    print(f\"Makespan of instance '{instance}': {makespan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486dcc1e-e00e-40f4-8ce1-cdb23722dc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
