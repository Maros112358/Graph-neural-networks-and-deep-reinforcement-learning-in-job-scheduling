{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231591d0-ec1a-4437-a3a8-0411a7033dc5",
   "metadata": {},
   "source": [
    "# Wheatley\n",
    "\n",
    "> Next-generation scheduling problem solver based on GNNs and Reinforcement Learning\n",
    "\n",
    "The authors of Wheatley created a [script for training](jssp/train.py) and a [script for solving](jssp/solve.py) the problem. Documentation is in [USAGE.md](docs/USAGE.md) For this quick showcase, I trained a model on random 15x15 instances (15 jobs, 15 machines). To solve benchmark instances, I just need to import the function implemented by Wheatley's authors. The model takes quite some time to train, and therefore the model in this showcase is trained very badly due to time constraints. Makespans will be therefore incredibly bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3dd1935-8b43-479a-8516-3ef980a49f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from generic.utils import decode_mask\n",
    "from jssp.description import Description\n",
    "from jssp.env.env import Env\n",
    "from jssp.models.agent import Agent\n",
    "from jssp.solution import Solution\n",
    "\n",
    "# import Wheatley jssp solver\n",
    "from jssp.solve import solve_instance\n",
    "from jssp.utils.loaders import load_problem\n",
    "from jssp.models.agent import Agent\n",
    "\n",
    "# load trained agent\n",
    "agent = Agent.load(\"saved_networks/agent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cd5f1-7997-4957-a19b-3d0eff2f9413",
   "metadata": {},
   "source": [
    "# Benchmarks Wheatley can solve right now\n",
    "\n",
    "Wheatley can solve only instances, which are the same size or smaller than those he has been trained on. Therefore I can \n",
    "I will now run Wheatley on all available JSSP benchmarks I currently have, which are 15x15 or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374346f-43eb-4c68-9a00-ef1db8b08cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/jssp/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f956101c-f44a-4b04-994d-def1faf44970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: abz5.txt, jobs: 10, machines: 10, makespan: 3749.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marosbratko/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/env/observation.py:127: RuntimeWarning: invalid value encountered in cast\n",
      "  \"edge_index\": edge_index.astype(\"int64\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: abz6.txt, jobs: 10, machines: 10, makespan: 2700.0\n",
      "Instance: ft06.txt, jobs: 6, machines: 6, makespan: 80.0\n",
      "Instance: ft10.txt, jobs: 10, machines: 10, makespan: 2768.0\n",
      "Instance: la01.txt, jobs: 10, machines: 5, makespan: 1121.0\n",
      "Instance: la02.txt, jobs: 10, machines: 5, makespan: 1171.0\n",
      "Instance: la03.txt, jobs: 10, machines: 5, makespan: 1096.0\n",
      "Instance: la04.txt, jobs: 10, machines: 5, makespan: 1296.0\n",
      "Instance: la05.txt, jobs: 10, machines: 5, makespan: 839.0\n",
      "Instance: la06.txt, jobs: 15, machines: 5, makespan: 1816.0\n",
      "Instance: la07.txt, jobs: 15, machines: 5, makespan: 1801.0\n",
      "Instance: la08.txt, jobs: 15, machines: 5, makespan: 2108.0\n",
      "Instance: la09.txt, jobs: 15, machines: 5, makespan: 2001.0\n",
      "Instance: la10.txt, jobs: 15, machines: 5, makespan: 2158.0\n",
      "Instance: la16.txt, jobs: 10, machines: 10, makespan: 2673.0\n",
      "Instance: la17.txt, jobs: 10, machines: 10, makespan: 2382.0\n",
      "Instance: la18.txt, jobs: 10, machines: 10, makespan: 2602.0\n",
      "Instance: la19.txt, jobs: 10, machines: 10, makespan: 2476.0\n",
      "Instance: la20.txt, jobs: 10, machines: 10, makespan: 2517.0\n",
      "Instance: la21.txt, jobs: 15, machines: 10, makespan: 3777.0\n",
      "Instance: la22.txt, jobs: 15, machines: 10, makespan: 3843.0\n",
      "Instance: la23.txt, jobs: 15, machines: 10, makespan: 3821.0\n",
      "Instance: la24.txt, jobs: 15, machines: 10, makespan: 3541.0\n",
      "Instance: la25.txt, jobs: 15, machines: 10, makespan: 3398.0\n",
      "Instance: la36.txt, jobs: 15, machines: 15, makespan: 5056.0\n",
      "Instance: la37.txt, jobs: 15, machines: 15, makespan: 5808.0\n",
      "Instance: la38.txt, jobs: 15, machines: 15, makespan: 5297.0\n",
      "Instance: la39.txt, jobs: 15, machines: 15, makespan: 5810.0\n",
      "Instance: la40.txt, jobs: 15, machines: 15, makespan: 5096.0\n",
      "Instance: orb01.txt, jobs: 10, machines: 10, makespan: 3140.0\n",
      "Instance: orb02.txt, jobs: 10, machines: 10, makespan: 3756.0\n",
      "Instance: orb03.txt, jobs: 10, machines: 10, makespan: 2217.0\n",
      "Instance: orb04.txt, jobs: 10, machines: 10, makespan: 4023.0\n",
      "Instance: orb05.txt, jobs: 10, machines: 10, makespan: 2688.0\n",
      "Instance: orb06.txt, jobs: 10, machines: 10, makespan: 3487.0\n",
      "Instance: orb07.txt, jobs: 10, machines: 10, makespan: 1567.0\n",
      "Instance: orb08.txt, jobs: 10, machines: 10, makespan: 2158.0\n",
      "Instance: orb09.txt, jobs: 10, machines: 10, makespan: 3695.0\n",
      "Instance: orb10.txt, jobs: 10, machines: 10, makespan: 3219.0\n",
      "Instance: ta01.txt, jobs: 15, machines: 15, makespan: 4761.0\n",
      "Instance: ta02.txt, jobs: 15, machines: 15, makespan: 5766.0\n",
      "Instance: ta03.txt, jobs: 15, machines: 15, makespan: 5951.0\n",
      "Instance: ta04.txt, jobs: 15, machines: 15, makespan: 5877.0\n",
      "Instance: ta05.txt, jobs: 15, machines: 15, makespan: 6061.0\n",
      "Instance: ta06.txt, jobs: 15, machines: 15, makespan: 5050.0\n",
      "Instance: ta07.txt, jobs: 15, machines: 15, makespan: 5986.0\n",
      "Instance: ta08.txt, jobs: 15, machines: 15, makespan: 5555.0\n",
      "Instance: ta09.txt, jobs: 15, machines: 15, makespan: 5251.0\n",
      "Instance: ta10.txt, jobs: 15, machines: 15, makespan: 5036.0\n"
     ]
    }
   ],
   "source": [
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        instance,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    if agent.env_specification.max_n_jobs < n_j:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < n_m:\n",
    "        continue\n",
    "        \n",
    "    solution = solve_instance(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "    print(f\"Instance: {instance.split('/')[-1]}, jobs: {n_j}, machines: {n_m}, makespan: {solution.get_makespan()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05f863-e45e-4321-ad91-9cc6a1d43f7f",
   "metadata": {},
   "source": [
    "# Dynamic JSSP\n",
    "\n",
    "In dynamic JSSP, only a subset of jobs is known at the beginning. The rest of jobs arrives dynamically online.\n",
    "\n",
    "The following attempt to expand L2D to being dynamic is inspired by paper [Large-scale Dynamic Scheduling for Flexible Job-shop with Random Arrivals of New Jobs by Hierarchical Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114974), where authors schedule newly incoming jobs and reschedule not yet executed operations, already executed operations can not be rescheduled. During each rescheduling, they formulate static FJSP and solve it. They use cache for incoming jobs and an agent choosing either to add jobs from cache to scheduling problem, or keep them in cache. I will skip this agent and always add new jobs to scheduling problem.\n",
    "\n",
    "Similarly to the paper, I will model the arrival of new jobs as poisson process with average arrival time following an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf49e3e4-a60e-4ef7-9d42-9730428df2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = np.empty((J, M), dtype=int)\n",
    "        orders_of_machines = np.empty((J, M), dtype=int)\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times[i] = list(map(int, f.readline().split()))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines[i] = list(map(int, f.readline().split()))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def get_dynamics_jssp(instance):\n",
    "    '''Turns static JSSP instance to dynamic\n",
    "\n",
    "      Args:\n",
    "        filename of static JSSP instance\n",
    "\n",
    "      Returns:\n",
    "        list of jobs known at the beginning\n",
    "        dictionary of arriving jobs as  as {time_of_arrival: (operations, machines)} \n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "\n",
    "    indices = np.arange(J)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # separate jobs into known jobs and arriving jobs\n",
    "    jobs_known_at_the_beginning = [(processor_times[i], orders_of_machines[i]) for i in indices[J//2:]]\n",
    "    arriving_jobs_indeces = indices[:J//2]\n",
    "\n",
    "    # calculate beta = 1/lambda\n",
    "    average_time_between_arrivals = (processor_times.mean() * len(processor_times[0])) / M\n",
    "    \n",
    "    t = 1\n",
    "    arriving_jobs = {}\n",
    "    for index in arriving_jobs_indeces:\n",
    "        t += int(np.random.exponential(scale=average_time_between_arrivals))\n",
    "        arriving_jobs[t] = (processor_times[index], orders_of_machines[index])\n",
    "\n",
    "    return jobs_known_at_the_beginning, arriving_jobs\n",
    "\n",
    "def save_static_jssp_taillard(jobs):\n",
    "    '''Saves list of jobs as static JSSP instance in taillards specification\n",
    "        \n",
    "      Args:\n",
    "        list of jobs to save\n",
    "\n",
    "      Returns:\n",
    "        filename where JSSP instance was saved to\n",
    "    '''\n",
    "    J, M = len(jobs), len(jobs[0][0])\n",
    "    formatted_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    with open(f\"/tmp/{J}_{M}_{formatted_datetime}.txt\", 'w') as f:\n",
    "        f.write(f\"{J} {M}\\n\")\n",
    "        for job in jobs:\n",
    "            times, _ = job\n",
    "            f.write(\" \".join(map(str, times)) + '\\n')\n",
    "        for job in jobs:\n",
    "            _, orders = job\n",
    "            f.write(\" \".join(map(str, orders)) + '\\n')  \n",
    "\n",
    "    return f\"/tmp/{J}_{M}_{formatted_datetime}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ceed6db-947f-4f48-bbe1-d303d92452ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic jssp\n",
    "\n",
    "def solve_instance_extended(\n",
    "    agent: Agent,\n",
    "    affectations: np.ndarray,\n",
    "    durations: np.ndarray,\n",
    "    deterministic: bool,\n",
    "    partial_plan: list | None = None\n",
    ") -> Solution:\n",
    "    problem_description = Description(\n",
    "        transition_model_config=\"simple\",\n",
    "        reward_model_config=\"Sparse\",\n",
    "        deterministic=deterministic,\n",
    "        fixed=True,\n",
    "        seed=0,\n",
    "        affectations=affectations,\n",
    "        durations=durations,\n",
    "    )\n",
    "    env_specification = agent.env_specification\n",
    "    env = Env(problem_description, env_specification)\n",
    "\n",
    "    done = False\n",
    "    obs, info = env.reset(soft=True)\n",
    "    actions = []\n",
    "\n",
    "    i = 0\n",
    "    while not done:\n",
    "        if partial_plan is not None and i < len(partial_plan):\n",
    "            action = partial_plan[i]\n",
    "        else:\n",
    "            action_masks = decode_mask(info[\"mask\"])\n",
    "            obs = agent.obs_as_tensor_add_batch_dim(obs)\n",
    "            action = agent.predict(obs, deterministic=True, action_masks=action_masks)\n",
    "\n",
    "        i += 1\n",
    "        actions.append(action)\n",
    "        obs, reward, done, _, info = env.step(action.long().item())\n",
    "        solution = env.get_solution()\n",
    "\n",
    "    return solution, solution.schedule, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c9d0a7-7f49-409f-be2e-d3dd59690115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance=ft06.txt, known_jobs=3, arriving_jobs=3\n",
      "Latest job arrives at 38 and has total makespan 10\n",
      "Makespan of dynamic instance 'ft06.txt': 108.0\n",
      "Makespan of static instance: ft06.txt, jobs: 6, machines: 6, makespan: 80.0\n"
     ]
    }
   ],
   "source": [
    "def solve_dynamic_jssp(instance, agent):\n",
    "    '''Turns static JSSP in Taillard specification instance to dynamic and solves it\n",
    "\n",
    "      Args: \n",
    "        instance to solve\n",
    "\n",
    "      Returns: \n",
    "        makespan\n",
    "    '''\n",
    "    # turn static JSSP instance to dynamic\n",
    "    known_jobs, arriving_jobs = get_dynamics_jssp(instance)\n",
    "    print(f\"instance={instance.split('/')[-1]}, known_jobs={len(known_jobs)}, arriving_jobs={len(arriving_jobs)}\")\n",
    "    latest_time_of_arrival = max(arriving_jobs)\n",
    "    print(f\"Latest job arrives at {latest_time_of_arrival} and has total makespan {arriving_jobs[latest_time_of_arrival][0].max()}\")\n",
    "    \n",
    "    # solve static JSSP with jobs known initially\n",
    "    instance_partial = save_static_jssp_taillard(known_jobs)\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        instance_partial,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "    solution, schedule, actions = solve_instance_extended(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "\n",
    "    # iterate over time\n",
    "    t = 0\n",
    "    while True:\n",
    "        t += 1\n",
    "        \n",
    "        # no jobs left\n",
    "        if not arriving_jobs:\n",
    "            break\n",
    "    \n",
    "        # no job arrived\n",
    "        if not t in arriving_jobs:\n",
    "            continue\n",
    "    \n",
    "        # new job arrived, remove not yet executed operations from the plan\n",
    "        partial_plan = []\n",
    "        J, M = len(known_jobs), len(known_jobs[0][0])\n",
    "        for action in actions:\n",
    "            action = action.long().item()\n",
    "            row = action // M\n",
    "            col = action % M\n",
    "    \n",
    "            if schedule[row][col] < t:\n",
    "                partial_plan.append(action)\n",
    "\n",
    "        # add new job to the plan, with times shifted to current time t\n",
    "        new_job = arriving_jobs.pop(t)\n",
    "        known_jobs.append(new_job)\n",
    "        instance_partial = save_static_jssp_taillard(known_jobs)\n",
    "        n_j, n_m, affectations, durations = load_problem(\n",
    "            instance_partial,\n",
    "            taillard_offset=True,\n",
    "            deterministic=True\n",
    "        )\n",
    "        \n",
    "        # create new schedule WHILE REUSING THE ALREADY EXECUTED PLAN\n",
    "        solution, schedule, actions = solve_instance_extended(\n",
    "            agent, affectations, durations, True, partial_plan=actions\n",
    "        )\n",
    "\n",
    "    makespan = solution.get_makespan()\n",
    "    return makespan\n",
    "\n",
    "\n",
    "# experiment\n",
    "BENCHMARKS_PATH = \"../../../benchmarks/jssp/ft_instances/Taillard_specification/\"\n",
    "INSTANCES = [\n",
    "    'ft06.txt'\n",
    "]\n",
    "\n",
    "for instance in INSTANCES:\n",
    "    makespan = solve_dynamic_jssp(BENCHMARKS_PATH + instance, agent)\n",
    "    print(f\"Makespan of dynamic instance '{instance}': {makespan}\")\n",
    "\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        BENCHMARKS_PATH + instance,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    if agent.env_specification.max_n_jobs < n_j:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < n_m:\n",
    "        continue\n",
    "        \n",
    "    solution = solve_instance(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "    print(f\"Makespan of static instance: {instance.split('/')[-1]}, jobs: {n_j}, machines: {n_m}, makespan: {solution.get_makespan()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753246e2-3882-4461-a939-8a6d3ad8d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
