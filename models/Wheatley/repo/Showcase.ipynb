{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231591d0-ec1a-4437-a3a8-0411a7033dc5",
   "metadata": {},
   "source": [
    "# Wheatley\n",
    "\n",
    "> Next-generation scheduling problem solver based on GNNs and Reinforcement Learning\n",
    "\n",
    "The authors of Wheatley created a [script for training](jssp/train.py) and a [script for solving](jssp/solve.py) the problem. Documentation is in [USAGE.md](docs/USAGE.md) For this quick showcase, I trained a model on random 15x15 instances (15 jobs, 15 machines). To solve benchmark instances, I just need to import the function implemented by Wheatley's authors. The model takes quite some time to train, and therefore the model in this showcase is trained very badly due to time constraints. Makespans will be therefore incredibly bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3dd1935-8b43-479a-8516-3ef980a49f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from generic.utils import decode_mask\n",
    "from jssp.description import Description\n",
    "from jssp.env.env import Env\n",
    "from jssp.models.agent import Agent\n",
    "from jssp.solution import Solution\n",
    "\n",
    "# import Wheatley jssp solver\n",
    "from jssp.solve import solve_instance\n",
    "from jssp.utils.loaders import load_problem\n",
    "from jssp.models.agent import Agent\n",
    "\n",
    "# load trained agent\n",
    "agent = Agent.load(\"saved_networks/agent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cd5f1-7997-4957-a19b-3d0eff2f9413",
   "metadata": {},
   "source": [
    "# Benchmarks Wheatley can solve right now\n",
    "\n",
    "Wheatley can solve only instances, which are the same size or smaller than those he has been trained on. Therefore I can \n",
    "I will now run Wheatley on all available JSSP benchmarks I currently have, which are 15x15 or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374346f-43eb-4c68-9a00-ef1db8b08cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = []\n",
    "        orders_of_machines = []\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times.append(list(map(int, f.readline().split())))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines.append(list(map(int, f.readline().split())))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/jssp/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "def solve_instance_taillard(instance, agent):\n",
    "    '''Solves JSSP instance in Taillard specification\n",
    "    \n",
    "      Args:\n",
    "        instance: instance to solve\n",
    "        agent: agent to use for solving the problem\n",
    "\n",
    "      Returns:\n",
    "        solution\n",
    "    '''\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        instance,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    assert agent.env_specification.max_n_jobs >= n_j\n",
    "    assert agent.env_specification.max_n_machines >= n_m\n",
    "        \n",
    "    solution = solve_instance(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f956101c-f44a-4b04-994d-def1faf44970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: abz5.txt, jobs: 10, machines: 10, makespan: 3749.0\n",
      "Instance: abz6.txt, jobs: 10, machines: 10, makespan: 2700.0\n",
      "Instance: ft06.txt, jobs: 6, machines: 6, makespan: 80.0\n",
      "Instance: ft10.txt, jobs: 10, machines: 10, makespan: 2768.0\n",
      "Instance: la01.txt, jobs: 10, machines: 5, makespan: 1121.0\n",
      "Instance: la02.txt, jobs: 10, machines: 5, makespan: 1171.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marosbratko/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/env/observation.py:127: RuntimeWarning: invalid value encountered in cast\n",
      "  \"edge_index\": edge_index.astype(\"int64\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: la03.txt, jobs: 10, machines: 5, makespan: 1096.0\n",
      "Instance: la04.txt, jobs: 10, machines: 5, makespan: 1296.0\n",
      "Instance: la05.txt, jobs: 10, machines: 5, makespan: 839.0\n",
      "Instance: la06.txt, jobs: 15, machines: 5, makespan: 1816.0\n",
      "Instance: la07.txt, jobs: 15, machines: 5, makespan: 1801.0\n",
      "Instance: la08.txt, jobs: 15, machines: 5, makespan: 2108.0\n",
      "Instance: la09.txt, jobs: 15, machines: 5, makespan: 2001.0\n",
      "Instance: la10.txt, jobs: 15, machines: 5, makespan: 2158.0\n",
      "Instance: la16.txt, jobs: 10, machines: 10, makespan: 2673.0\n",
      "Instance: la17.txt, jobs: 10, machines: 10, makespan: 2382.0\n",
      "Instance: la18.txt, jobs: 10, machines: 10, makespan: 2602.0\n",
      "Instance: la19.txt, jobs: 10, machines: 10, makespan: 2476.0\n",
      "Instance: la20.txt, jobs: 10, machines: 10, makespan: 2517.0\n",
      "Instance: la21.txt, jobs: 15, machines: 10, makespan: 3777.0\n",
      "Instance: la22.txt, jobs: 15, machines: 10, makespan: 3843.0\n",
      "Instance: la23.txt, jobs: 15, machines: 10, makespan: 3821.0\n",
      "Instance: la24.txt, jobs: 15, machines: 10, makespan: 3541.0\n",
      "Instance: la25.txt, jobs: 15, machines: 10, makespan: 3398.0\n",
      "Instance: la36.txt, jobs: 15, machines: 15, makespan: 5056.0\n",
      "Instance: la37.txt, jobs: 15, machines: 15, makespan: 5808.0\n",
      "Instance: la38.txt, jobs: 15, machines: 15, makespan: 5297.0\n",
      "Instance: la39.txt, jobs: 15, machines: 15, makespan: 5810.0\n",
      "Instance: la40.txt, jobs: 15, machines: 15, makespan: 5096.0\n",
      "Instance: orb01.txt, jobs: 10, machines: 10, makespan: 3140.0\n",
      "Instance: orb02.txt, jobs: 10, machines: 10, makespan: 3756.0\n",
      "Instance: orb03.txt, jobs: 10, machines: 10, makespan: 2217.0\n",
      "Instance: orb04.txt, jobs: 10, machines: 10, makespan: 4023.0\n",
      "Instance: orb05.txt, jobs: 10, machines: 10, makespan: 2688.0\n",
      "Instance: orb06.txt, jobs: 10, machines: 10, makespan: 3487.0\n",
      "Instance: orb07.txt, jobs: 10, machines: 10, makespan: 1567.0\n",
      "Instance: orb08.txt, jobs: 10, machines: 10, makespan: 2158.0\n",
      "Instance: orb09.txt, jobs: 10, machines: 10, makespan: 3695.0\n",
      "Instance: orb10.txt, jobs: 10, machines: 10, makespan: 3219.0\n",
      "Instance: ta01.txt, jobs: 15, machines: 15, makespan: 4761.0\n",
      "Instance: ta02.txt, jobs: 15, machines: 15, makespan: 5766.0\n",
      "Instance: ta03.txt, jobs: 15, machines: 15, makespan: 5951.0\n",
      "Instance: ta04.txt, jobs: 15, machines: 15, makespan: 5877.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_machines \u001b[38;5;241m<\u001b[39m M:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance_taillard\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstance\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, jobs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, machines: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, makespan: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolution\u001b[38;5;241m.\u001b[39mget_makespan()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m, in \u001b[0;36msolve_instance_taillard\u001b[0;34m(instance, agent)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_jobs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_j\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_machines \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_m\n\u001b[0;32m---> 67\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffectations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/solve.py:36\u001b[0m, in \u001b[0;36msolve_instance\u001b[0;34m(agent, affectations, durations, deterministic)\u001b[0m\n\u001b[1;32m     34\u001b[0m action_masks \u001b[38;5;241m=\u001b[39m decode_mask(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     35\u001b[0m obs \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mobs_as_tensor_add_batch_dim(obs)\n\u001b[0;32m---> 36\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m obs, reward, done, _, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     38\u001b[0m solution \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_solution()\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/generic/agent.py:145\u001b[0m, in \u001b[0;36mAgent.predict\u001b[0;34m(self, observation, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation, deterministic, action_masks):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 145\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(features)\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m action_masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/wheatley-rhxD3zb4-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/wheatley-rhxD3zb4-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/models/gnn_dgl.py:375\u001b[0m, in \u001b[0;36mGnnDGL.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    371\u001b[0m     g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    372\u001b[0m         g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(g\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgconv_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgatv2\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 375\u001b[0m     features, new_e_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlps[layer](features\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, end_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# update edge features below\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# g.edata[\"emb\"] = self.mlps_edges[layer](new_e_attr.flatten(start_dim=-2, end_dim=-1))\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/wheatley-rhxD3zb4-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/wheatley-rhxD3zb4-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/wheatley-rhxD3zb4-py3.10/lib/python3.10/site-packages/dgl/nn/pytorch/conv/egatconv.py:237\u001b[0m, in \u001b[0;36mEGATConv.forward\u001b[0;34m(self, graph, nfeats, efeats, edge_weight, get_attention)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     f_out \u001b[38;5;241m=\u001b[39m f_out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[0;32m--> 237\u001b[0m f_out \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m f_out \u001b[38;5;241m=\u001b[39m f_out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_edge_feats)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# compute attention factor\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/wheatley-rhxD3zb4-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:1646\u001b[0m, in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mleaky_relu_(\u001b[38;5;28minput\u001b[39m, negative_slope)\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1646\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaky_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_slope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    J, M, _, _ = parse_instance_taillard(instance)\n",
    "    if agent.env_specification.max_n_jobs < J:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < M:\n",
    "        continue\n",
    "        \n",
    "    solution = solve_instance_taillard(instance, agent)\n",
    "    print(f\"Instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {solution.get_makespan()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05f863-e45e-4321-ad91-9cc6a1d43f7f",
   "metadata": {},
   "source": [
    "# Dynamic JSSP\n",
    "\n",
    "In dynamic JSSP, only a subset of jobs is known at the beginning. The rest of jobs arrives dynamically online.\n",
    "\n",
    "The following attempt to expand L2D to being dynamic is inspired by paper [Large-scale Dynamic Scheduling for Flexible Job-shop with Random Arrivals of New Jobs by Hierarchical Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114974), where authors schedule newly incoming jobs and reschedule not yet executed operations, already executed operations can not be rescheduled. During each rescheduling, they formulate static FJSP and solve it. They use cache for incoming jobs and an agent choosing either to add jobs from cache to scheduling problem, or keep them in cache. I will skip this agent and always add new jobs to scheduling problem.\n",
    "\n",
    "Similarly to the paper, I will model the arrival of new jobs as poisson process with average arrival time following an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf49e3e4-a60e-4ef7-9d42-9730428df2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generate_arrival_times_for_jssp(instance):\n",
    "    '''Turns static JSSP instance to dynamic\n",
    "\n",
    "      Args:\n",
    "        filename of static JSSP instance\n",
    "\n",
    "      Returns:\n",
    "        list of jobs known at the beginning\n",
    "        dictionary of arriving jobs as  as {time_of_arrival: (operations, machines)} \n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "    arrival_times = np.zeros(J, dtype=int)\n",
    "\n",
    "    # calculate beta = 1/lambda\n",
    "    flattened_processor_times = [operation_time for job in processor_times for operation_time in job]\n",
    "    average_time_between_arrivals = (np.mean(flattened_processor_times) * len(processor_times[0])) / M\n",
    "    \n",
    "    # separate jobs into known jobs and arriving jobs\n",
    "    indices = np.arange(J)\n",
    "    arriving_jobs_indeces = indices[:J//2]\n",
    "    np.random.shuffle(indices)\n",
    "    t = 1\n",
    "    for index in arriving_jobs_indeces:\n",
    "        t += int(np.random.exponential(scale=average_time_between_arrivals)) + 1\n",
    "        arrival_times[index] = t\n",
    "\n",
    "    return list(arrival_times)\n",
    "\n",
    "def save_jssp_taillard(processor_times, orders_of_machines):\n",
    "    '''Saves list of jobs as static JSSP instance in taillards specification\n",
    "        \n",
    "      Args:\n",
    "        list of jobs to save\n",
    "\n",
    "      Returns:\n",
    "        filename where JSSP instance was saved to\n",
    "    '''\n",
    "    assert len(processor_times) == len(orders_of_machines), \"Processor times and machines do not have the same length\"\n",
    "    for times, machines in zip(processor_times, orders_of_machines):\n",
    "        assert len(times) == len(machines), \"Times and machines for a specific job do not have the same length\"\n",
    "        \n",
    "    J = len(processor_times)\n",
    "    M = max(max(machines) for machines in orders_of_machines)\n",
    "    \n",
    "    formatted_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    with open(f\"/tmp/{J}_{M}_{formatted_datetime}.txt\", 'w') as f:\n",
    "        f.write(f\"{J} {M}\\n\")\n",
    "        for times in processor_times:\n",
    "            f.write(\" \".join(map(str, times)) + '\\n')\n",
    "        for orders in orders_of_machines:\n",
    "            f.write(\" \".join(map(str, orders)) + '\\n')  \n",
    "\n",
    "    return f\"/tmp/{J}_{M}_{formatted_datetime}.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab9a20-616e-4629-99f7-9ddf6ba511ce",
   "metadata": {},
   "source": [
    "According to https://github.com/jolibrain/wheatley/issues/89, I was advised to model dynamic JSSP by adding a \"virtual task\" for jobs not known at the beginning, which have processing time equal to the arrival time of the job. Each virtual task is performed on a separate machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753246e2-3882-4461-a939-8a6d3ad8d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_jssp(instance, arrival_times):\n",
    "    '''Turns static JSSP into dynamic JSSP\n",
    "\n",
    "    Args:\n",
    "      instance: static JSSP instance\n",
    "      arrival_times: arrival times of jobs\n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "\n",
    "    for index, arrival_time in enumerate(arrival_times):\n",
    "        if arrival_time == 0:\n",
    "            # job known at the start\n",
    "            continue\n",
    "\n",
    "        # add a new task with processing time equal to arrival_time\n",
    "        processor_times[index].insert(0, arrival_time)\n",
    "\n",
    "        # new task is processed on a separate machine\n",
    "        M += 1\n",
    "        orders_of_machines[index].insert(0, M)\n",
    "\n",
    "    return save_jssp_taillard(processor_times, orders_of_machines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf849b-689b-4eff-9dc7-d4cf6f96014b",
   "metadata": {},
   "source": [
    "## Dynamic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19812000-e38c-4fd5-8eb0-1782a270cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static instance: abz5.txt, jobs: 10, machines: 15, makespan: 3749.0\n",
      "Dynamic instance: abz5.txt, jobs: 10, machines: 15, makespan: 3434.0\n",
      "Static instance: abz6.txt, jobs: 10, machines: 15, makespan: 2700.0\n",
      "Dynamic instance: abz6.txt, jobs: 10, machines: 15, makespan: 2740.0\n",
      "Static instance: ft06.txt, jobs: 6, machines: 9, makespan: 80.0\n",
      "Dynamic instance: ft06.txt, jobs: 6, machines: 9, makespan: 101.0\n",
      "Static instance: ft10.txt, jobs: 10, machines: 15, makespan: 2768.0\n",
      "Dynamic instance: ft10.txt, jobs: 10, machines: 15, makespan: 2987.0\n",
      "Static instance: la01.txt, jobs: 10, machines: 10, makespan: 1121.0\n",
      "Dynamic instance: la01.txt, jobs: 10, machines: 10, makespan: 1400.0\n",
      "Static instance: la02.txt, jobs: 10, machines: 10, makespan: 1171.0\n",
      "Dynamic instance: la02.txt, jobs: 10, machines: 10, makespan: 1238.0\n",
      "Static instance: la03.txt, jobs: 10, machines: 10, makespan: 1096.0\n",
      "Dynamic instance: la03.txt, jobs: 10, machines: 10, makespan: 890.0\n",
      "Static instance: la04.txt, jobs: 10, machines: 10, makespan: 1296.0\n",
      "Dynamic instance: la04.txt, jobs: 10, machines: 10, makespan: 1153.0\n",
      "Static instance: la05.txt, jobs: 10, machines: 10, makespan: 839.0\n",
      "Dynamic instance: la05.txt, jobs: 10, machines: 10, makespan: 1058.0\n",
      "Static instance: la06.txt, jobs: 15, machines: 12, makespan: 1816.0\n",
      "Dynamic instance: la06.txt, jobs: 15, machines: 12, makespan: 1845.0\n",
      "Static instance: la07.txt, jobs: 15, machines: 12, makespan: 1801.0\n",
      "Dynamic instance: la07.txt, jobs: 15, machines: 12, makespan: 1918.0\n",
      "Static instance: la08.txt, jobs: 15, machines: 12, makespan: 2108.0\n",
      "Dynamic instance: la08.txt, jobs: 15, machines: 12, makespan: 1950.0\n",
      "Static instance: la09.txt, jobs: 15, machines: 12, makespan: 2001.0\n",
      "Dynamic instance: la09.txt, jobs: 15, machines: 12, makespan: 1970.0\n",
      "Static instance: la10.txt, jobs: 15, machines: 12, makespan: 2158.0\n",
      "Dynamic instance: la10.txt, jobs: 15, machines: 12, makespan: 2417.0\n",
      "Static instance: la16.txt, jobs: 10, machines: 15, makespan: 2673.0\n",
      "Dynamic instance: la16.txt, jobs: 10, machines: 15, makespan: 2571.0\n",
      "Static instance: la17.txt, jobs: 10, machines: 15, makespan: 2382.0\n",
      "Dynamic instance: la17.txt, jobs: 10, machines: 15, makespan: 2297.0\n",
      "Static instance: la18.txt, jobs: 10, machines: 15, makespan: 2602.0\n",
      "Dynamic instance: la18.txt, jobs: 10, machines: 15, makespan: 2970.0\n",
      "Static instance: la19.txt, jobs: 10, machines: 15, makespan: 2476.0\n",
      "Dynamic instance: la19.txt, jobs: 10, machines: 15, makespan: 2428.0\n",
      "Static instance: la20.txt, jobs: 10, machines: 15, makespan: 2517.0\n",
      "Dynamic instance: la20.txt, jobs: 10, machines: 15, makespan: 2636.0\n",
      "Static instance: orb01.txt, jobs: 10, machines: 15, makespan: 3140.0\n",
      "Dynamic instance: orb01.txt, jobs: 10, machines: 15, makespan: 2781.0\n",
      "Static instance: orb02.txt, jobs: 10, machines: 15, makespan: 3756.0\n",
      "Dynamic instance: orb02.txt, jobs: 10, machines: 15, makespan: 3143.0\n",
      "Static instance: orb03.txt, jobs: 10, machines: 15, makespan: 2217.0\n",
      "Dynamic instance: orb03.txt, jobs: 10, machines: 15, makespan: 2553.0\n",
      "Static instance: orb04.txt, jobs: 10, machines: 15, makespan: 4023.0\n",
      "Dynamic instance: orb04.txt, jobs: 10, machines: 15, makespan: 3999.0\n",
      "Static instance: orb05.txt, jobs: 10, machines: 15, makespan: 2688.0\n",
      "Dynamic instance: orb05.txt, jobs: 10, machines: 15, makespan: 3010.0\n",
      "Static instance: orb06.txt, jobs: 10, machines: 15, makespan: 3487.0\n",
      "Dynamic instance: orb06.txt, jobs: 10, machines: 15, makespan: 3653.0\n",
      "Static instance: orb07.txt, jobs: 10, machines: 15, makespan: 1567.0\n",
      "Dynamic instance: orb07.txt, jobs: 10, machines: 15, makespan: 1672.0\n",
      "Static instance: orb08.txt, jobs: 10, machines: 15, makespan: 2158.0\n",
      "Dynamic instance: orb08.txt, jobs: 10, machines: 15, makespan: 2129.0\n",
      "Static instance: orb09.txt, jobs: 10, machines: 15, makespan: 3695.0\n",
      "Dynamic instance: orb09.txt, jobs: 10, machines: 15, makespan: 4101.0\n",
      "Static instance: orb10.txt, jobs: 10, machines: 15, makespan: 3219.0\n",
      "Dynamic instance: orb10.txt, jobs: 10, machines: 15, makespan: 2963.0\n"
     ]
    }
   ],
   "source": [
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    arrival_times = generate_arrival_times_for_jssp(instance)\n",
    "    dynamic_instance = get_dynamic_jssp(instance, arrival_times)\n",
    "    J, M, _, _ = parse_instance_taillard(dynamic_instance)\n",
    "    if agent.env_specification.max_n_jobs < J:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < M:\n",
    "        continue\n",
    "        \n",
    "    static_solution = solve_instance_taillard(instance, agent)\n",
    "    print(f\"Static instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {static_solution.get_makespan()}\")\n",
    "    dynamic_solution = solve_instance_taillard(dynamic_instance, agent)\n",
    "    print(f\"Dynamic instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {dynamic_solution.get_makespan()}\")\n",
    "\n",
    "    # uncomment this to print schedule correctly\n",
    "    # print(f\"{arrival_times=}\")\n",
    "    # for index, arrival_time in enumerate(arrival_times):\n",
    "    #     if arrival_time > 0:    \n",
    "    #         print(arrival_time, dynamic_solution.schedule[index][1:])\n",
    "    #     else:\n",
    "    #         print(arrival_time, dynamic_solution.schedule[index])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2fe9aa-f7f3-44f2-bbf1-80ee745203ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
