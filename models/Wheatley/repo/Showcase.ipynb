{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231591d0-ec1a-4437-a3a8-0411a7033dc5",
   "metadata": {},
   "source": [
    "# Wheatley\n",
    "\n",
    "> Next-generation scheduling problem solver based on GNNs and Reinforcement Learning\n",
    "\n",
    "The authors of Wheatley created a [script for training](jssp/train.py) and a [script for solving](jssp/solve.py) the problem. Documentation is in [USAGE.md](docs/USAGE.md) For this quick showcase, I trained a model on random 15x15 instances (15 jobs, 15 machines). To solve benchmark instances, I just need to import the function implemented by Wheatley's authors. The model takes quite some time to train, and therefore the model in this showcase is trained very badly due to time constraints. Makespans will be therefore incredibly bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3dd1935-8b43-479a-8516-3ef980a49f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Wheatley jssp solver\n",
    "from jssp.solve import solve_instance\n",
    "from jssp.utils.loaders import load_problem\n",
    "from jssp.models.agent import Agent\n",
    "\n",
    "# load trained agent\n",
    "agent = Agent.load(\"saved_networks/agent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cd5f1-7997-4957-a19b-3d0eff2f9413",
   "metadata": {},
   "source": [
    "# Benchmarks Wheatley can solve right now\n",
    "\n",
    "Wheatley can solve only instances, which are the same size or smaller than those he has been trained on. Therefore I can \n",
    "I will now run Wheatley on all available JSSP benchmarks I currently have, which are 15x15 or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374346f-43eb-4c68-9a00-ef1db8b08cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f956101c-f44a-4b04-994d-def1faf44970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marosbratko/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/env/observation.py:127: RuntimeWarning: invalid value encountered in cast\n",
      "  \"edge_index\": edge_index.astype(\"int64\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: abz5.txt, jobs: 10, machines: 10, makespan: 3749.0\n",
      "Instance: abz6.txt, jobs: 10, machines: 10, makespan: 2700.0\n",
      "Instance: ft06.txt, jobs: 6, machines: 6, makespan: 80.0\n",
      "Instance: ft10.txt, jobs: 10, machines: 10, makespan: 2768.0\n",
      "Instance: la01.txt, jobs: 10, machines: 5, makespan: 1121.0\n",
      "Instance: la02.txt, jobs: 10, machines: 5, makespan: 1171.0\n",
      "Instance: la03.txt, jobs: 10, machines: 5, makespan: 1096.0\n",
      "Instance: la04.txt, jobs: 10, machines: 5, makespan: 1296.0\n",
      "Instance: la05.txt, jobs: 10, machines: 5, makespan: 839.0\n",
      "Instance: la06.txt, jobs: 15, machines: 5, makespan: 1816.0\n",
      "Instance: la07.txt, jobs: 15, machines: 5, makespan: 1801.0\n",
      "Instance: la08.txt, jobs: 15, machines: 5, makespan: 2108.0\n",
      "Instance: la09.txt, jobs: 15, machines: 5, makespan: 2001.0\n",
      "Instance: la10.txt, jobs: 15, machines: 5, makespan: 2158.0\n",
      "Instance: la16.txt, jobs: 10, machines: 10, makespan: 2673.0\n",
      "Instance: la17.txt, jobs: 10, machines: 10, makespan: 2382.0\n",
      "Instance: la18.txt, jobs: 10, machines: 10, makespan: 2602.0\n",
      "Instance: la19.txt, jobs: 10, machines: 10, makespan: 2476.0\n",
      "Instance: la20.txt, jobs: 10, machines: 10, makespan: 2517.0\n",
      "Instance: la21.txt, jobs: 15, machines: 10, makespan: 3777.0\n",
      "Instance: la22.txt, jobs: 15, machines: 10, makespan: 3843.0\n",
      "Instance: la23.txt, jobs: 15, machines: 10, makespan: 3821.0\n",
      "Instance: la24.txt, jobs: 15, machines: 10, makespan: 3541.0\n",
      "Instance: la25.txt, jobs: 15, machines: 10, makespan: 3398.0\n",
      "Instance: la36.txt, jobs: 15, machines: 15, makespan: 5056.0\n",
      "Instance: la37.txt, jobs: 15, machines: 15, makespan: 5808.0\n",
      "Instance: la38.txt, jobs: 15, machines: 15, makespan: 5297.0\n",
      "Instance: la39.txt, jobs: 15, machines: 15, makespan: 5810.0\n",
      "Instance: la40.txt, jobs: 15, machines: 15, makespan: 5096.0\n",
      "Instance: orb01.txt, jobs: 10, machines: 10, makespan: 3140.0\n",
      "Instance: orb02.txt, jobs: 10, machines: 10, makespan: 3756.0\n",
      "Instance: orb03.txt, jobs: 10, machines: 10, makespan: 2217.0\n",
      "Instance: orb04.txt, jobs: 10, machines: 10, makespan: 4023.0\n",
      "Instance: orb05.txt, jobs: 10, machines: 10, makespan: 2688.0\n",
      "Instance: orb06.txt, jobs: 10, machines: 10, makespan: 3487.0\n",
      "Instance: orb07.txt, jobs: 10, machines: 10, makespan: 1567.0\n",
      "Instance: orb08.txt, jobs: 10, machines: 10, makespan: 2158.0\n",
      "Instance: orb09.txt, jobs: 10, machines: 10, makespan: 3695.0\n",
      "Instance: orb10.txt, jobs: 10, machines: 10, makespan: 3219.0\n",
      "Instance: ta01.txt, jobs: 15, machines: 15, makespan: 4761.0\n",
      "Instance: ta02.txt, jobs: 15, machines: 15, makespan: 5766.0\n",
      "Instance: ta03.txt, jobs: 15, machines: 15, makespan: 5951.0\n",
      "Instance: ta04.txt, jobs: 15, machines: 15, makespan: 5877.0\n",
      "Instance: ta05.txt, jobs: 15, machines: 15, makespan: 6061.0\n",
      "Instance: ta06.txt, jobs: 15, machines: 15, makespan: 5050.0\n",
      "Instance: ta07.txt, jobs: 15, machines: 15, makespan: 5986.0\n",
      "Instance: ta08.txt, jobs: 15, machines: 15, makespan: 5555.0\n",
      "Instance: ta09.txt, jobs: 15, machines: 15, makespan: 5251.0\n",
      "Instance: ta10.txt, jobs: 15, machines: 15, makespan: 5036.0\n"
     ]
    }
   ],
   "source": [
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        instance,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    if agent.env_specification.max_n_jobs < n_j:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < n_m:\n",
    "        continue\n",
    "        \n",
    "    solution = solve_instance(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "    print(f\"Instance: {instance.split('/')[-1]}, jobs: {n_j}, machines: {n_m}, makespan: {solution.get_makespan()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceed6db-947f-4f48-bbe1-d303d92452ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
