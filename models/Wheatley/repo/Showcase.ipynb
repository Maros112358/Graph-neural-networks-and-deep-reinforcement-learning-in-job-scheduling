{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231591d0-ec1a-4437-a3a8-0411a7033dc5",
   "metadata": {},
   "source": [
    "# Wheatley\n",
    "\n",
    "> Next-generation scheduling problem solver based on GNNs and Reinforcement Learning\n",
    "\n",
    "The authors of Wheatley created a [script for training](jssp/train.py) and a [script for solving](jssp/solve.py) the problem. Documentation is in [USAGE.md](docs/USAGE.md) For this quick showcase, I trained a model on random 15x15 instances (15 jobs, 15 machines). To solve benchmark instances, I just need to import the function implemented by Wheatley's authors. The model takes quite some time to train, and therefore the model in this showcase is trained very badly due to time constraints. Makespans will be therefore incredibly bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3dd1935-8b43-479a-8516-3ef980a49f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from generic.utils import decode_mask\n",
    "from jssp.description import Description\n",
    "from jssp.env.env import Env\n",
    "from jssp.models.agent import Agent\n",
    "from jssp.solution import Solution\n",
    "\n",
    "# import Wheatley jssp solver\n",
    "from jssp.solve import solve_instance\n",
    "from jssp.utils.loaders import load_problem\n",
    "from jssp.models.agent import Agent\n",
    "\n",
    "# load trained agent\n",
    "agent = Agent.load(\"saved_networks/agent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cd5f1-7997-4957-a19b-3d0eff2f9413",
   "metadata": {},
   "source": [
    "# Benchmarks Wheatley can solve right now\n",
    "\n",
    "Wheatley can solve only instances, which are the same size or smaller than those he has been trained on. Therefore I can \n",
    "I will now run Wheatley on all available JSSP benchmarks I currently have, which are 15x15 or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374346f-43eb-4c68-9a00-ef1db8b08cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = []\n",
    "        orders_of_machines = []\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times.append(list(map(int, f.readline().split())))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines.append(list(map(int, f.readline().split())))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/jssp/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "def solve_instance_taillard(instance, agent):\n",
    "    '''Solves JSSP instance in Taillard specification\n",
    "    \n",
    "      Args:\n",
    "        instance: instance to solve\n",
    "        agent: agent to use for solving the problem\n",
    "\n",
    "      Returns:\n",
    "        solution\n",
    "    '''\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        instance,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    assert agent.env_specification.max_n_jobs >= n_j\n",
    "    assert agent.env_specification.max_n_machines >= n_m\n",
    "        \n",
    "    solution = solve_instance(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f956101c-f44a-4b04-994d-def1faf44970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_bounds= -1.0\n",
      "Instance: abz5.txt, jobs: 10, machines: 10, makespan: 3970.0\n",
      "runtime 0.4933128356933594\n",
      "generate_bounds= -1.0\n",
      "Instance: abz6.txt, jobs: 10, machines: 10, makespan: 3049.0\n",
      "runtime 0.4589118957519531\n",
      "generate_bounds= -1.0\n",
      "Instance: abz7.txt, jobs: 20, machines: 15, makespan: 3913.0\n",
      "runtime 1.8555028438568115\n",
      "generate_bounds= -1.0\n",
      "Instance: abz8.txt, jobs: 20, machines: 15, makespan: 3926.0\n",
      "runtime 1.8436949253082275\n",
      "generate_bounds= -1.0\n",
      "Instance: abz9.txt, jobs: 20, machines: 15, makespan: 3253.0\n",
      "runtime 1.8647408485412598\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu01.txt, jobs: 20, machines: 15, makespan: 14523.0\n",
      "runtime 1.8324451446533203\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu02.txt, jobs: 20, machines: 15, makespan: 18598.0\n",
      "runtime 1.8685522079467773\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu03.txt, jobs: 20, machines: 15, makespan: 16040.0\n",
      "runtime 1.8612818717956543\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu04.txt, jobs: 20, machines: 15, makespan: 14877.0\n",
      "runtime 1.8495841026306152\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu05.txt, jobs: 20, machines: 15, makespan: 15713.0\n",
      "runtime 1.8706567287445068\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu06.txt, jobs: 20, machines: 20, makespan: 22042.0\n",
      "runtime 2.728708267211914\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu07.txt, jobs: 20, machines: 20, makespan: 20533.0\n",
      "runtime 2.7137129306793213\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu08.txt, jobs: 20, machines: 20, makespan: 24560.0\n",
      "runtime 2.7696619033813477\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu09.txt, jobs: 20, machines: 20, makespan: 23365.0\n",
      "runtime 2.9495811462402344\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu10.txt, jobs: 20, machines: 20, makespan: 23793.0\n",
      "runtime 2.855984926223755\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu11.txt, jobs: 30, machines: 15, makespan: 22484.0\n",
      "runtime 3.8515658378601074\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu12.txt, jobs: 30, machines: 15, makespan: 23134.0\n",
      "runtime 3.7885069847106934\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu13.txt, jobs: 30, machines: 15, makespan: 22870.0\n",
      "runtime 3.7300820350646973\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu14.txt, jobs: 30, machines: 15, makespan: 22121.0\n",
      "runtime 3.8196139335632324\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu15.txt, jobs: 30, machines: 15, makespan: 25856.0\n",
      "runtime 3.8648619651794434\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu16.txt, jobs: 30, machines: 20, makespan: 30959.0\n",
      "runtime 6.015489816665649\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu17.txt, jobs: 30, machines: 20, makespan: 36527.0\n",
      "runtime 6.432941913604736\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu18.txt, jobs: 30, machines: 20, makespan: 31630.0\n",
      "runtime 5.7628867626190186\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu19.txt, jobs: 30, machines: 20, makespan: 30793.0\n",
      "runtime 6.041268825531006\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu20.txt, jobs: 30, machines: 20, makespan: 29139.0\n",
      "runtime 5.767145872116089\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu21.txt, jobs: 40, machines: 15, makespan: 28369.0\n",
      "runtime 6.467808961868286\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu22.txt, jobs: 40, machines: 15, makespan: 32486.0\n",
      "runtime 6.500410795211792\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu23.txt, jobs: 40, machines: 15, makespan: 30825.0\n",
      "runtime 6.416343927383423\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu24.txt, jobs: 40, machines: 15, makespan: 33467.0\n",
      "runtime 6.419344186782837\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu25.txt, jobs: 40, machines: 15, makespan: 28698.0\n",
      "runtime 6.360584020614624\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu26.txt, jobs: 40, machines: 20, makespan: 37996.0\n",
      "runtime 10.16389513015747\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu27.txt, jobs: 40, machines: 20, makespan: 42840.0\n",
      "runtime 10.166388034820557\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu28.txt, jobs: 40, machines: 20, makespan: 46892.0\n",
      "runtime 10.113752841949463\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu29.txt, jobs: 40, machines: 20, makespan: 39048.0\n",
      "runtime 102.21784806251526\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu30.txt, jobs: 40, machines: 20, makespan: 44841.0\n",
      "runtime 10.43464708328247\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu31.txt, jobs: 50, machines: 15, makespan: 42635.0\n",
      "runtime 10.54935598373413\n",
      "generate_bounds= -1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# if agent.env_specification.max_n_jobs < J:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# if agent.env_specification.max_n_machines < M:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 12\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance_taillard\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m runtime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstance\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, jobs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, machines: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, makespan: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolution\u001b[38;5;241m.\u001b[39mget_makespan()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m, in \u001b[0;36msolve_instance_taillard\u001b[0;34m(instance, agent)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_jobs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_j\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_machines \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_m\n\u001b[0;32m---> 67\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffectations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/solve.py:37\u001b[0m, in \u001b[0;36msolve_instance\u001b[0;34m(agent, affectations, durations, deterministic)\u001b[0m\n\u001b[1;32m     35\u001b[0m action_masks \u001b[38;5;241m=\u001b[39m decode_mask(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     36\u001b[0m obs \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mobs_as_tensor_add_batch_dim(obs)\n\u001b[0;32m---> 37\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m obs, reward, done, _, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     39\u001b[0m solution \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_solution()\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/generic/agent.py:212\u001b[0m, in \u001b[0;36mAgent.predict\u001b[0;34m(self, observation, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation, deterministic, action_masks):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 212\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(features)\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m action_masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    J, M, _, _ = parse_instance_taillard(instance)\n",
    "    # if agent.env_specification.max_n_jobs < J:\n",
    "    #     continue\n",
    "\n",
    "    # if agent.env_specification.max_n_machines < M:\n",
    "    #     continue\n",
    "\n",
    "    start = time.time()\n",
    "    solution = solve_instance_taillard(instance, agent)\n",
    "    runtime = time.time() - start\n",
    "    \n",
    "    print(f\"Instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {solution.get_makespan()}\")\n",
    "    print('runtime', runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05f863-e45e-4321-ad91-9cc6a1d43f7f",
   "metadata": {},
   "source": [
    "# Dynamic JSSP\n",
    "\n",
    "In dynamic JSSP, only a subset of jobs is known at the beginning. The rest of jobs arrives dynamically online.\n",
    "\n",
    "The following attempt to expand L2D to being dynamic is inspired by paper [Large-scale Dynamic Scheduling for Flexible Job-shop with Random Arrivals of New Jobs by Hierarchical Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114974), where authors schedule newly incoming jobs and reschedule not yet executed operations, already executed operations can not be rescheduled. During each rescheduling, they formulate static FJSP and solve it. They use cache for incoming jobs and an agent choosing either to add jobs from cache to scheduling problem, or keep them in cache. I will skip this agent and always add new jobs to scheduling problem.\n",
    "\n",
    "Similarly to the paper, I will model the arrival of new jobs as poisson process with average arrival time following an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf49e3e4-a60e-4ef7-9d42-9730428df2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generate_arrival_times_for_jssp(instance):\n",
    "    '''Turns static JSSP instance to dynamic\n",
    "\n",
    "      Args:\n",
    "        filename of static JSSP instance\n",
    "\n",
    "      Returns:\n",
    "        list of jobs known at the beginning\n",
    "        dictionary of arriving jobs as  as {time_of_arrival: (operations, machines)} \n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "    arrival_times = np.zeros(J, dtype=int)\n",
    "\n",
    "    # calculate beta = 1/lambda\n",
    "    flattened_processor_times = [operation_time for job in processor_times for operation_time in job]\n",
    "    average_time_between_arrivals = (np.mean(flattened_processor_times) * len(processor_times[0])) / M\n",
    "    \n",
    "    # separate jobs into known jobs and arriving jobs\n",
    "    indices = np.arange(J)\n",
    "    arriving_jobs_indeces = indices[:J//2]\n",
    "    np.random.shuffle(indices)\n",
    "    t = 1\n",
    "    for index in arriving_jobs_indeces:\n",
    "        t += int(np.random.exponential(scale=average_time_between_arrivals)) + 1\n",
    "        arrival_times[index] = t\n",
    "\n",
    "    return list(arrival_times)\n",
    "\n",
    "def save_jssp_taillard(processor_times, orders_of_machines):\n",
    "    '''Saves list of jobs as static JSSP instance in taillards specification\n",
    "        \n",
    "      Args:\n",
    "        list of jobs to save\n",
    "\n",
    "      Returns:\n",
    "        filename where JSSP instance was saved to\n",
    "    '''\n",
    "    assert len(processor_times) == len(orders_of_machines), \"Processor times and machines do not have the same length\"\n",
    "    for times, machines in zip(processor_times, orders_of_machines):\n",
    "        assert len(times) == len(machines), \"Times and machines for a specific job do not have the same length\"\n",
    "        \n",
    "    J = len(processor_times)\n",
    "    M = max(max(machines) for machines in orders_of_machines)\n",
    "    \n",
    "    formatted_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    with open(f\"/tmp/{J}_{M}_{formatted_datetime}.txt\", 'w') as f:\n",
    "        f.write(f\"{J} {M}\\n\")\n",
    "        for times in processor_times:\n",
    "            f.write(\" \".join(map(str, times)) + '\\n')\n",
    "        for orders in orders_of_machines:\n",
    "            f.write(\" \".join(map(str, orders)) + '\\n')  \n",
    "\n",
    "    return f\"/tmp/{J}_{M}_{formatted_datetime}.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab9a20-616e-4629-99f7-9ddf6ba511ce",
   "metadata": {},
   "source": [
    "According to https://github.com/jolibrain/wheatley/issues/89, I was advised to model dynamic JSSP by adding a \"virtual task\" for jobs not known at the beginning, which have processing time equal to the arrival time of the job. Each virtual task is performed on a separate machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753246e2-3882-4461-a939-8a6d3ad8d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_jssp(instance, arrival_times):\n",
    "    '''Turns static JSSP into dynamic JSSP\n",
    "\n",
    "    Args:\n",
    "      instance: static JSSP instance\n",
    "      arrival_times: arrival times of jobs\n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "\n",
    "    for index, arrival_time in enumerate(arrival_times):\n",
    "        if arrival_time == 0:\n",
    "            # job known at the start\n",
    "            continue\n",
    "\n",
    "        # add a new task with processing time equal to arrival_time\n",
    "        processor_times[index].insert(0, arrival_time)\n",
    "\n",
    "        # new task is processed on a separate machine\n",
    "        M += 1\n",
    "        orders_of_machines[index].insert(0, M)\n",
    "\n",
    "    return save_jssp_taillard(processor_times, orders_of_machines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf849b-689b-4eff-9dc7-d4cf6f96014b",
   "metadata": {},
   "source": [
    "## Dynamic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19812000-e38c-4fd5-8eb0-1782a270cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_bounds= -1.0\n",
      "Static instance: abz5.txt, jobs: 10, machines: 15, makespan: 3970.0\n",
      "generate_bounds= -1.0\n",
      "Dynamic instance: abz5.txt, jobs: 10, machines: 15, makespan: 4740.0\n",
      "generate_bounds= -1.0\n",
      "Static instance: abz6.txt, jobs: 10, machines: 15, makespan: 3049.0\n",
      "generate_bounds= -1.0\n",
      "Dynamic instance: abz6.txt, jobs: 10, machines: 15, makespan: 3771.0\n",
      "generate_bounds= -1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_machines \u001b[38;5;241m<\u001b[39m M:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m static_solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance_taillard\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatic instance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstance\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, jobs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, machines: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, makespan: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatic_solution\u001b[38;5;241m.\u001b[39mget_makespan()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m dynamic_solution \u001b[38;5;241m=\u001b[39m solve_instance_taillard(dynamic_instance, agent)\n",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m, in \u001b[0;36msolve_instance_taillard\u001b[0;34m(instance, agent)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_jobs \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_j\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m agent\u001b[38;5;241m.\u001b[39menv_specification\u001b[38;5;241m.\u001b[39mmax_n_machines \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_m\n\u001b[0;32m---> 67\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffectations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solution\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/jssp/solve.py:35\u001b[0m, in \u001b[0;36msolve_instance\u001b[0;34m(agent, affectations, durations, deterministic)\u001b[0m\n\u001b[1;32m     33\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 35\u001b[0m     action_masks \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     obs \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mobs_as_tensor_add_batch_dim(obs)\n\u001b[1;32m     37\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, action_masks\u001b[38;5;241m=\u001b[39maction_masks)\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/repo/generic/utils.py:38\u001b[0m, in \u001b[0;36mdecode_mask\u001b[0;34m(info_mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_mask\u001b[39m(info_mask):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/venv/lib/python3.10/site-packages/numpy/core/shape_base.py:443\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_stack_dispatcher)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Join a sequence of arrays along a new axis.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/Wheatley/venv/lib/python3.10/site-packages/numpy/core/shape_base.py:443\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_stack_dispatcher)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    374\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Join a sequence of arrays along a new axis.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    arrival_times = generate_arrival_times_for_jssp(instance)\n",
    "    dynamic_instance = get_dynamic_jssp(instance, arrival_times)\n",
    "    J, M, _, _ = parse_instance_taillard(dynamic_instance)\n",
    "    if agent.env_specification.max_n_jobs < J:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < M:\n",
    "        continue\n",
    "        \n",
    "    static_solution = solve_instance_taillard(instance, agent)\n",
    "    print(f\"Static instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {static_solution.get_makespan()}\")\n",
    "    dynamic_solution = solve_instance_taillard(dynamic_instance, agent)\n",
    "    print(f\"Dynamic instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {dynamic_solution.get_makespan()}\")\n",
    "\n",
    "    # uncomment this to print schedule correctly\n",
    "    # print(f\"{arrival_times=}\")\n",
    "    # for index, arrival_time in enumerate(arrival_times):\n",
    "    #     if arrival_time > 0:    \n",
    "    #         print(arrival_time, dynamic_solution.schedule[index][1:])\n",
    "    #     else:\n",
    "    #         print(arrival_time, dynamic_solution.schedule[index])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2fe9aa-f7f3-44f2-bbf1-80ee745203ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
