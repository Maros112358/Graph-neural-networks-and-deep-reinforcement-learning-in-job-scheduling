{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231591d0-ec1a-4437-a3a8-0411a7033dc5",
   "metadata": {},
   "source": [
    "# Wheatley\n",
    "\n",
    "> Next-generation scheduling problem solver based on GNNs and Reinforcement Learning\n",
    "\n",
    "The authors of Wheatley created a [script for training](jssp/train.py) and a [script for solving](jssp/solve.py) the problem. Documentation is in [USAGE.md](docs/USAGE.md) For this quick showcase, I trained a model on random 15x15 instances (15 jobs, 15 machines). To solve benchmark instances, I just need to import the function implemented by Wheatley's authors. The model takes quite some time to train, and therefore the model in this showcase is trained very badly due to time constraints. Makespans will be therefore incredibly bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3dd1935-8b43-479a-8516-3ef980a49f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from generic.utils import decode_mask\n",
    "from jssp.description import Description\n",
    "from jssp.env.env import Env\n",
    "from jssp.models.agent import Agent\n",
    "from jssp.solution import Solution\n",
    "\n",
    "# import Wheatley jssp solver\n",
    "from jssp.solve import solve_instance\n",
    "from jssp.utils.loaders import load_problem\n",
    "from jssp.models.agent import Agent\n",
    "\n",
    "# load trained agent\n",
    "agent = Agent.load(\"saved_networks/agent.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cd5f1-7997-4957-a19b-3d0eff2f9413",
   "metadata": {},
   "source": [
    "# Benchmarks Wheatley can solve right now\n",
    "\n",
    "Wheatley can solve only instances, which are the same size or smaller than those he has been trained on. Therefore I can \n",
    "I will now run Wheatley on all available JSSP benchmarks I currently have, which are 15x15 or smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374346f-43eb-4c68-9a00-ef1db8b08cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = []\n",
    "        orders_of_machines = []\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times.append(list(map(int, f.readline().split())))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines.append(list(map(int, f.readline().split())))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/jssp/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "def solve_instance_taillard(instance, agent):\n",
    "    '''Solves JSSP instance in Taillard specification\n",
    "    \n",
    "      Args:\n",
    "        instance: instance to solve\n",
    "        agent: agent to use for solving the problem\n",
    "\n",
    "      Returns:\n",
    "        solution\n",
    "    '''\n",
    "    n_j, n_m, affectations, durations = load_problem(\n",
    "        instance,\n",
    "        taillard_offset=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    assert agent.env_specification.max_n_jobs >= n_j\n",
    "    assert agent.env_specification.max_n_machines >= n_m\n",
    "        \n",
    "    solution = solve_instance(\n",
    "        agent, affectations, durations, True\n",
    "    )\n",
    "\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956101c-f44a-4b04-994d-def1faf44970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_bounds= -1.0\n",
      "Instance: abz5.txt, jobs: 10, machines: 10, makespan: 3970.0\n",
      "runtime 0.4933128356933594\n",
      "generate_bounds= -1.0\n",
      "Instance: abz6.txt, jobs: 10, machines: 10, makespan: 3049.0\n",
      "runtime 0.4589118957519531\n",
      "generate_bounds= -1.0\n",
      "Instance: abz7.txt, jobs: 20, machines: 15, makespan: 3913.0\n",
      "runtime 1.8555028438568115\n",
      "generate_bounds= -1.0\n",
      "Instance: abz8.txt, jobs: 20, machines: 15, makespan: 3926.0\n",
      "runtime 1.8436949253082275\n",
      "generate_bounds= -1.0\n",
      "Instance: abz9.txt, jobs: 20, machines: 15, makespan: 3253.0\n",
      "runtime 1.8647408485412598\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu01.txt, jobs: 20, machines: 15, makespan: 14523.0\n",
      "runtime 1.8324451446533203\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu02.txt, jobs: 20, machines: 15, makespan: 18598.0\n",
      "runtime 1.8685522079467773\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu03.txt, jobs: 20, machines: 15, makespan: 16040.0\n",
      "runtime 1.8612818717956543\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu04.txt, jobs: 20, machines: 15, makespan: 14877.0\n",
      "runtime 1.8495841026306152\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu05.txt, jobs: 20, machines: 15, makespan: 15713.0\n",
      "runtime 1.8706567287445068\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu06.txt, jobs: 20, machines: 20, makespan: 22042.0\n",
      "runtime 2.728708267211914\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu07.txt, jobs: 20, machines: 20, makespan: 20533.0\n",
      "runtime 2.7137129306793213\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu08.txt, jobs: 20, machines: 20, makespan: 24560.0\n",
      "runtime 2.7696619033813477\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu09.txt, jobs: 20, machines: 20, makespan: 23365.0\n",
      "runtime 2.9495811462402344\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu10.txt, jobs: 20, machines: 20, makespan: 23793.0\n",
      "runtime 2.855984926223755\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu11.txt, jobs: 30, machines: 15, makespan: 22484.0\n",
      "runtime 3.8515658378601074\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu12.txt, jobs: 30, machines: 15, makespan: 23134.0\n",
      "runtime 3.7885069847106934\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu13.txt, jobs: 30, machines: 15, makespan: 22870.0\n",
      "runtime 3.7300820350646973\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu14.txt, jobs: 30, machines: 15, makespan: 22121.0\n",
      "runtime 3.8196139335632324\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu15.txt, jobs: 30, machines: 15, makespan: 25856.0\n",
      "runtime 3.8648619651794434\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu16.txt, jobs: 30, machines: 20, makespan: 30959.0\n",
      "runtime 6.015489816665649\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu17.txt, jobs: 30, machines: 20, makespan: 36527.0\n",
      "runtime 6.432941913604736\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu18.txt, jobs: 30, machines: 20, makespan: 31630.0\n",
      "runtime 5.7628867626190186\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu19.txt, jobs: 30, machines: 20, makespan: 30793.0\n",
      "runtime 6.041268825531006\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu20.txt, jobs: 30, machines: 20, makespan: 29139.0\n",
      "runtime 5.767145872116089\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu21.txt, jobs: 40, machines: 15, makespan: 28369.0\n",
      "runtime 6.467808961868286\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu22.txt, jobs: 40, machines: 15, makespan: 32486.0\n",
      "runtime 6.500410795211792\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu23.txt, jobs: 40, machines: 15, makespan: 30825.0\n",
      "runtime 6.416343927383423\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu24.txt, jobs: 40, machines: 15, makespan: 33467.0\n",
      "runtime 6.419344186782837\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu25.txt, jobs: 40, machines: 15, makespan: 28698.0\n",
      "runtime 6.360584020614624\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu26.txt, jobs: 40, machines: 20, makespan: 37996.0\n",
      "runtime 10.16389513015747\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu27.txt, jobs: 40, machines: 20, makespan: 42840.0\n",
      "runtime 10.166388034820557\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu28.txt, jobs: 40, machines: 20, makespan: 46892.0\n",
      "runtime 10.113752841949463\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu29.txt, jobs: 40, machines: 20, makespan: 39048.0\n",
      "runtime 102.21784806251526\n",
      "generate_bounds= -1.0\n",
      "Instance: dmu30.txt, jobs: 40, machines: 20, makespan: 44841.0\n",
      "runtime 10.43464708328247\n",
      "generate_bounds= -1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    J, M, _, _ = parse_instance_taillard(instance)\n",
    "    # if agent.env_specification.max_n_jobs < J:\n",
    "    #     continue\n",
    "\n",
    "    # if agent.env_specification.max_n_machines < M:\n",
    "    #     continue\n",
    "\n",
    "    start = time.time()\n",
    "    solution = solve_instance_taillard(instance, agent)\n",
    "    runtime = time.time() - start\n",
    "    \n",
    "    print(f\"Instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {solution.get_makespan()}\")\n",
    "    print('runtime', runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05f863-e45e-4321-ad91-9cc6a1d43f7f",
   "metadata": {},
   "source": [
    "# Dynamic JSSP\n",
    "\n",
    "In dynamic JSSP, only a subset of jobs is known at the beginning. The rest of jobs arrives dynamically online.\n",
    "\n",
    "The following attempt to expand L2D to being dynamic is inspired by paper [Large-scale Dynamic Scheduling for Flexible Job-shop with Random Arrivals of New Jobs by Hierarchical Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114974), where authors schedule newly incoming jobs and reschedule not yet executed operations, already executed operations can not be rescheduled. During each rescheduling, they formulate static FJSP and solve it. They use cache for incoming jobs and an agent choosing either to add jobs from cache to scheduling problem, or keep them in cache. I will skip this agent and always add new jobs to scheduling problem.\n",
    "\n",
    "Similarly to the paper, I will model the arrival of new jobs as poisson process with average arrival time following an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49e3e4-a60e-4ef7-9d42-9730428df2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generate_arrival_times_for_jssp(instance):\n",
    "    '''Turns static JSSP instance to dynamic\n",
    "\n",
    "      Args:\n",
    "        filename of static JSSP instance\n",
    "\n",
    "      Returns:\n",
    "        list of jobs known at the beginning\n",
    "        dictionary of arriving jobs as  as {time_of_arrival: (operations, machines)} \n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "    arrival_times = np.zeros(J, dtype=int)\n",
    "\n",
    "    # calculate beta = 1/lambda\n",
    "    flattened_processor_times = [operation_time for job in processor_times for operation_time in job]\n",
    "    average_time_between_arrivals = (np.mean(flattened_processor_times) * len(processor_times[0])) / M\n",
    "    \n",
    "    # separate jobs into known jobs and arriving jobs\n",
    "    indices = np.arange(J)\n",
    "    arriving_jobs_indeces = indices[:J//2]\n",
    "    np.random.shuffle(indices)\n",
    "    t = 1\n",
    "    for index in arriving_jobs_indeces:\n",
    "        t += int(np.random.exponential(scale=average_time_between_arrivals)) + 1\n",
    "        arrival_times[index] = t\n",
    "\n",
    "    return list(arrival_times)\n",
    "\n",
    "def save_jssp_taillard(processor_times, orders_of_machines):\n",
    "    '''Saves list of jobs as static JSSP instance in taillards specification\n",
    "        \n",
    "      Args:\n",
    "        list of jobs to save\n",
    "\n",
    "      Returns:\n",
    "        filename where JSSP instance was saved to\n",
    "    '''\n",
    "    assert len(processor_times) == len(orders_of_machines), \"Processor times and machines do not have the same length\"\n",
    "    for times, machines in zip(processor_times, orders_of_machines):\n",
    "        assert len(times) == len(machines), \"Times and machines for a specific job do not have the same length\"\n",
    "        \n",
    "    J = len(processor_times)\n",
    "    M = max(max(machines) for machines in orders_of_machines)\n",
    "    \n",
    "    formatted_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    with open(f\"/tmp/{J}_{M}_{formatted_datetime}.txt\", 'w') as f:\n",
    "        f.write(f\"{J} {M}\\n\")\n",
    "        for times in processor_times:\n",
    "            f.write(\" \".join(map(str, times)) + '\\n')\n",
    "        for orders in orders_of_machines:\n",
    "            f.write(\" \".join(map(str, orders)) + '\\n')  \n",
    "\n",
    "    return f\"/tmp/{J}_{M}_{formatted_datetime}.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab9a20-616e-4629-99f7-9ddf6ba511ce",
   "metadata": {},
   "source": [
    "According to https://github.com/jolibrain/wheatley/issues/89, I was advised to model dynamic JSSP by adding a \"virtual task\" for jobs not known at the beginning, which have processing time equal to the arrival time of the job. Each virtual task is performed on a separate machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753246e2-3882-4461-a939-8a6d3ad8d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_jssp(instance, arrival_times):\n",
    "    '''Turns static JSSP into dynamic JSSP\n",
    "\n",
    "    Args:\n",
    "      instance: static JSSP instance\n",
    "      arrival_times: arrival times of jobs\n",
    "    '''\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(instance)\n",
    "\n",
    "    for index, arrival_time in enumerate(arrival_times):\n",
    "        if arrival_time == 0:\n",
    "            # job known at the start\n",
    "            continue\n",
    "\n",
    "        # add a new task with processing time equal to arrival_time\n",
    "        processor_times[index].insert(0, arrival_time)\n",
    "\n",
    "        # new task is processed on a separate machine\n",
    "        M += 1\n",
    "        orders_of_machines[index].insert(0, M)\n",
    "\n",
    "    return save_jssp_taillard(processor_times, orders_of_machines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf849b-689b-4eff-9dc7-d4cf6f96014b",
   "metadata": {},
   "source": [
    "## Dynamic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19812000-e38c-4fd5-8eb0-1782a270cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    arrival_times = generate_arrival_times_for_jssp(instance)\n",
    "    dynamic_instance = get_dynamic_jssp(instance, arrival_times)\n",
    "    J, M, _, _ = parse_instance_taillard(dynamic_instance)\n",
    "    if agent.env_specification.max_n_jobs < J:\n",
    "        continue\n",
    "\n",
    "    if agent.env_specification.max_n_machines < M:\n",
    "        continue\n",
    "        \n",
    "    static_solution = solve_instance_taillard(instance, agent)\n",
    "    print(f\"Static instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {static_solution.get_makespan()}\")\n",
    "    dynamic_solution = solve_instance_taillard(dynamic_instance, agent)\n",
    "    print(f\"Dynamic instance: {instance.split('/')[-1]}, jobs: {J}, machines: {M}, makespan: {dynamic_solution.get_makespan()}\")\n",
    "\n",
    "    # uncomment this to print schedule correctly\n",
    "    # print(f\"{arrival_times=}\")\n",
    "    # for index, arrival_time in enumerate(arrival_times):\n",
    "    #     if arrival_time > 0:    \n",
    "    #         print(arrival_time, dynamic_solution.schedule[index][1:])\n",
    "    #     else:\n",
    "    #         print(arrival_time, dynamic_solution.schedule[index])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2fe9aa-f7f3-44f2-bbf1-80ee745203ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
