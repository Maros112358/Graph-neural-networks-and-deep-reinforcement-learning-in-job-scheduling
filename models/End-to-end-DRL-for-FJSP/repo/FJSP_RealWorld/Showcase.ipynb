{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7905ef-e29f-47f2-9ccd-fde1a2a14fd5",
   "metadata": {},
   "source": [
    "# Showcase\n",
    "\n",
    "This paper uses more complicated architecture for solving ***Flexible** Job-Shop Scheduling Problem*.  This paper is a bit more technical and complicate, so I didn't dive into the details. I just tried to make the model work. There were 3 checkpoints in the official repository, but I managed to run only one of them.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "Since this model works on **FJSP**, I need to trasform our JSSP benchmarks to FJSP as in the model [fjsp-drl](/models/fjsp-drl/repo/Showcase%20fjsp-drl.ipynb). I will just reuse the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41949d9-d075-4acb-997b-9a89cd1ae66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../../benchmarks/jssp\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = np.empty((J, M), dtype=int)\n",
    "        orders_of_machines = np.empty((J, M), dtype=int)\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times[i] = list(map(int, f.readline().split()))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines[i] = list(map(int, f.readline().split()))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def jssp_taillard_to_fjsp(filename: str) -> str:\n",
    "    '''Transforms JSSP instance in Taillard's specification to FJSP instance\n",
    "       and stores it in a temporary file\n",
    "    \n",
    "      Args:\n",
    "        filename - name of the file with JSSP instance in Taillard's specification\n",
    "        \n",
    "      Returns:\n",
    "        string - filename of the equivalent FJSP instance \n",
    "    '''\n",
    "    # parse JSSP Taillard instance\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(filename)\n",
    "    \n",
    "    # convert JSSP to FJSP\n",
    "    with open(\"/tmp/fjsp_\" + filename.split(\"/\")[-1], 'w') as f:\n",
    "        # write number of jobs, number of machines, and jobs/machines (which is always 1 for JSSP)\n",
    "        f.write(str(J) + \"   \" + str(M) + \"   1\\n\")\n",
    "        \n",
    "        # each line is a job\n",
    "        for i in range(J):\n",
    "            # each line starts with the number of operations in a job\n",
    "            number_of_operations = len(processor_times[i])\n",
    "            f.write(str(number_of_operations) + \"  \")\n",
    "            \n",
    "            # print the operation as a tuple (number of available machines, current machine, processing time)\n",
    "            for j in range(number_of_operations):\n",
    "                f.write(\" 1   \" + str(orders_of_machines[i][j]) + \"   \" + str(processor_times[i][j]) + \"  \")\n",
    "                \n",
    "            f.write('\\n')\n",
    "            \n",
    "    return \"/tmp/fjsp_\" + filename.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d591c78-1b12-477c-91f1-8848e6e84060",
   "metadata": {},
   "source": [
    "The original code is a bit messy, so I had to make a small wrapper around the original code to make it nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919b2f16-caea-4f09-b48c-b291da5b0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Params import configs\n",
    "from validation_realWorld import test\n",
    "from torch.utils.data import DataLoader\n",
    "from PPOwithValue import PPO\n",
    "from DataRead import getdata\n",
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "from FJSP_Env import FJSP\n",
    "from mb_agg import g_pool_cal\n",
    "from mb_agg import *\n",
    "from copy import deepcopy\n",
    "\n",
    "def validate(vali_set,batch_size, policy_job,policy_mch,num_operation,number_of_task,Data, plan: list | None = None):\n",
    "    policy_job = copy.deepcopy(policy_job)\n",
    "    policy_mch = copy.deepcopy(policy_mch)\n",
    "    policy_job.eval()\n",
    "    policy_mch.eval()\n",
    "    def eval_model_bat(bat, plan: list | None = None):\n",
    "        actions = []\n",
    "        start_times = []\n",
    "        with torch.no_grad():\n",
    "            data = bat.numpy()\n",
    "\n",
    "            env = FJSP(n_j=Data['n'], n_m=configs.n_m,EachJob_num_operation=num_operation)\n",
    "            device = torch.device(configs.device)\n",
    "            g_pool_step = g_pool_cal(graph_pool_type=configs.graph_pool_type,\n",
    "                                     batch_size=torch.Size(\n",
    "                                         [batch_size, number_of_task, number_of_task]),\n",
    "                                     n_nodes=number_of_task,\n",
    "                                     device=device)\n",
    "\n",
    "            adj, fea, candidate, mask, mask_mch, dur, mch_time, job_time = env.reset(data)\n",
    "            first_task = []\n",
    "            pretask = []\n",
    "\n",
    "            ep_rewards = - env.initQuality\n",
    "            rewards = []\n",
    "            env_mask_mch = torch.from_numpy(np.copy(mask_mch)).to(device)\n",
    "            env_dur = torch.from_numpy(np.copy(dur)).float().to(device)\n",
    "            pool=None\n",
    "            for j in itertools.count():\n",
    "                env_adj = aggr_obs(deepcopy(adj).to(device).to_sparse(), number_of_task)\n",
    "\n",
    "                env_fea = torch.from_numpy(np.copy(fea)).float().to(device)\n",
    "                env_fea = deepcopy(env_fea).reshape(-1, env_fea.size(-1))\n",
    "                env_candidate = torch.from_numpy(np.copy(candidate)).long().to(device)\n",
    "                env_mask = torch.from_numpy(np.copy(mask)).to(device)\n",
    "                env_mch_time = torch.from_numpy(np.copy(mch_time)).float().to(device)\n",
    "                \n",
    "                if plan is not None and j < len(plan):\n",
    "                    # choose action from partial plan if possible\n",
    "                    action, a_idx, log_a, action_node, _, mask_mch_action, hx = plan[j]\n",
    "                else:\n",
    "                    # if no action was chosen from partial plan, use agent to choose\n",
    "                    action, a_idx, log_a, action_node, _, mask_mch_action, hx = policy_job(x=env_fea,\n",
    "                                                                                                   graph_pool=g_pool_step,\n",
    "                                                                                                   padded_nei=None,\n",
    "                                                                                                   adj=env_adj,\n",
    "                                                                                                   candidate=env_candidate\n",
    "                                                                                                   , mask=env_mask\n",
    "    \n",
    "                                                                                                   , mask_mch=env_mask_mch\n",
    "                                                                                                   , dur=env_dur\n",
    "                                                                                                   , a_index=0\n",
    "                                                                                                   , old_action=0\n",
    "                                                                                           , mch_pool=pool\n",
    "                                                                                                   ,old_policy=True,\n",
    "                                                                                                    T=1\n",
    "                                                                                                   ,greedy=True\n",
    "                                                                                                   )\n",
    "                actions.append((action, a_idx, log_a, action_node, _, mask_mch_action, hx))\n",
    "                pi_mch,_,pool = policy_mch(action_node, hx, mask_mch_action, env_mch_time)\n",
    "                _, mch_a = pi_mch.squeeze(-1).max(1)\n",
    "\n",
    "                if j == 0:\n",
    "                    first_task = action.type(torch.long).to(device)\n",
    "                pretask = action.type(torch.long).to(device)\n",
    "\n",
    "                # make an action\n",
    "                adj, fea, reward, done, candidate, mask,job,_,mch_time,job_time = env.step(action.cpu().numpy(), mch_a)\n",
    "\n",
    "                action = action.cpu().numpy()\n",
    "                row = np.where(action[0] <= env.last_col[0])[0][0]\n",
    "                col = action[0] - env.first_col[0][row]\n",
    "                start_times.append(env.temp1[0][row][col] - env.dur_a)\n",
    "\n",
    "                if env.done():\n",
    "                    break\n",
    "\n",
    "            cost = env.mchsEndTimes.max(-1).max(-1)\n",
    "            # assert cost[0] == cost[1], f/\"First cost and second cost are not equal {cost[0], cost[1]}\"\n",
    "        return cost[0], actions, start_times\n",
    "\n",
    "    for bat in vali_set:\n",
    "        assert torch.equal(bat[0], bat[1]), \"First and second matrix in batch are not equal\"\n",
    "        return eval_model_bat(bat, plan)\n",
    "\n",
    "def test(filepath, datafile, plan: list | None = None):\n",
    "\n",
    "    Data = getdata(datafile)\n",
    "\n",
    "    n_j = Data['n']\n",
    "    n_m = Data['m']\n",
    "\n",
    "    ppo = PPO(configs.lr, configs.gamma, configs.k_epochs, configs.eps_clip,\n",
    "                n_j=n_j,\n",
    "                n_m=n_m,\n",
    "                num_layers=configs.num_layers,\n",
    "                neighbor_pooling_type=configs.neighbor_pooling_type,\n",
    "                input_dim=configs.input_dim,\n",
    "                hidden_dim=configs.hidden_dim,\n",
    "                num_mlp_layers_feature_extract=configs.num_mlp_layers_feature_extract,\n",
    "                num_mlp_layers_actor=configs.num_mlp_layers_actor,\n",
    "                hidden_dim_actor=configs.hidden_dim_actor,\n",
    "                num_mlp_layers_critic=configs.num_mlp_layers_critic,\n",
    "                hidden_dim_critic=configs.hidden_dim_critic)\n",
    "\n",
    "    job_path = './{}.pth'.format('policy_job')\n",
    "    mch_path = './{}.pth'.format('policy_mch')\n",
    "\n",
    "    job_path = os.path.join(filepath,job_path)\n",
    "    mch_path = os.path.join(filepath, mch_path)\n",
    "\n",
    "    ppo.policy_job.load_state_dict(torch.load(job_path, map_location=torch.device('cpu')))\n",
    "    ppo.policy_mch.load_state_dict(torch.load(mch_path, map_location=torch.device('cpu')))\n",
    "\n",
    "    batch_size = 2\n",
    "    num_operations = []\n",
    "    num_operation = []\n",
    "    for i in Data['J']:\n",
    "        num_operation.append(Data['OJ'][i][-1])\n",
    "    num_operation_max = np.array(num_operation).max()\n",
    "\n",
    "    time_window = np.zeros(shape=(Data['n'], num_operation_max, Data['m']))\n",
    "\n",
    "    data_set = []\n",
    "    for i in range(Data['n']):\n",
    "        for j in Data['OJ'][i+1]:\n",
    "            mchForJob = Data['operations_machines'][(i + 1, j)]\n",
    "            for k in mchForJob:\n",
    "                time_window[i][j-1][k - 1] = Data['operations_times'][(i + 1, j, k)]\n",
    "\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        num_operations.append(num_operation)\n",
    "        data_set.append(time_window)\n",
    "    data_set = np.array(data_set)\n",
    "\n",
    "    num_operation = np.array(num_operations)\n",
    "    number_of_tasks = num_operation.sum(axis=1)[0]\n",
    "    number_of_tasks = int(number_of_tasks)\n",
    "\n",
    "    valid_loader = DataLoader(data_set, batch_size=batch_size)\n",
    "    makespan, actions, start_times = validate(valid_loader,batch_size, ppo.policy_job, ppo.policy_mch,num_operation,number_of_tasks,Data, plan)\n",
    "\n",
    "    return makespan, actions, start_times\n",
    "\n",
    "def solve_fjsp_instance(model, instance, plan: list | None = None):\n",
    "    '''Solves FJSP instance using given model\n",
    "\n",
    "    Args:\n",
    "      model - model to use for solving the instance\n",
    "      instance - instance to be solved\n",
    "      plan - preset actions to make by agent\n",
    "\n",
    "    Returns:\n",
    "      makespan of the instance,\n",
    "      actions made by agent,\n",
    "      time it took to solve the instance\n",
    "    '''\n",
    "    # get number of machines\n",
    "    with open(instance, 'r') as f:\n",
    "        M = int(f.readline().strip().split()[1])\n",
    "\n",
    "    # override the value of number of machines in the configs according to the instance \n",
    "    # this is not handled in the original code and causes errors\n",
    "    setattr(configs, 'n_m', M)\n",
    "\n",
    "    # solve the instance\n",
    "    start = time.time()\n",
    "    makespan, actions, start_times = test(model, instance, plan)\n",
    "    end = time.time()\n",
    "\n",
    "    return makespan, actions, start_times, end - start\n",
    "\n",
    "# makespan, actions, start_times, run_time = solve_fjsp_instance(\"saved_network/FJSP_J15M15/best_value0\", \"/Users/marosbratko/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/benchmarks/fjsp/0_BehnkeGeiger/Behnke1.fjs\")\n",
    "# actions = actions[:len(actions) // 2]\n",
    "# makespan, actions, start_times, run_time = solve_fjsp_instance(\"saved_network/FJSP_J15M15/best_value0\", \"/Users/marosbratko/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/benchmarks/fjsp/0_BehnkeGeiger/Behnke1.fjs\", plan=actions)\n",
    "# print(makespan, run_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f46ce20-2c1c-4fd5-afb3-6c9b82afc2f6",
   "metadata": {},
   "source": [
    "## Run the model on instances from the paper available in the official repository\n",
    "\n",
    "Only subset of instances from the paper are available in the official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660bb84d-57b8-4359-b894-456694e28a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: HurinkVdata39.fjs, makespan: 972.0, time: 0.61\n",
      "Instance: HurinkVdata40.fjs, makespan: 1030.0, time: 0.61\n",
      "Instance: HurinkVdata41.fjs, makespan: 960.0, time: 0.62\n",
      "Instance: HurinkVdata42.fjs, makespan: 988.0, time: 0.59\n",
      "Instance: HurinkVdata43.fjs, makespan: 974.0, time: 0.59\n",
      "Instance: HurinkVdata46.fjs, makespan: 524.0, time: 0.83\n",
      "Instance: HurinkVdata47.fjs, makespan: 561.0, time: 0.86\n",
      "Instance: HurinkVdata48.fjs, makespan: 555.0, time: 0.86\n"
     ]
    }
   ],
   "source": [
    "from validation_realWorld import get_imlist\n",
    "\n",
    "MODEL_PATH = 'saved_network/FJSP_J15M15/best_value0'\n",
    "INSTANCES_PATH = './FJSSPinstances/M15'\n",
    "\n",
    "for instance in sorted(get_imlist(INSTANCES_PATH)):\n",
    "    makespan, _, _, run_time = solve_fjsp_instance(MODEL_PATH, instance)\n",
    "    print(f\"Instance: {instance.split('/')[-1]}, makespan: {makespan}, time: {np.round(run_time, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80083a-127c-4be2-9293-0ad17b87151d",
   "metadata": {},
   "source": [
    "## Run the model on JSSP benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b97465-dd1d-4cf8-b55c-af0c604dce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: abz5.txt, makespan: 1382.0, time: 0.24\n",
      "Instance: abz6.txt, makespan: 1194.0, time: 0.21\n",
      "Instance: abz7.txt, makespan: 780.0, time: 0.89\n",
      "Instance: abz8.txt, makespan: 885.0, time: 0.87\n",
      "Instance: abz9.txt, makespan: 913.0, time: 0.86\n",
      "Instance: dmu01.txt, makespan: 3391.0, time: 0.88\n",
      "Instance: dmu02.txt, makespan: 3561.0, time: 0.85\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkipping\u001b[39m\u001b[38;5;124m'\u001b[39m, instance)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m makespan, _, _, run_time \u001b[38;5;241m=\u001b[39m \u001b[43msolve_fjsp_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjssp_taillard_to_fjsp\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstance\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, makespan: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmakespan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(run_time,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 184\u001b[0m, in \u001b[0;36msolve_fjsp_instance\u001b[0;34m(model, instance, plan)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# solve the instance\u001b[39;00m\n\u001b[1;32m    183\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 184\u001b[0m makespan, actions, start_times \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m makespan, actions, start_times, end \u001b[38;5;241m-\u001b[39m start\n",
      "Cell \u001b[0;32mIn[2], line 157\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(filepath, datafile, plan)\u001b[0m\n\u001b[1;32m    154\u001b[0m number_of_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(number_of_tasks)\n\u001b[1;32m    156\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(data_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m--> 157\u001b[0m makespan, actions, start_times \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_operation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumber_of_tasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43mData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m makespan, actions, start_times\n",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(vali_set, batch_size, policy_job, policy_mch, num_operation, number_of_task, Data, plan)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bat \u001b[38;5;129;01min\u001b[39;00m vali_set:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(bat[\u001b[38;5;241m0\u001b[39m], bat[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst and second matrix in batch are not equal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meval_model_bat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mvalidate.<locals>.eval_model_bat\u001b[0;34m(bat, plan)\u001b[0m\n\u001b[1;32m     55\u001b[0m     action, a_idx, log_a, action_node, _, mask_mch_action, hx \u001b[38;5;241m=\u001b[39m plan[j]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# if no action was chosen from partial plan, use agent to choose\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     action, a_idx, log_a, action_node, _, mask_mch_action, hx \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_fea\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mgraph_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg_pool_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mpadded_nei\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_adj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_candidate\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_mask\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_mch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_mask_mch\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdur\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv_dur\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                                                                           \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmch_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43mold_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                                                                                    \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m,\u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m actions\u001b[38;5;241m.\u001b[39mappend((action, a_idx, log_a, action_node, _, mask_mch_action, hx))\n\u001b[1;32m     75\u001b[0m pi_mch,_,pool \u001b[38;5;241m=\u001b[39m policy_mch(action_node, hx, mask_mch_action, env_mch_time)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/End-to-end-DRL-for-FJSP/repo/FJSP_RealWorld/models/Actor1.py:125\u001b[0m, in \u001b[0;36mJob_Actor.forward\u001b[0;34m(self, x, graph_pool, padded_nei, adj, candidate, mask, mask_mch, dur, a_index, old_action, mch_pool, old_policy, T, greedy)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    109\u001b[0m             x,\n\u001b[1;32m    110\u001b[0m             graph_pool,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m             ):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m#print('sssssssssssssssssssssss',x.size(),graph_pool.size(),padded_nei,adj.size(),candidate.size(),mask.size())\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     h_pooled, h_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mgraph_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mpadded_nei\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadded_nei\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m old_policy:\n\u001b[1;32m    131\u001b[0m         dummy \u001b[38;5;241m=\u001b[39m candidate\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_j, h_nodes\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/End-to-end-DRL-for-FJSP/repo/FJSP_RealWorld/models/Actor1.py:43\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, graph_pool, padded_nei, adj)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,graph_pool, padded_nei, adj,):\n\u001b[0;32m---> 43\u001b[0m     h_pooled, h_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mgraph_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mpadded_nei\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadded_nei\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h_pooled,h_nodes\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/End-to-end-DRL-for-FJSP/repo/FJSP_RealWorld/models/graphcnn_congForSJSSP.py:142\u001b[0m, in \u001b[0;36mGraphCNN.forward\u001b[0;34m(self, x, graph_pool, padded_nei, adj)\u001b[0m\n\u001b[1;32m    140\u001b[0m         h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_layer(h, layer, padded_neighbor_list\u001b[38;5;241m=\u001b[39mpadded_neighbor_list)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighbor_pooling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_eps:\n\u001b[0;32m--> 142\u001b[0m         h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAdj_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdj_block\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m h_nodes \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# print(graph_pool.shape, h.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/End-to-end-DRL-for-FJSP/repo/FJSP_RealWorld/models/graphcnn_congForSJSSP.py:102\u001b[0m, in \u001b[0;36mGraphCNN.next_layer\u001b[0;34m(self, h, layer, padded_neighbor_list, Adj_block)\u001b[0m\n\u001b[1;32m     97\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(h, padded_neighbor_list)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# If sum or average pooling\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# print(Adj_block.dtype)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# print(h.dtype)\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAdj_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneighbor_pooling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m# If average pooling\u001b[39;00m\n\u001b[1;32m    105\u001b[0m         degree \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(Adj_block, torch\u001b[38;5;241m.\u001b[39mones((Adj_block\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'saved_network/FJSP_J15M15/best_value0'\n",
    "\n",
    "exceptions = [\n",
    "    '../../../../benchmarks/jssp/orb_instances/Taillard_specification/orb07.txt' # this instance gets stuck while solving, I haven't figured out why\n",
    "]\n",
    "\n",
    "for instance in sorted(get_all_instances_in_taillard_specification()):\n",
    "    if instance in exceptions:\n",
    "        print('Skipping', instance)\n",
    "        continue\n",
    "\n",
    "    makespan, _, _, run_time = solve_fjsp_instance(MODEL_PATH, jssp_taillard_to_fjsp(instance))\n",
    "    print(f\"Instance: {instance.split('/')[-1]}, makespan: {makespan}, time: {np.round(run_time, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6511a-ce3b-4a82-b5e5-7a9308182e90",
   "metadata": {},
   "source": [
    "# Run the model on FJSP benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf69f09-9891-4d5f-b521-f03f8288be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_fjsp_instances():\n",
    "    '''Lists all FJSP instances'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../../benchmarks/fjsp\"\n",
    "    target_string = \".fjs\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f3ebb5-7586-444e-9568-91201297acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: Behnke1.fjs, makespan: 110.0, time: 0.14\n",
      "Instance: Behnke10.fjs, makespan: 163.0, time: 0.25\n",
      "Instance: Behnke11.fjs, makespan: 284.0, time: 1.1\n",
      "Instance: Behnke12.fjs, makespan: 277.0, time: 1.11\n",
      "Instance: Behnke13.fjs, makespan: 306.0, time: 1.06\n",
      "Instance: Behnke14.fjs, makespan: 303.0, time: 1.04\n",
      "Instance: Behnke15.fjs, makespan: 292.0, time: 1.06\n",
      "Instance: Behnke16.fjs, makespan: 514.0, time: 5.19\n",
      "Instance: Behnke17.fjs, makespan: 491.0, time: 5.21\n",
      "Instance: Behnke18.fjs, makespan: 500.0, time: 5.21\n",
      "Instance: Behnke19.fjs, makespan: 504.0, time: 5.45\n",
      "Instance: Behnke2.fjs, makespan: 110.0, time: 0.12\n",
      "Instance: Behnke20.fjs, makespan: 496.0, time: 5.41\n",
      "Instance: Behnke21.fjs, makespan: 105.0, time: 0.13\n",
      "Instance: Behnke22.fjs, makespan: 107.0, time: 0.13\n",
      "Instance: Behnke23.fjs, makespan: 106.0, time: 0.13\n",
      "Instance: Behnke24.fjs, makespan: 108.0, time: 0.13\n",
      "Instance: Behnke25.fjs, makespan: 96.0, time: 0.13\n",
      "Instance: Behnke26.fjs, makespan: 150.0, time: 0.29\n",
      "Instance: Behnke27.fjs, makespan: 155.0, time: 0.31\n",
      "Instance: Behnke28.fjs, makespan: 138.0, time: 0.29\n",
      "Instance: Behnke29.fjs, makespan: 147.0, time: 0.29\n",
      "Instance: Behnke3.fjs, makespan: 128.0, time: 0.11\n",
      "Instance: Behnke30.fjs, makespan: 145.0, time: 0.3\n",
      "Instance: Behnke31.fjs, makespan: 279.0, time: 1.21\n",
      "Instance: Behnke32.fjs, makespan: 272.0, time: 1.22\n",
      "Instance: Behnke33.fjs, makespan: 262.0, time: 1.18\n",
      "Instance: Behnke34.fjs, makespan: 272.0, time: 1.21\n",
      "Instance: Behnke35.fjs, makespan: 244.0, time: 1.27\n",
      "Instance: Behnke36.fjs, makespan: 471.0, time: 5.59\n",
      "Instance: Behnke37.fjs, makespan: 476.0, time: 5.29\n",
      "Instance: Behnke38.fjs, makespan: 472.0, time: 5.25\n",
      "Instance: Behnke39.fjs, makespan: 466.0, time: 5.27\n",
      "Instance: Behnke4.fjs, makespan: 131.0, time: 0.11\n",
      "Instance: Behnke40.fjs, makespan: 489.0, time: 5.02\n",
      "Instance: Behnke41.fjs, makespan: 99.0, time: 0.14\n",
      "Instance: Behnke42.fjs, makespan: 104.0, time: 0.14\n",
      "Instance: Behnke43.fjs, makespan: 102.0, time: 0.14\n",
      "Instance: Behnke44.fjs, makespan: 92.0, time: 0.14\n",
      "Instance: Behnke45.fjs, makespan: 111.0, time: 0.14\n",
      "Instance: Behnke46.fjs, makespan: 143.0, time: 0.33\n",
      "Instance: Behnke47.fjs, makespan: 149.0, time: 0.34\n",
      "Instance: Behnke48.fjs, makespan: 159.0, time: 0.33\n",
      "Instance: Behnke49.fjs, makespan: 145.0, time: 0.32\n",
      "Instance: Behnke5.fjs, makespan: 108.0, time: 0.11\n",
      "Instance: Behnke50.fjs, makespan: 169.0, time: 0.34\n",
      "Instance: Behnke51.fjs, makespan: 254.0, time: 1.33\n",
      "Instance: Behnke52.fjs, makespan: 248.0, time: 1.3\n",
      "Instance: Behnke53.fjs, makespan: 268.0, time: 1.32\n",
      "Instance: Behnke54.fjs, makespan: 276.0, time: 1.31\n",
      "Instance: Behnke55.fjs, makespan: 271.0, time: 1.29\n",
      "Instance: Behnke56.fjs, makespan: 471.0, time: 5.84\n",
      "Instance: Behnke57.fjs, makespan: 482.0, time: 5.69\n",
      "Instance: Behnke58.fjs, makespan: 471.0, time: 5.49\n",
      "Instance: Behnke59.fjs, makespan: 460.0, time: 5.61\n",
      "Instance: Behnke6.fjs, makespan: 163.0, time: 0.26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(get_all_fjsp_instances()):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m         makespan, _, _, run_time \u001b[38;5;241m=\u001b[39m \u001b[43msolve_fjsp_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstance\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, makespan: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmakespan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mround(run_time,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[2], line 184\u001b[0m, in \u001b[0;36msolve_fjsp_instance\u001b[0;34m(model, instance, plan)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# solve the instance\u001b[39;00m\n\u001b[1;32m    183\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 184\u001b[0m makespan, actions, start_times \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m makespan, actions, start_times, end \u001b[38;5;241m-\u001b[39m start\n",
      "Cell \u001b[0;32mIn[2], line 157\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(filepath, datafile, plan)\u001b[0m\n\u001b[1;32m    154\u001b[0m number_of_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(number_of_tasks)\n\u001b[1;32m    156\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(data_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m--> 157\u001b[0m makespan, actions, start_times \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_operation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumber_of_tasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43mData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m makespan, actions, start_times\n",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(vali_set, batch_size, policy_job, policy_mch, num_operation, number_of_task, Data, plan)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bat \u001b[38;5;129;01min\u001b[39;00m vali_set:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mequal(bat[\u001b[38;5;241m0\u001b[39m], bat[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst and second matrix in batch are not equal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meval_model_bat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m, in \u001b[0;36mvalidate.<locals>.eval_model_bat\u001b[0;34m(bat, plan)\u001b[0m\n\u001b[1;32m     80\u001b[0m pretask \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# make an action\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m adj, fea, reward, done, candidate, mask,job,_,mch_time,job_time \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmch_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     86\u001b[0m row \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(action[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mlast_col[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/End-to-end-DRL-for-FJSP/repo/FJSP_RealWorld/FJSP_Env.py:125\u001b[0m, in \u001b[0;36mFJSP.step\u001b[0;34m(self, action, mch_a)\u001b[0m\n\u001b[1;32m    118\u001b[0m     mask1, mch_mask \u001b[38;5;241m=\u001b[39m DRs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmch_time[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_time[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmchsEndTimes[i],\n\u001b[1;32m    119\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_machines, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdur_cp[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp1[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39momega[i],\n\u001b[1;32m    120\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[i], done, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_mch[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_operation[i],\n\u001b[1;32m    121\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatched_num_opera[i],\n\u001b[1;32m    122\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_min[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_col[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_max[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrule,\n\u001b[1;32m    123\u001b[0m                           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_col[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_col[i])\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     mch_space, mchForJobSpace, mask1, mch_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmin_job_mch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmch_time\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_time\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmchsEndTimes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_machines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdur_cp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43momega\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_mch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_col\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_col\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m masks\u001b[38;5;241m.\u001b[39mappend(mask1)\n\u001b[1;32m    131\u001b[0m mch_masks\u001b[38;5;241m.\u001b[39mappend(mch_mask)\n",
      "File \u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/End-to-end-DRL-for-FJSP/repo/FJSP_RealWorld/min_job_machine_time.py:87\u001b[0m, in \u001b[0;36mmin_job_mch\u001b[0;34m(mch_time, job_time, mchsEndTimes, number_of_machines, dur, temp, omega, mask_last, done, mask_mch, first_col, last_col)\u001b[0m\n\u001b[1;32m     85\u001b[0m mchFor_minTask \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m min_task:\n\u001b[0;32m---> 87\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_col\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m     col \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m-\u001b[39m first_col[row]\n\u001b[1;32m     89\u001b[0m     mch_for_job \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(dur[row, col] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/end-to-end-drl-for-fjsp-cBOGAF6U-py3.10/lib/python3.10/site-packages/numpy/core/multiarray.py:346\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    inner(a, b, /)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mwhere)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwhere\u001b[39m(condition, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'saved_network/FJSP_J15M15/best_value0'\n",
    "\n",
    "for instance in sorted(get_all_fjsp_instances()):\n",
    "    try:\n",
    "        makespan, _, _, run_time = solve_fjsp_instance(MODEL_PATH, instance)\n",
    "        print(f\"Instance: {instance.split('/')[-1]}, makespan: {makespan}, time: {np.round(run_time, 2)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to solve instance {instance}, error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b91f2-c99b-48c1-8617-9265d1cecaef",
   "metadata": {},
   "source": [
    "# Dynamic FJSP\n",
    "\n",
    "In dynamic FJSP, only a subset of jobs is known at the beginning. The rest of jobs arrives dynamically online.\n",
    "\n",
    "The following attempt to expand this model to being dynamic is inspired by paper [Large-scale Dynamic Scheduling for Flexible Job-shop with Random Arrivals of New Jobs by Hierarchical Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10114974&tag=1), where authors schedule newly incoming jobs and reschedule not yet executed operations, already executed operations can not be rescheduled. During each rescheduling, they formulate static FJSP and solve it. They use cache for incoming jobs and an agent choosing either to add jobs from cache to scheduling problem, or keep them in cache. I will skip this agent and always add new jobs to scheduling problem.\n",
    "\n",
    "Similarly to the paper, I will model the arrival of new jobs as poisson process with average arrival time following an exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282abe4-7d07-4c9f-9d3f-0443ee346723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_dynamic_fjsp(instance):\n",
    "    '''Turns static FJSP instance to dynamic\n",
    "\n",
    "      Args:\n",
    "        filename of static FJSP instance\n",
    "\n",
    "      Returns:\n",
    "        list of jobs known at the beginning\n",
    "        dictionary of arriving jobs as  as {time_of_arrival: (operations, machines)} \n",
    "    '''\n",
    "    # get number of jobs and average time per operation from \n",
    "    total_time_of_operations = 0\n",
    "    number_of_operations = 0\n",
    "    number_of_operations_per_job = []\n",
    "    jobs = []\n",
    "    with open(instance, 'r') as f:\n",
    "        J, M = list(map(lambda o: int(o), f.readline().removesuffix('\\n').split()[:2]))\n",
    "\n",
    "        for line in f:\n",
    "            jobs.append(line.removesuffix('\\n'))\n",
    "            number_of_operations_per_job.append(int(line[0]))\n",
    "            line = line.split()[1:]\n",
    "\n",
    "            while line:\n",
    "                # get number of available machines for operation\n",
    "                number_of_machines_for_current_operation = int(line[0])\n",
    "                number_of_operations += number_of_machines_for_current_operation\n",
    "\n",
    "                # get possible durations of operation\n",
    "                current_operation = list(map(lambda arg: int(arg), line[1:1+number_of_machines_for_current_operation*2]))\n",
    "                total_time_of_operations += sum(current_operation[1::2])\n",
    "\n",
    "                # move to next operation\n",
    "                line = line[1+number_of_machines_for_current_operation*2:]\n",
    "\n",
    "    # calculate average time between arrivals (beta=1/lambda)\n",
    "    average_operation_duration = total_time_of_operations // number_of_operations\n",
    "    average_time_between_arrivals = average_operation_duration * sum(number_of_operations_per_job) / len(number_of_operations_per_job) / M\n",
    "\n",
    "    # shuffle jobs\n",
    "    indices = np.arange(J)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # # separate jobs into known jobs and arriving jobs\n",
    "    jobs_known_at_the_beginning = [jobs[index] for index in indices[J//2:]]\n",
    "    arriving_jobs_indeces = indices[:J//2]\n",
    "\n",
    "    # create arriving jobs\n",
    "    t = 0\n",
    "    arriving_jobs = {}\n",
    "    for index in arriving_jobs_indeces:\n",
    "        t += int(np.random.exponential(scale=average_time_between_arrivals))\n",
    "        arriving_jobs[t] = jobs[index]\n",
    "\n",
    "    return jobs_known_at_the_beginning, arriving_jobs, M\n",
    "\n",
    "def save_static_fjsp(jobs, number_of_machines):\n",
    "    '''Saves list of jobs as static FJSP instance\n",
    "        \n",
    "      Args:\n",
    "        list of jobs to save\n",
    "        number of machines in instance\n",
    "\n",
    "      Returns:\n",
    "        filename where JSSP instance was saved to\n",
    "    '''\n",
    "    J, M = len(jobs), number_of_machines\n",
    "    formatted_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    with open(f\"/tmp/{J}_{M}_{formatted_datetime}.txt\", 'w') as f:\n",
    "        f.write(f\"{J} {M} 0\\n\")\n",
    "        for job in jobs:\n",
    "            f.write(job + '\\n') \n",
    "\n",
    "    return f\"/tmp/{J}_{M}_{formatted_datetime}.txt\"\n",
    "\n",
    "# jobs_known_at_the_beginning, arriving_jobs, number_of_machines = get_dynamic_fjsp('/Users/marosbratko/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/benchmarks/fjsp/0_BehnkeGeiger/Behnke1.fjs')\n",
    "# instance = save_static_fjsp(jobs_known_at_the_beginning, number_of_machines)\n",
    "# print(instance)\n",
    "# a, b, c, d = solve_fjsp_instance(\"saved_network/FJSP_J15M15/best_value0\", instance)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8db74c-4bc6-4e40-977a-4fa3e93a8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_dynamic_fjsp(model, instance):\n",
    "    '''Turns static FJSP instance to dynamic and solves it\n",
    "\n",
    "      Args: \n",
    "        model to use\n",
    "        instance to solve\n",
    "\n",
    "      Returns: \n",
    "        makespan, run\n",
    "    '''\n",
    "    # turn static JSSP instance to dynamic\n",
    "    known_jobs, arriving_jobs, number_of_machines = get_dynamic_fjsp(instance)\n",
    "    print(f\"instance={instance.split('/')[-1]}, known_jobs={len(known_jobs)}, arriving_jobs={len(arriving_jobs)}\")\n",
    "    latest_time_of_arrival = max(arriving_jobs)\n",
    "    print(f\"Latest job arrives at {latest_time_of_arrival}\")\n",
    "    \n",
    "    # solve static JSSP with jobs known initially\n",
    "    makespan, actions, start_times, _ = solve_fjsp_instance(model, save_static_fjsp(known_jobs, number_of_machines))\n",
    "    t = 0\n",
    "    while True:\n",
    "        t += 1\n",
    "        \n",
    "        # no jobs left\n",
    "        if not arriving_jobs:\n",
    "            break\n",
    "    \n",
    "        # no job arrived\n",
    "        if not t in arriving_jobs:\n",
    "            continue\n",
    "    \n",
    "        # new job arrived, remove not yet executed operations from the plan\n",
    "        partial_plan = []\n",
    "        flag = False\n",
    "        for action, start_time in zip(reversed(actions), reversed(start_times)):\n",
    "            if start_time < t:\n",
    "                flag = True\n",
    "\n",
    "            if flag:\n",
    "                partial_plan.append(action)\n",
    "\n",
    "        partial_plan = list(reversed(partial_plan))\n",
    "        # add new job to the plan, with times shifted to current time t\n",
    "        new_job = arriving_jobs.pop(t)\n",
    "        known_jobs.append(new_job)\n",
    "        \n",
    "        # create new schedule WHILE REUSING THE ALREADY EXECUTED PLAN\n",
    "        makespan, actions, start_times, _ = solve_fjsp_instance(model, save_static_fjsp(known_jobs, number_of_machines), plan=partial_plan)\n",
    "    return makespan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe195fb-f932-4a8f-b2dd-d5aa044944d7",
   "metadata": {},
   "source": [
    "# Dynamic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51691304-00a9-4f82-99fb-4ba58fa8831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'saved_network/FJSP_J15M15/best_value0'\n",
    "\n",
    "for instance in sorted(get_all_fjsp_instances())[:10]:\n",
    "    try:\n",
    "        makespan = solve_dynamic_fjsp(MODEL_PATH, instance)\n",
    "        print(f\"Instance: {instance.split('/')[-1]}, makespan: {makespan}, time: {np.round(run_time, 2)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to solve instance {instance}, error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813490be-1e16-4388-bd31-79e101c6d01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
