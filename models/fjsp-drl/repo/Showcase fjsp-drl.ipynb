{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5ff412",
   "metadata": {},
   "source": [
    "# Showcase of fjsp-drl\n",
    "\n",
    "This model requires python 3.6 and package versions in `requirements.txt`.\n",
    "This model solves FJSP instances, which are a generalisation of JSSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cdad435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, json, PPO_model, copy, os, gym, time\n",
    "import numpy as np\n",
    "from env.load_data import nums_detec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77b2ad",
   "metadata": {},
   "source": [
    "# JSSP TO FJSP\n",
    "First I need to convert JSSP to FJSP instance. Below is an example of JSSP instance in [Taillard's specification](http://jobshop.jjvh.nl/explanation.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764dff9e",
   "metadata": {},
   "source": [
    "```\n",
    "6\t6\n",
    "1\t3\t6\t7\t3\t6\n",
    "8\t5\t10\t10\t10\t4\n",
    "5\t4\t8\t9\t1\t7\n",
    "5\t5\t5\t3\t8\t9\n",
    "9\t3\t5\t4\t3\t1\n",
    "3\t3\t9\t10\t4\t1\n",
    "3\t1\t2\t4\t6\t5\n",
    "2\t3\t5\t6\t1\t4\n",
    "3\t4\t6\t1\t2\t5\n",
    "2\t1\t3\t4\t5\t6\n",
    "3\t2\t5\t6\t1\t4\n",
    "2\t4\t6\t1\t5\t3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acaa30d",
   "metadata": {},
   "source": [
    "Below is the same problem as [FJSP](https://people.idsia.ch/~monaldo/fjsp.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e3adf",
   "metadata": {},
   "source": [
    "```\n",
    "6   6   1   \n",
    "6   1   3   1   1   1   3   1   2   6   1   4   7   1   6   3   1   5   6   \n",
    "6   1   2   8   1   3   5   1   5   10  1   6   10  1   1   10  1   4   4   \n",
    "6   1   3   5   1   4   4   1   6   8   1   1   9   1   2   1   1   5   7   \n",
    "6   1   2   5   1   1   5   1   3   5   1   4   3   1   5   8   1   6   9   \n",
    "6   1   3   9   1   2   3   1   5   5   1   6   4   1   1   3   1   4   1   \n",
    "6   1   2   3   1   4   3   1   6   9   1   1   10  1   5   4   1   3   1   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fada63",
   "metadata": {},
   "source": [
    "Helper functions to convert JSSP to FJSP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d578c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instance_taillard(filename):\n",
    "    '''Parses instance written in Taillard specification: http://jobshop.jjvh.nl/explanation.php\n",
    "    \n",
    "      Args:\n",
    "        filename - file containing the instance in Taillard specification\n",
    "\n",
    "      Returns:\n",
    "        number of jobs,\n",
    "        number of machines,\n",
    "        the processor times for each operation,\n",
    "        the order for visiting the machines\n",
    "    '''\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        # parse number of jobs J and machines M\n",
    "        J, M = map(int, f.readline().split())\n",
    "\n",
    "        # Initialize two empty numpy arrays with dimensions J x M\n",
    "        processor_times = np.empty((J, M), dtype=int)\n",
    "        orders_of_machines = np.empty((J, M), dtype=int)\n",
    "    \n",
    "        # Read the next J lines containing processor times\n",
    "        for i in range(J):\n",
    "            processor_times[i] = list(map(int, f.readline().split()))\n",
    "    \n",
    "        # Read the next J lines containing orders of machines\n",
    "        for i in range(J):\n",
    "            orders_of_machines[i] = list(map(int, f.readline().split()))\n",
    "\n",
    "        return J, M, processor_times, orders_of_machines\n",
    "\n",
    "def jssp_taillard_to_fjsp(filename: str) -> str:\n",
    "    '''Transforms JSSP instance in Taillard's specification to FJSP instance\n",
    "       and stores it in a temporary file\n",
    "    \n",
    "      Args:\n",
    "        filename - name of the file with JSSP instance in Taillard's specification\n",
    "        \n",
    "      Returns:\n",
    "        string - filename of the equivalent FJSP instance \n",
    "    '''\n",
    "    # parse JSSP Taillard instance\n",
    "    J, M, processor_times, orders_of_machines = parse_instance_taillard(filename)\n",
    "    \n",
    "    # convert JSSP to FJSP\n",
    "    with open(\"/tmp/fjsp_\" + filename.split(\"/\")[-1], 'w') as f:\n",
    "        # write number of jobs, number of machines, and jobs/machines (which is always 1 for JSSP)\n",
    "        f.write(str(J) + \"   \" + str(M) + \"   1\\n\")\n",
    "        \n",
    "        # each line is a job\n",
    "        for i in range(J):\n",
    "            # each line starts with the number of operations in a job\n",
    "            number_of_operations = len(processor_times[i])\n",
    "            f.write(str(number_of_operations) + \"  \")\n",
    "            \n",
    "            # print the operation as a tuple (number of available machines, current machine, processing time)\n",
    "            for j in range(number_of_operations):\n",
    "                f.write(\" 1   \" + str(orders_of_machines[i][j]) + \"   \" + str(processor_times[i][j]) + \"  \")\n",
    "                \n",
    "            f.write('\\n')\n",
    "            \n",
    "    return \"/tmp/fjsp_\" + filename.split(\"/\")[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa2a27",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4d1ec",
   "metadata": {},
   "source": [
    "## Model setup\n",
    "\n",
    "Setup torch, load the configuration of the experiment prepare the model and load its parameters from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf780cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type=='cuda':\n",
    "    torch.cuda.set_device(device)\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    \n",
    "# load configuration of the experiment\n",
    "with open(\"./config.json\", 'r') as load_f:\n",
    "    load_dict = json.load(load_f)\n",
    "    \n",
    "model_paras = load_dict['model_paras']\n",
    "model_paras[\"actor_in_dim\"] = model_paras[\"out_size_ma\"] * 2 + model_paras[\"out_size_ope\"] * 2\n",
    "model_paras[\"critic_in_dim\"] = model_paras[\"out_size_ma\"] + model_paras[\"out_size_ope\"]\n",
    "model_paras['device'] = device\n",
    "env_paras = load_dict['env_paras']\n",
    "env_paras['device'] = device\n",
    "env_paras['batch_size'] = 1\n",
    "\n",
    "# create model and its parameters from the checkpoint\n",
    "memories = PPO_model.Memory()\n",
    "model_CKPT = torch.load('./model/save_10_5.pt')\n",
    "model = PPO_model.PPO(model_paras, load_dict['train_paras'])\n",
    "model.policy.load_state_dict(model_CKPT)\n",
    "model.policy_old.load_state_dict(model_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7275c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_instance(instance_file, model, memories, flag_sample=False):\n",
    "    '''Solves FJSP instance using given model and memories\n",
    "    \n",
    "      Args:\n",
    "          instance_file - name of the file with the FJSP instance\n",
    "          model - model used to solve the instance\n",
    "          memories - model's memories\n",
    "    \n",
    "      Returns:\n",
    "          makespan and time it took to solve the instance\n",
    "    '''\n",
    "    with open(instance_file, 'r') as file_object:\n",
    "        # load the parameters of the instance\n",
    "        line = file_object.readlines()\n",
    "        ins_num_jobs, ins_num_mas, _ = nums_detec(line)\n",
    "        env_paras[\"num_jobs\"] = ins_num_jobs\n",
    "        env_paras[\"num_mas\"] = ins_num_mas\n",
    "        \n",
    "        # create env and get states and completion signal\n",
    "        env = gym.make('fjsp-v0', case=[instance_file], env_paras=env_paras, data_source='file')\n",
    "        state = env.state\n",
    "        dones = env.done_batch\n",
    "        done = False  # Unfinished at the beginning\n",
    "        \n",
    "        # perform scheduling\n",
    "        start = time.time()\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                actions = model.policy_old.act(state, memories, dones, flag_sample=flag_sample, flag_train=False)\n",
    "            state, rewards, dones = env.step(actions)  # environment transit\n",
    "            done = dones.all()\n",
    "        run_time = time.time() - start  # The time taken to solve this environment (instance)\n",
    "\n",
    "        gantt_result = env.validate_gantt()[0]\n",
    "        if not gantt_result:\n",
    "            raise Exception(\"Scheduling error\")\n",
    "\n",
    "        return copy.deepcopy(env.makespan_batch), run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f50ef3",
   "metadata": {},
   "source": [
    "## FJSP instances from the paper\n",
    "\n",
    "Run the experiment on some instances from this paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6faebac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makespan of Mk01.fjs : 43.0\n",
      "Makespan of Mk02.fjs : 38.0\n",
      "Makespan of Mk03.fjs : 204.0\n",
      "Makespan of Mk04.fjs : 81.0\n",
      "Makespan of Mk05.fjs : 192.0\n",
      "Makespan of Mk06.fjs : 99.0\n",
      "Makespan of Mk07.fjs : 221.0\n",
      "Makespan of Mk08.fjs : 529.0\n",
      "Makespan of Mk09.fjs : 339.0\n",
      "Makespan of Mk10.fjs : 264.0\n"
     ]
    }
   ],
   "source": [
    "TEST_FILES_PATH = \"data_test/Public/\"\n",
    "test_files = sorted(os.listdir(TEST_FILES_PATH))\n",
    "for file in test_files[:10]:\n",
    "    makespan, _ = solve_instance(TEST_FILES_PATH + file, model, memories)\n",
    "    print(\"Makespan of\", file, \":\", makespan.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca39174",
   "metadata": {},
   "source": [
    "## JSSP instances from our benchmarks\n",
    "\n",
    "Run the experiment on our benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b41721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_instances_in_taillard_specification():\n",
    "    '''Lists all instances in Taillard specification'''\n",
    "    matching_files = []\n",
    "    root_dir = \"../../../benchmarks/\"\n",
    "    target_string = \"Taillard_specification\"\n",
    "\n",
    "    for foldername, subfolders, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(foldername, filename)\n",
    "            if target_string in filepath:\n",
    "                matching_files.append(filepath)\n",
    "\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6987fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makespan of yn03.txt : 1073.0\n",
      "Makespan of yn02.txt : 1043.0\n",
      "Makespan of yn01.txt : 1032.0\n",
      "Makespan of yn04.txt : 1247.0\n",
      "Makespan of swv14.txt : 3955.0\n",
      "Makespan of swv18.txt : 2852.0\n",
      "Makespan of swv20.txt : 2823.0\n",
      "Makespan of swv17.txt : 2794.0\n",
      "Makespan of swv19.txt : 3009.0\n",
      "Makespan of swv08.txt : 2401.0\n",
      "Makespan of swv02.txt : 2098.0\n",
      "Makespan of swv05.txt : 1842.0\n",
      "Makespan of swv12.txt : 4036.0\n",
      "Makespan of swv01.txt : 1971.0\n",
      "Makespan of swv06.txt : 2100.0\n",
      "Makespan of swv11.txt : 3961.0\n",
      "Makespan of swv13.txt : 4316.0\n",
      "Makespan of swv03.txt : 1919.0\n",
      "Makespan of swv07.txt : 2070.0\n",
      "Makespan of swv09.txt : 2216.0\n",
      "Makespan of swv04.txt : 1905.0\n",
      "Makespan of swv15.txt : 3903.0\n",
      "Makespan of swv10.txt : 2297.0\n",
      "Makespan of swv16.txt : 2924.0\n",
      "Makespan of ta32.txt : 2160.0\n",
      "Makespan of ta11.txt : 1629.0\n",
      "Makespan of ta79.txt : 5539.0\n",
      "Makespan of ta60.txt : 3014.0\n",
      "Makespan of ta28.txt : 1886.0\n",
      "Makespan of ta56.txt : 3151.0\n",
      "Makespan of ta65.txt : 3218.0\n",
      "Makespan of ta43.txt : 2341.0\n",
      "Makespan of ta40.txt : 2025.0\n",
      "Makespan of ta24.txt : 1987.0\n",
      "Makespan of ta52.txt : 3334.0\n",
      "Makespan of ta12.txt : 1608.0\n",
      "Makespan of ta61.txt : 3340.0\n",
      "Makespan of ta73.txt : 5893.0\n",
      "Makespan of ta63.txt : 3104.0\n",
      "Makespan of ta22.txt : 1848.0\n",
      "Makespan of ta70.txt : 3434.0\n",
      "Makespan of ta49.txt : 2440.0\n",
      "Makespan of ta29.txt : 1978.0\n",
      "Makespan of ta18.txt : 1703.0\n",
      "Makespan of ta68.txt : 3151.0\n",
      "Makespan of ta06.txt : 1368.0\n",
      "Makespan of ta33.txt : 2311.0\n",
      "Makespan of ta72.txt : 5561.0\n",
      "Makespan of ta30.txt : 1926.0\n",
      "Makespan of ta09.txt : 1553.0\n",
      "Makespan of ta14.txt : 1632.0\n",
      "Makespan of ta46.txt : 2348.0\n",
      "Makespan of ta23.txt : 1838.0\n",
      "Makespan of ta66.txt : 3318.0\n",
      "Makespan of ta36.txt : 2259.0\n",
      "Makespan of ta37.txt : 2031.0\n",
      "Makespan of ta69.txt : 3409.0\n",
      "Makespan of ta02.txt : 1472.0\n",
      "Makespan of ta54.txt : 3066.0\n",
      "Makespan of ta01.txt : 1462.0\n",
      "Makespan of ta75.txt : 6059.0\n",
      "Makespan of ta17.txt : 1861.0\n",
      "Makespan of ta71.txt : 5881.0\n",
      "Makespan of ta07.txt : 1374.0\n",
      "Makespan of ta20.txt : 1628.0\n",
      "Makespan of ta45.txt : 2418.0\n",
      "Makespan of ta16.txt : 1632.0\n",
      "Makespan of ta15.txt : 1691.0\n",
      "Makespan of ta25.txt : 1980.0\n",
      "Makespan of ta55.txt : 3126.0\n",
      "Makespan of ta50.txt : 2378.0\n",
      "Makespan of ta53.txt : 3056.0\n",
      "Makespan of ta39.txt : 2186.0\n",
      "Makespan of ta38.txt : 1995.0\n",
      "Makespan of ta78.txt : 5727.0\n",
      "Makespan of ta26.txt : 1918.0\n",
      "Makespan of ta21.txt : 1995.0\n",
      "Makespan of ta05.txt : 1384.0\n",
      "Makespan of ta47.txt : 2322.0\n",
      "Makespan of ta51.txt : 3355.0\n",
      "Makespan of ta58.txt : 3250.0\n",
      "Makespan of ta48.txt : 2355.0\n",
      "Makespan of ta57.txt : 3184.0\n",
      "Makespan of ta64.txt : 3072.0\n",
      "Makespan of ta19.txt : 1635.0\n",
      "Makespan of ta10.txt : 1445.0\n",
      "Makespan of ta31.txt : 2200.0\n",
      "Makespan of ta44.txt : 2381.0\n",
      "Makespan of ta74.txt : 5544.0\n",
      "Makespan of ta77.txt : 5602.0\n",
      "Makespan of ta04.txt : 1403.0\n",
      "Makespan of ta42.txt : 2398.0\n",
      "Makespan of ta59.txt : 3056.0\n",
      "Makespan of ta08.txt : 1448.0\n",
      "Makespan of ta41.txt : 2464.0\n",
      "Makespan of ta34.txt : 2160.0\n",
      "Makespan of ta80.txt : 5530.0\n",
      "Makespan of ta03.txt : 1440.0\n",
      "Makespan of ta27.txt : 2084.0\n",
      "Makespan of ta62.txt : 3382.0\n",
      "Makespan of ta76.txt : 5755.0\n",
      "Makespan of ta13.txt : 1667.0\n",
      "Makespan of ta35.txt : 2159.0\n",
      "Makespan of ta67.txt : 3277.0\n",
      "Makespan of ft20.txt : 1519.0\n",
      "Makespan of ft10.txt : 1136.0\n",
      "Makespan of ft06.txt : 59.0\n",
      "Makespan of la13.txt : 1150.0\n",
      "Makespan of la05.txt : 593.0\n",
      "Makespan of la10.txt : 958.0\n",
      "Makespan of la36.txt : 1508.0\n",
      "Makespan of la30.txt : 1483.0\n",
      "Makespan of la02.txt : 835.0\n",
      "Makespan of la34.txt : 1809.0\n",
      "Makespan of la01.txt : 706.0\n",
      "Makespan of la07.txt : 973.0\n",
      "Makespan of la37.txt : 1657.0\n",
      "Makespan of la35.txt : 2014.0\n",
      "Makespan of la09.txt : 951.0\n",
      "Makespan of la31.txt : 1784.0\n",
      "Makespan of la14.txt : 1292.0\n",
      "Makespan of la22.txt : 1061.0\n",
      "Makespan of la19.txt : 950.0\n",
      "Makespan of la39.txt : 1472.0\n",
      "Makespan of la16.txt : 1073.0\n",
      "Makespan of la23.txt : 1162.0\n",
      "Makespan of la12.txt : 1050.0\n",
      "Makespan of la17.txt : 846.0\n",
      "Makespan of la32.txt : 1911.0\n",
      "Makespan of la24.txt : 1100.0\n",
      "Makespan of la38.txt : 1444.0\n",
      "Makespan of la26.txt : 1426.0\n",
      "Makespan of la08.txt : 906.0\n",
      "Makespan of la18.txt : 1003.0\n",
      "Makespan of la11.txt : 1222.0\n",
      "Makespan of la25.txt : 1127.0\n",
      "Makespan of la03.txt : 696.0\n",
      "Makespan of la40.txt : 1447.0\n",
      "Makespan of la27.txt : 1491.0\n",
      "Makespan of la06.txt : 926.0\n",
      "Makespan of la15.txt : 1250.0\n",
      "Makespan of la33.txt : 1838.0\n",
      "Makespan of la20.txt : 999.0\n",
      "Makespan of la28.txt : 1444.0\n",
      "Makespan of la21.txt : 1213.0\n",
      "Makespan of la29.txt : 1320.0\n",
      "Makespan of la04.txt : 724.0\n",
      "Makespan of orb08.txt : 1194.0\n",
      "Makespan of orb01.txt : 1281.0\n",
      "Makespan of orb04.txt : 1133.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d2d95e448741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfjsp_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjssp_taillard_to_fjsp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmakespan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfjsp_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Makespan of\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmakespan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b4978857c46c>\u001b[0m in \u001b[0;36msolve_instance\u001b[0;34m(instance_file, model, memories, flag_sample)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflag_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# environment transit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m  \u001b[0;31m# The time taken to solve this environment (instance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/fjsp-drl/fjsp-drl/env/fjsp_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mflag_trans_2_next_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_no_eligible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag_trans_2_next_time\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag_trans_2_next_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0mflag_trans_2_next_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_no_eligible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Graph-neural-networks-and-deep-reinforcement-learning-in-job-scheduling/models/fjsp-drl/fjsp-drl/env/fjsp_env.py\u001b[0m in \u001b[0;36mnext_time\u001b[0;34m(self, flag_trans_2_next_time)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_mas_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutiliz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachines_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0mjobs_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mjob_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjobs_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instances = get_all_instances_in_taillard_specification()\n",
    "for instance in instances:\n",
    "    fjsp_instance = jssp_taillard_to_fjsp(instance)\n",
    "    makespan, _ = solve_instance(fjsp_instance, model, memories)\n",
    "    print(\"Makespan of\", instance.split(\"/\")[-1], \":\", makespan.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac1c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
