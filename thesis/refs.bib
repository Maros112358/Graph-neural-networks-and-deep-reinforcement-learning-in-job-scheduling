@book{knuth1979tex,
  title={TEX and METAFONT: New directions in typesetting},
  author={Knuth, Donald Ervin},
  year={1979},
  publisher={American Mathematical Society}
}

@book{lamport1994latex,
  title={LATEX: a document preparation system: user's guide and reference manual},
  author={Lamport, Leslie},
  year={1994},
  publisher={Addison-Wesley}
}

@book{glasman2010science,
  title={Science research writing for non-native speakers of English},
  author={Glasman-Deal, Hilary},
  year={2010},
  publisher={World Scientific}
}

@book{sparling1989english,
  title={English or Czenglish? Jak se vyhnout čechismům v angličtině},
  author={Sparling, Don},
  year={1989},
  publisher={Státní pedagogické nakladatelství}
}

@book{tufte1990envisioning,
  title={Envisioning information},
  author={Tufte, Edward R and Goeler, Nora Hillman and Benson, Richard},
  year={1990},
  publisher={Graphics press Cheshire, CT}
}

@book{tufte1983visual,
  title={Visual display of quantitative information},
  author={Tufte, Edward R},
  year={1983},
  publisher={Graphics press Cheshire, CT}
}

@book{wilke2019fundamentals,
  title={Fundamentals of Data Visualization},
  author={Wilke, Claus O},
  year={2019},
  publisher={O'Reilly Media, Inc.},
  url={https://clauswilke.com/dataviz/},
  isbn={9781492031086}
}

@article{YamadaNakanoJSSP,
  author = {Yamada, Takeshi and Nakano, Ryohei},
  year = {2000},
  month = {09},
  pages = {},
  title = {Job-Shop Scheduling}
}

@article{DAUZEREPERES2024409,
  title = {The flexible job shop scheduling problem: A review},
  journal = {European Journal of Operational Research},
  volume = {314},
  number = {2},
  pages = {409-432},
  year = {2024},
  issn = {0377-2217},
  doi = {https://doi.org/10.1016/j.ejor.2023.05.017},
  url = {https://www.sciencedirect.com/science/article/pii/S037722172300382X},
  author = {Stéphane Dauzère-Pérès and Junwen Ding and Liji Shen and Karim Tamssaouet},
  keywords = {Scheduling, Flexible job shop, Survey, Criteria, Constraints},
  abstract = {The flexible job shop scheduling problem (FJSP) is an NP-hard combinatorial optimization problem, which has wide applications in the real world. The complexity and relevance of the FJSP have led to numerous research works on its modeling and resolution. This paper reviews some of the research of the past 30 years on the problem, by presenting and classifying the different criteria, constraints, configurations and solution approaches that have been considered. Recent emerging topics on complex shop scheduling, multi-criteria optimization and uncertain and dynamic environments are discussed. Finally, future research opportunities are proposed.}
}

@article{MOHAN201934,
  title = {A Review of Dynamic Job Shop Scheduling Techniques},
  journal = {Procedia Manufacturing},
  volume = {30},
  pages = {34-39},
  year = {2019},
  note = {Digital Manufacturing Transforming Industry Towards Sustainable Growth},
  issn = {2351-9789},
  doi = {https://doi.org/10.1016/j.promfg.2019.02.006},
  url = {https://www.sciencedirect.com/science/article/pii/S2351978919300368},
  author = {Jatoth Mohan and Krishnanand Lanka and A. Neelakanteswara Rao},
  keywords = {dynamic job shop scheduling, scheduling method, precise, approximate},
  abstract = {In this paper, the development of dynamic job shop scheduling problem was summarized broadly. It discusses the concept of dynamic job shop scheduling, dynamic events, evaluation indicator, dynamic scheduling strategy, dynamic scheduling methods, and scheduling system. The scheduling methods are divided into two classes: the precise methods and approximate methods. Characteristics of each method are analyzed. At last, problems which need further investigation and possible research directions are pointed out.}
}

@article{BLAZEWICZ2000317,
title = {The disjunctive graph machine representation of the job shop scheduling problem},
journal = {European Journal of Operational Research},
volume = {127},
number = {2},
pages = {317-331},
year = {2000},
issn = {0377-2217},
doi = {https://doi.org/10.1016/S0377-2217(99)00486-5},
url = {https://www.sciencedirect.com/science/article/pii/S0377221799004865},
author = {Jacek Błażewicz and Erwin Pesch and Małgorzata Sterna},
keywords = {Disjunctive graph, Graph representations, Graph matrix, Scheduling theory},
abstract = {The disjunctive graph is one of the most popular models used for describing instances of the job shop scheduling problem, which has been very intensively explored. In this paper, a new time and memory efficient representation of the disjunctive graph is proposed. It has the form of a graph matrix and combines advantages of a few classical graph representations, enabling easy operating on the problem data. Computational experiments have proved higher efficiency of the proposed approach over the classical ones.}
}

@article{Garey1976TheCO,
  title={The Complexity of Flowshop and Jobshop Scheduling},
  author={M. R. Garey and David S. Johnson and Ravi Sethi},
  journal={Math. Oper. Res.},
  year={1976},
  volume={1},
  pages={117-129},
  url={https://api.semanticscholar.org/CorpusID:207233771}
}

@inproceedings{Jansen2000ApproximationAF,
  title={Approximation algorithms for flexible job shop problems},
  author={Klaus Jansen and Monaldo Mastrolilli and Roberto Solis-Oba},
  booktitle={International Journal of Foundations of Computer Science},
  year={2000},
  url={https://api.semanticscholar.org/CorpusID:16760211}
}

@article{Haupt1989ASO,
  title={A survey of priority rule-based scheduling},
  author={R. Haupt},
  journal={Operations-Research-Spektrum},
  year={1989},
  volume={11},
  pages={3-16},
  url={https://api.semanticscholar.org/CorpusID:60820532}
}

@article{doi:10.1080/00207543.2011.611539,
  author = {Veronique Sels, Nele Gheysen and Mario Vanhoucke},
  title = {A comparison of priority rules for the job shop scheduling problem under different flow time- and tardiness-related objective functions},
  journal = {International Journal of Production Research},
  volume = {50},
  number = {15},
  pages = {4255-4270},
  year = {2012},
  publisher = {Taylor \& Francis},
  doi = {10.1080/00207543.2011.611539},
  URL = { 
          https://doi.org/10.1080/00207543.2011.611539
  },
  eprint = { 
          https://doi.org/10.1080/00207543.2011.611539
  }
}

@misc{bengio2020machine,
      title={Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon}, 
      author={Yoshua Bengio and Andrea Lodi and Antoine Prouvost},
      year={2020},
      eprint={1811.06128},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhang2020learning,
      title={Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning}, 
      author={Cong Zhang and Wen Song and Zhiguang Cao and Jie Zhang and Puay Siew Tan and Chi Xu},
      year={2020},
      eprint={2010.12367},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{https://doi.org/10.1002/tee.23788,
  author = {Gebreyesus, Goytom and Fellek, Getu and Farid, Ahmed and Fujimura, Shigeru and Yoshie, Osamu},
  title = {Gated-Attention Model with Reinforcement Learning for Solving Dynamic Job Shop Scheduling Problem},
  journal = {IEEJ Transactions on Electrical and Electronic Engineering},
  volume = {18},
  number = {6},
  pages = {932-944},
  keywords = {deep reinforcement learning, job shop scheduling, gated attention mechanism},
  doi = {https://doi.org/10.1002/tee.23788},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/tee.23788},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/tee.23788},
  abstract = {Job shop scheduling problem (JSSP) is one of the well-known NP-hard combinatorial optimization problems (COPs) that aims to optimize the sequential assignment of finite machines to a set of jobs while adhering to specified problem constraints. Conventional solution approaches which include heuristic dispatching rules and evolutionary algorithms has been largely in use to solve JSSPs. Recently, the use of reinforcement learning (RL) has gained popularity for delivering better solution quality for JSSPs. In this research, we propose an end-to-end deep reinforcement learning (DRL) based scheduling model for solving the standard JSSP. Our DRL model uses attention-based encoder of Transformer network to embed the JSSP environment represented as a disjunctive graph. We introduced Gate mechanism to modulate the flow of learnt features by preventing noise features from propagating across the network to enrich the representations of nodes of the disjunctive graph. In addition, we designed a novel Gate-based graph pooling mechanism that preferentially constructs the graph embedding. A simple multi-layer perceptron (MLP) based action selection network is used for sequentially generating optimal schedules. The model is trained using proximal policy optimization (PPO) algorithm which is built on actor critic (AC) framework. Experimental results show that our model outperforms existing heuristics and state of the art DRL based baselines on generated instances and well-known public test benchmarks. © 2023 Institute of Electrical Engineers of Japan. Published by Wiley Periodicals LLC.},
  year = {2023}
}

@article{DBLP:journals/corr/abs-2106-01086,
  author       = {Junyoung Park and
                  Jaehyeong Chun and
                  Sang{-}Hun Kim and
                  Youngkook Kim and
                  Jinkyoo Park},
  title        = {Learning to schedule job-shop problems: Representation and policy
                  learning using graph neural network and reinforcement learning},
  journal      = {CoRR},
  volume       = {abs/2106.01086},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.01086},
  eprinttype    = {arXiv},
  eprint       = {2106.01086},
  timestamp    = {Wed, 09 Jun 2021 18:45:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2106-01086.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{10114974,
  author={Lei, Kun and Guo, Peng and Wang, Yi and Zhang, Jian and Meng, Xiangyin and Qian, Linmao},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Large-Scale Dynamic Scheduling for Flexible Job-Shop With Random Arrivals of New Jobs by Hierarchical Reinforcement Learning}, 
  year={2024},
  volume={20},
  number={1},
  pages={1007-1018},
  keywords={Job shop scheduling;Dynamic scheduling;Real-time systems;Dispatching;Heuristic algorithms;Schedules;Production;Dynamic flexible job shop scheduling problem (DFJSP);graph neural network (GNN);hierarchical reinforcement learning (HRL);Markov decision process (MDP);real-time optimization},
  doi={10.1109/TII.2023.3272661}
}

@INPROCEEDINGS{10226873,
  author={Ho, Kuo-Hao and Wu, Ji-Han and Chiang, Fan and Wu, Yuan-Yu and Chen, Sheng-I and Kuo, Ted and Wang, Feng-Jian and Wu, I-Chen},
  booktitle={2023 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)}, 
  title={Deep Reinforcement Learning Based on Graph Neural Networks for Job-shop Scheduling}, 
  year={2023},
  volume={},
  number={},
  pages={805-806},
  keywords={Deep learning;Reinforcement learning;Graph neural networks;Dispatching;Optimization;Consumer electronics;scheduling;neural network applications},
  doi={10.1109/ICCE-Taiwan58799.2023.10226873}
}

@article{WILSON2003430,
  title = {Gantt charts: A centenary appreciation},
  journal = {European Journal of Operational Research},
  volume = {149},
  number = {2},
  pages = {430-437},
  year = {2003},
  note = {Sequencing and Scheduling},
  issn = {0377-2217},
  doi = {https://doi.org/10.1016/S0377-2217(02)00769-5},
  url = {https://www.sciencedirect.com/science/article/pii/S0377221702007695},
  author = {James M. Wilson},
  keywords = {Project management, Machine loading, Production planning, Gantt charts},
  abstract = {With the proliferation of microcomputer based project management packages Gantt charts have enjoyed a revival in their use. Although Henry L. Gantt is recognized as their developer their origins and provenance are less well known. Gantt was a close associate of Frederick W. Taylor and an advocate of Scientific Management. His paper describing the use of “graphics” for general production planning appeared alongside Taylor’s Shop Management in 1903 and was an integral and critical component of Taylor’s system. Without Gantt’s charts to plan the workloads for men and machines both in departments and throughout the factory Taylor’s system would have been unworkable. The focus of this paper is to describe more fully their development and early history; and review their contemporary uses and future prospects.}
}

@article{doi:10.1287/opre.17.6.941,
  author = {Balas, Egon},
  title = {Machine Sequencing Via Disjunctive Graphs: An Implicit Enumeration Algorithm},
  journal = {Operations Research},
  volume = {17},
  number = {6},
  pages = {941-957},
  year = {1969},
  doi = {10.1287/opre.17.6.941},
  URL = {
    https://doi.org/10.1287/opre.17.6.941
  },
  eprint = { 
    https://doi.org/10.1287/opre.17.6.941
  },
  abstract = { One formulation of the machine sequencing problem is that of finding a mini-maximal path in a disjunctive graph. This paper describes an implicit enumeration procedure that solves the problem by generating a sequence of circuit-free graphs and solving a slightly amended critical-path problem for each graph in the sequence. Each new term of the sequence is generated from an earlier one by complementing one disjunctive arc. The search tree is drastically cut down by the fact that the only disjunctive arcs that have to be considered for being complemented are those on a critical path. An evaluation of these candidates is used to direct the search at each stage. The procedure can start with any feasible schedule (like the one actually used in production, or generated by some heuristics), and gradually improve it. Thus one can possibly stop short of the optimum, with a reasonably “good” feasible schedule. Storage requirements are limited to the data pertinent to the current node of the search tree. }
}

@ARTICLE{9826438,
  author={Song, Wen and Chen, Xinyang and Li, Qiqiang and Cao, Zhiguang},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Flexible Job-Shop Scheduling via Graph Neural Network and Deep Reinforcement Learning}, 
  year={2023},
  volume={19},
  number={2},
  pages={1600-1610},
  keywords={Job shop scheduling;Manufacturing;Scheduling;Processor scheduling;Optimal scheduling;Cloud computing;Informatics;Deep reinforcement learning (DRL);flexible job-shop scheduling;graph neural network (GNN)},
  doi={10.1109/TII.2022.3189725}
}

@article{https://doi.org/10.1049/iet-cim.2018.0009,
author = {Xie, Jin and Gao, Liang and Peng, Kunkun and Li, Xinyu and Li, Haoran},
title = {Review on flexible job shop scheduling},
journal = {IET Collaborative Intelligent Manufacturing},
volume = {1},
number = {3},
pages = {67-77},
keywords = {optimisation, job shop scheduling, combinatorial mathematics, manufacturing industries, FJSP, flexible job shop scheduling problem, NP-hard combinatorial optimisation problem, meta-heuristics, manufacturing industry},
doi = {https://doi.org/10.1049/iet-cim.2018.0009},
url = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-cim.2018.0009},
eprint = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/iet-cim.2018.0009},
abstract = {Flexible job shop scheduling problem (FJSP) is an NP-hard combinatorial optimisation problem, which has significant applications in the real world. Due to its complexity and significance, lots of attentions have been paid to tackle this problem. In this study, the existing solution methods for the FJSP in recent literature are classified into exact algorithms, heuristics and meta-heuristics, which are reviewed comprehensively. Moreover, the real-world applications of the FJSP are also introduced. Finally, the development trends of the manufacturing industry are analysed, and the future research opportunities of the FJSP are summarised in detail.},
year = {2019}
}

@article{Brandimarte_1993, 
  title={Routing and scheduling in a flexible job shop by Tabu Search}, volume={41}, 
  DOI={10.1007/bf02023073}, 
  number={3}, 
  journal={Annals of Operations Research}, 
  author={Brandimarte, Paolo}, 
  year={1993}, 
  month={9}, 
  pages={157-183}
} 

@article{LEI2022117796,
  title = {A multi-action deep reinforcement learning framework for flexible Job-shop scheduling problem},
  journal = {Expert Systems with Applications},
  volume = {205},
  pages = {117796},
  year = {2022},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2022.117796},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417422010624},
  author = {Kun Lei and Peng Guo and Wenchao Zhao and Yi Wang and Linmao Qian and Xiangyin Meng and Liansheng Tang},
  keywords = {Flexible job-shop scheduling problem, Multi-action deep reinforcement learning, Graph neural network, Markov decision process, Multi-proximal policy optimization},
  abstract = {This paper presents an end-to-end deep reinforcement framework to automatically learn a policy for solving a flexible Job-shop scheduling problem (FJSP) using a graph neural network. In the FJSP environment, the reinforcement agent needs to schedule an operation belonging to a job on an eligible machine among a set of compatible machines at each timestep. This means that an agent needs to control multiple actions simultaneously. Such a problem with multi-actions is formulated as a multiple Markov decision process (MMDP). For solving the MMDPs, we propose a multi-pointer graph networks (MPGN) architecture and a training algorithm called multi-Proximal Policy Optimization (multi-PPO) to learn two sub-policies, including a job operation action policy and a machine action policy to assign a job operation to a machine. The MPGN architecture consists of two encoder-decoder components, which define the job operation action policy and the machine action policy for predicting probability distributions over different operations and machines, respectively. We introduce a disjunctive graph representation of FJSP and use a graph neural network to embed the local state encountered during scheduling. The computational experiment results show that the agent can learn a high-quality dispatching policy and outperforms handcrafted heuristic dispatching rules in solution quality and meta-heuristic algorithm in running time. Moreover, the results achieved on random and benchmark instances demonstrate that the learned policies have a good generalization performance on real-world instances and significantly larger scale instances with up to 2000 operations.}
}

@article{KUNDAKCI201631,
  title = {Hybrid genetic algorithms for minimizing makespan in dynamic job shop scheduling problem},
  journal = {Computers \& Industrial Engineering},
  volume = {96},
  pages = {31-51},
  year = {2016},
  issn = {0360-8352},
  doi = {https://doi.org/10.1016/j.cie.2016.03.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0360835216300742},
  author = {Nilsen Kundakcı and Osman Kulak},
  keywords = {Hybrid genetic algorithm, Tabu search, Dynamic job shop scheduling},
  abstract = {Job shop scheduling has been the focus of a substantial amount of research over the last decade and most of these approaches are formulated and designed to address the static job shop scheduling problem. Dynamic events such as random job arrivals, machine breakdowns and changes in processing time, which are inevitable occurrences in production environment, are ignored in static job shop scheduling problem. As dynamic job shop scheduling problem is known NP-hard combinatorial optimization, this paper introduces efficient hybrid Genetic Algorithm (GA) methodologies for minimizing makespan in this kind of problem. Various benchmark problems including the number of jobs, the number of machines, and different dynamic events are generated and detailed numerical experiments are carried out to evaluate the performance of proposed methodologies. The numerical results indicate that the proposed methods produce superior solutions for well-known benchmark problems compared to those reported in the literature.}
}

@article{Haupt_1989a, 
  title={A survey of priority rule-based scheduling}, 
  volume={11}, DOI={10.1007/bf01721162}, 
  number={1}, 
  journal={OR Spektrum}, 
  author={Haupt, R.}, 
  year={1989}, 
  month={3}, 
  pages={3-16}
} 

@article{discovering_dispatching_rules,
  author = {Ingimundardottir, Helga and Runarsson, Thomas},
  year = {2018},
  month = {08},
  pages = {1-16},
  title = {Discovering dispatching rules from data using imitation learning: A case study for the job-shop problem},
  volume = {21},
  journal = {Journal of Scheduling},
  doi = {10.1007/s10951-017-0534-0}
}

@INPROCEEDINGS{7232991,
  author={Zahmani, Mohamed Habib and Atmani, Baghdad and Bekrar, Abdelghani and Aissani, Nassima},
  booktitle={2015 3rd International Conference on Control, Engineering \& Information Technology (CEIT)}, 
  title={Multiple priority dispatching rules for the job shop scheduling problem}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  keywords={Dispatching;Job shop scheduling;Data mining;Databases;Data models;Object recognition;Optimization;Job Shop Scheduling;Simulation;Dispatching Rules;Makespan;Learning Database},
  doi={10.1109/CEIT.2015.7232991}
}

@article{jssp_rl_env,
  author       = {Pierre Tassel and
                  Martin Gebser and
                  Konstantin Schekotihin},
  title        = {A Reinforcement Learning Environment For Job-Shop Scheduling},
  journal      = {CoRR},
  volume       = {abs/2104.03760},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.03760},
  eprinttype    = {arXiv},
  eprint       = {2104.03760},
  timestamp    = {Tue, 13 Apr 2021 16:46:17 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2104-03760.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/RedmonDGF15,
  author       = {Joseph Redmon and
                  Santosh Kumar Divvala and
                  Ross B. Girshick and
                  Ali Farhadi},
  title        = {You Only Look Once: Unified, Real-Time Object Detection},
  journal      = {CoRR},
  volume       = {abs/1506.02640},
  year         = {2015},
  url          = {http://arxiv.org/abs/1506.02640},
  eprinttype    = {arXiv},
  eprint       = {1506.02640},
  timestamp    = {Mon, 13 Aug 2018 16:48:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RedmonDGF15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1109/IVS.2019.8813777,
author = {Zinelli, Andrea and Musto, Luigi and Pizzati, Fabio},
title = {A Deep-Learning Approach for Parking Slot Detection on Surround-View Images},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IVS.2019.8813777},
doi = {10.1109/IVS.2019.8813777},
abstract = {Being able to automatically detect parking slots during navigation is an important part of an autonomous driving system. Most of the current parking slot detectors either work on images coming from static cameras or are based on hand-designed low-level visual features, limiting the domains of application of such systems considerably. Learning the most suitable features for the task directly from data would allow the system to function in a broader range of situations and be more robust to noise and different observation conditions. This paper presents an end-to-end deep neural network trained to perform automatic parking slot detection and classification on surround-view images, generated by fusing the views of four different cameras positioned on a vehicle. The network architecture is based on the Faster R-CNN baseline. To account for the fact that parking slots can be of different shapes and can be observed at different angles, the predicted bounding boxes are generic quadrilaterals rather than image-aligned rectangles. Moreover, instead of computing offsets wrt anchor boxes, the RPN regresses the region proposals directly. In order to train the network, a small training set comprised of a few hundred images has been manually annotated. The network shows good performance and generalization capability on new examples containing parking slots of the same kinds as those in the training set, suggesting that a wider array of parking slot types could easily be integrated into the system by expanding the dataset.},
booktitle = {2019 IEEE Intelligent Vehicles Symposium (IV)},
pages = {683–688},
numpages = {6},
location = {Paris, France}
}

@ARTICLE{8627998,
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-Tao and Wu, Xindong},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Object Detection With Deep Learning: A Review}, 
  year={2019},
  volume={30},
  number={11},
  pages={3212-3232},
  keywords={Object detection;Deep learning;Task analysis;Feature extraction;Computer architecture;Training;Neural networks;Deep learning;neural network;object detection},
  doi={10.1109/TNNLS.2018.2876865}
}

@article{DBLP:journals/corr/LuongPM15,
  author       = {Minh{-}Thang Luong and
                  Hieu Pham and
                  Christopher D. Manning},
  title        = {Effective Approaches to Attention-based Neural Machine Translation},
  journal      = {CoRR},
  volume       = {abs/1508.04025},
  year         = {2015},
  url          = {http://arxiv.org/abs/1508.04025},
  eprinttype    = {arXiv},
  eprint       = {1508.04025},
  timestamp    = {Mon, 13 Aug 2018 16:46:14 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LuongPM15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8003957,
  author={Singh, Shashi Pal and Kumar, Ajai and Darbari, Hemant and Singh, Lenali and Rastogi, Anshika and Jain, Shikha},
  booktitle={2017 International Conference on Computer, Communications and Electronics (Comptelix)}, 
  title={Machine translation using deep learning: An overview}, 
  year={2017},
  volume={},
  number={},
  pages={162-167},
  keywords={Artificial neural networks;History;Binary trees;Training;Predictive models;Recurrent neural networks;Neural Network(NN);Deep neural network(DNN);convolutional neural network(CNN);feed-forward neural network(FNN);recurrent neural network(RNN);recursive auto-encoder( RAE);Long Short-term memory(LSTM)},
  doi={10.1109/COMPTELIX.2017.8003957}
}

@article{DBLP:journals/corr/abs-2002-07526,
  author       = {Shuoheng Yang and
                  Yuxin Wang and
                  Xiaowen Chu},
  title        = {A Survey of Deep Learning Techniques for Neural Machine Translation},
  journal      = {CoRR},
  volume       = {abs/2002.07526},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.07526},
  eprinttype    = {arXiv},
  eprint       = {2002.07526},
  timestamp    = {Mon, 02 Mar 2020 16:46:06 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-07526.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DONG2021100379,
  title = {A survey on deep learning and its applications},
  journal = {Computer Science Review},
  volume = {40},
  pages = {100379},
  year = {2021},
  issn = {1574-0137},
  doi = {https://doi.org/10.1016/j.cosrev.2021.100379},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013721000198},
  author = {Shi Dong and Ping Wang and Khushnood Abbas},
  keywords = {Deep learning, Stacked auto encoder, Deep belief networks, Deep Boltzmann machine, Convolutional neural network},
  abstract = {Deep learning, a branch of machine learning, is a frontier for artificial intelligence, aiming to be closer to its primary goal—artificial intelligence. This paper mainly adopts the summary and the induction methods of deep learning. Firstly, it introduces the global development and the current situation of deep learning. Secondly, it describes the structural principle, the characteristics, and some kinds of classic models of deep learning, such as stacked auto encoder, deep belief network, deep Boltzmann machine, and convolutional neural network. Thirdly, it presents the latest developments and applications of deep learning in many fields such as speech processing, computer vision, natural language processing, and medical applications. Finally, it puts forward the problems and the future research directions of deep learning.}
}

@article{10.1145/3505243,
  author = {Yang, Yanming and Xia, Xin and Lo, David and Grundy, John},
  title = {A Survey on Deep Learning for Software Engineering},
  year = {2022},
  issue_date = {January 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {54},
  number = {10s},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3505243},
  doi = {10.1145/3505243},
  abstract = {In 2006, Geoffrey Hinton proposed the concept of training “Deep Neural Networks (DNNs)” and an improved model training method to break the bottleneck of neural network development. More recently, the introduction of AlphaGo in 2016 demonstrated the powerful learning ability of deep learning and its enormous potential. Deep learning has been increasingly used to develop state-of-the-art software engineering (SE) research tools due to its ability to boost performance for various SE tasks. There are many factors, e.g., deep learning model selection, internal structure differences, and model optimization techniques, that may have an impact on the performance of DNNs applied in SE. Few works to date focus on summarizing, classifying, and analyzing the application of deep learning techniques in SE. To fill this gap, we performed a survey to analyze the relevant studies published since 2006. We first provide an example to illustrate how deep learning techniques are used in SE. We then conduct a background analysis (BA) of primary studies and present four research questions to describe the trend of DNNs used in SE (BA), summarize and classify different deep learning techniques (RQ1), and analyze the data processing including data collection, data classification, data pre-processing, and data representation (RQ2). In RQ3, we depicted a range of key research topics using DNNs and investigated the relationships between DL-based model adoption and multiple factors (i.e., DL architectures, task types, problem types, and data types). We also summarized commonly used datasets for different SE tasks. In RQ4, we summarized the widely used optimization algorithms and provided important evaluation metrics for different problem types, including regression, classification, recommendation, and generation. Based on our findings, we present a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work.},
  journal = {ACM Comput. Surv.},
  month = {sep},
  articleno = {206},
  numpages = {73},
  keywords = {survey, software engineering, machine learning, neural network, Deep learning}
}

@article{PICCIALLI2021111,
  title = {A survey on deep learning in medicine: Why, how and when?},
  journal = {Information Fusion},
  volume = {66},
  pages = {111-137},
  year = {2021},
  issn = {1566-2535},
  doi = {https://doi.org/10.1016/j.inffus.2020.09.006},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253520303651},
  author = {Francesco Piccialli and Vittorio Di Somma and Fabio Giampaolo and Salvatore Cuomo and Giancarlo Fortino},
  keywords = {Deep learning, Medicine, Artificial intelligence, Data science, Neural networks},
  abstract = {New technologies are transforming medicine, and this revolution starts with data. Health data, clinical images, genome sequences, data on prescribed therapies and results obtained, data that each of us has helped to create. Although the first uses of artificial intelligence (AI) in medicine date back to the 1980s, it is only with the beginning of the new millennium that there has been an explosion of interest in this sector worldwide. We are therefore witnessing the exponential growth of health-related information with the result that traditional analysis techniques are not suitable for satisfactorily management of this vast amount of data. AI applications (especially Deep Learning), on the other hand, are naturally predisposed to cope with this explosion of data, as they always work better as the amount of training data increases, a phase necessary to build the optimal neural network for a given clinical problem. This paper proposes a comprehensive and in-depth study of Deep Learning methodologies and applications in medicine. An in-depth analysis of the literature is presented; how, where and why Deep Learning models are applied in medicine are discussed and reviewed. Finally, current challenges and future research directions are outlined and analysed.}
}

@inproceedings{10.1145/3308558.3313488,
  author = {Fan, Wenqi and Ma, Yao and Li, Qing and He, Yuan and Zhao, Eric and Tang, Jiliang and Yin, Dawei},
  title = {Graph Neural Networks for Social Recommendation},
  year = {2019},
  isbn = {9781450366748},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3308558.3313488},
  doi = {10.1145/3308558.3313488},
  abstract = {In recent years, Graph Neural Networks (GNNs), which can naturally integrate node information and topological structure, have been demonstrated to be powerful in learning on graph data. These advantages of GNNs provide great potential to advance social recommendation since data in social recommender systems can be represented as user-user social graph and user-item graph; and learning latent factors of users and items is the key. However, building social recommender systems based on GNNs faces challenges. For example, the user-item graph encodes both interactions and their associated opinions; social relations have heterogeneous strengths; users involve in two graphs (e.g., the user-user social graph and the user-item graph). To address the three aforementioned challenges simultaneously, in this paper, we present a novel graph neural network framework (GraphRec) for social recommendations. In particular, we provide a principled approach to jointly capture interactions and opinions in the user-item graph and propose the framework GraphRec, which coherently models two graphs and heterogeneous strengths. Extensive experiments on two real-world datasets demonstrate the effectiveness of the proposed framework GraphRec.},
  booktitle = {The World Wide Web Conference},
  pages = {417–426},
  numpages = {10},
  keywords = {Social Recommendation, Social Network, Recommender Systems, Neural Networks, Graph Neural Networks},
  location = {San Francisco, CA, USA},
  series = {WWW '19}
}

@article{strokach2020fast,
  title={Fast and flexible protein design using deep graph neural networks},
  author={Strokach, Alexey and Becerra, David and Corbi-Verge, Carles and Perez-Riba, Albert and Kim, Philip M},
  journal={Cell systems},
  volume={11},
  number={4},
  pages={402--411},
  year={2020},
  publisher={Elsevier}
}

@article{JIANG2022117921,
  title = {Graph neural network for traffic forecasting: A survey},
  journal = {Expert Systems with Applications},
  volume = {207},
  pages = {117921},
  year = {2022},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2022.117921},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417422011654},
  author = {Weiwei Jiang and Jiayun Luo},
  keywords = {Traffic forecasting, Graph neural networks, Graph convolution network, Graph attention network, Deep learning},
  abstract = {Traffic forecasting is important for the success of intelligent transportation systems. Deep learning models, including convolution neural networks and recurrent neural networks, have been extensively applied in traffic forecasting problems to model spatial and temporal dependencies. In recent years, to model the graph structures in transportation systems as well as contextual information, graph neural networks have been introduced and have achieved state-of-the-art performance in a series of traffic forecasting problems. In this survey, we review the rapidly growing body of research using different graph neural networks, e.g. graph convolutional and graph attention networks, in various traffic forecasting problems, e.g. road traffic flow and speed forecasting, passenger flow forecasting in urban rail transit systems, and demand forecasting in ride-hailing platforms. We also present a comprehensive list of open data and source codes for each problem and identify future research directions. To the best of our knowledge, this paper is the first comprehensive survey that explores the application of graph neural networks for traffic forecasting problems. We have also created a public GitHub repository where the latest papers, open data, and source codes will be updated.}
}

@ARTICLE{9046288,
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Comprehensive Survey on Graph Neural Networks}, 
  year={2021},
  volume={32},
  number={1},
  pages={4-24},
  keywords={Deep learning;Neural networks;Task analysis;Kernel;Feature extraction;Data mining;Learning systems;Deep learning;graph autoencoder (GAE);graph convolutional networks (GCNs);graph neural networks (GNNs);graph representation learning;network embedding},
  doi={10.1109/TNNLS.2020.2978386}
}

@article{sanchez-lengeling2021a,
  author = {Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B.},
  title = {A Gentle Introduction to Graph Neural Networks},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2021/gnn-intro},
  doi = {10.23915/distill.00033}
}


@InProceedings{pmlr-v70-gilmer17a,
  title = 	 {Neural Message Passing for Quantum Chemistry},
  author =       {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1263--1272},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/gilmer17a.html},
  abstract = 	 {Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels.}
}

@article{10.1145/3495161,
  author = {Zhou, Yu and Zheng, Haixia and Huang, Xin and Hao, Shufeng and Li, Dengao and Zhao, Jumin},
  title = {Graph Neural Networks: Taxonomy, Advances, and Trends},
  year = {2022},
  issue_date = {February 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {13},
  number = {1},
  issn = {2157-6904},
  url = {https://doi.org/10.1145/3495161},
  doi = {10.1145/3495161},
  abstract = {Graph neural networks provide a powerful toolkit for embedding real-world graphs into low-dimensional spaces according to specific tasks. Up to now, there have been several surveys on this topic. However, they usually lay emphasis on different angles so that the readers cannot see a panorama of the graph neural networks. This survey aims to overcome this limitation and provide a systematic and comprehensive review on the graph neural networks. First of all, we provide a novel taxonomy for the graph neural networks, and then refer to up to 327 relevant literatures to show the panorama of the graph neural networks. All of them are classified into the corresponding categories. In order to drive the graph neural networks into a new stage, we summarize four future research directions so as to overcome the challenges faced. It is expected that more and more scholars can understand and exploit the graph neural networks and use them in their research community.},
  journal = {ACM Trans. Intell. Syst. Technol.},
  month = {jan},
  articleno = {15},
  numpages = {54},
  keywords = {graph neural network, graph attention mechanism, graph pooling operator, graph recurrent neural network, Graph convolutional neural network}
}

@article{DBLP:journals/corr/abs-1810-00826,
  author       = {Keyulu Xu and
                  Weihua Hu and
                  Jure Leskovec and
                  Stefanie Jegelka},
  title        = {How Powerful are Graph Neural Networks?},
  journal      = {CoRR},
  volume       = {abs/1810.00826},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.00826},
  eprinttype    = {arXiv},
  eprint       = {1810.00826},
  timestamp    = {Tue, 30 Oct 2018 10:49:09 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-00826.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{pytorch_hetero_conv,
  author       = {Pytorch Geometric Team},
  howpublished = {Pytorch Geometric Online documentation},
  title        = {conv.HeteroConv module},
  year         = {2024},
  month        = {3},
  url = {https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HeteroConv.html}
}

@misc{veličković2018graph,
      title={Graph Attention Networks}, 
      author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
      year={2018},
      eprint={1710.10903},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{DBLP:journals/corr/abs-2105-14491,
  author       = {Shaked Brody and
                  Uri Alon and
                  Eran Yahav},
  title        = {How Attentive are Graph Attention Networks?},
  journal      = {CoRR},
  volume       = {abs/2105.14491},
  year         = {2021},
  url          = {https://arxiv.org/abs/2105.14491},
  eprinttype    = {arXiv},
  eprint       = {2105.14491},
  timestamp    = {Wed, 02 Jun 2021 11:46:42 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-14491.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2002-01680,
  author       = {Xinyu Fu and
                  Jiani Zhang and
                  Ziqiao Meng and
                  Irwin King},
  title        = {{MAGNN:} Metapath Aggregated Graph Neural Network for Heterogeneous
                  Graph Embedding},
  journal      = {CoRR},
  volume       = {abs/2002.01680},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.01680},
  eprinttype    = {arXiv},
  eprint       = {2002.01680},
  timestamp    = {Tue, 01 Sep 2020 13:30:17 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-01680.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{PEZZELLA20083202,
  title = {A genetic algorithm for the Flexible Job-shop Scheduling Problem},
  journal = {Computers \& Operations Research},
  volume = {35},
  number = {10},
  pages = {3202-3212},
  year = {2008},
  note = {Part Special Issue: Search-based Software Engineering},
  issn = {0305-0548},
  doi = {https://doi.org/10.1016/j.cor.2007.02.014},
  url = {https://www.sciencedirect.com/science/article/pii/S0305054807000524},
  author = {F. Pezzella and G. Morganti and G. Ciaschetti},
  keywords = {Job-shop Scheduling, Genetic algorithms, Flexible manufacturing systems},
  abstract = {In this paper, we present a genetic algorithm for the Flexible Job-shop Scheduling Problem (FJSP). The algorithm integrates different strategies for generating the initial population, selecting the individuals for reproduction and reproducing new individuals. Computational result shows that the integration of more strategies in a genetic framework leads to better results, with respect to other genetic algorithms. Moreover, results are quite comparable to those obtained by the best-known algorithm, based on tabu search. These two results, together with the flexibility of genetic paradigm, prove that genetic algorithms are effective for solving FJSP.}
}

@article{zhang2011effective,
  title={An effective genetic algorithm for the flexible job-shop scheduling problem},
  author={Zhang, Guohui and Gao, Liang and Shi, Yang},
  journal={Expert Systems with Applications},
  volume={38},
  number={4},
  pages={3563--3573},
  year={2011},
  publisher={Elsevier}
}

@article{ZHANG20091309,
  title = {An effective hybrid particle swarm optimization algorithm for multi-objective flexible job-shop scheduling problem},
  journal = {Computers \& Industrial Engineering},
  volume = {56},
  number = {4},
  pages = {1309-1318},
  year = {2009},
  issn = {0360-8352},
  doi = {https://doi.org/10.1016/j.cie.2008.07.021},
  url = {https://www.sciencedirect.com/science/article/pii/S0360835208001666},
  author = {Guohui Zhang and Xinyu Shao and Peigen Li and Liang Gao},
  keywords = {Multi-objective optimization, Flexible job-shop scheduling, Particle swarm optimization, Tabu search},
  abstract = {Flexible job-shop scheduling problem (FJSP) is an extension of the classical job-shop scheduling problem. Although the traditional optimization algorithms could obtain preferable results in solving the mono-objective FJSP. However, they are very difficult to solve multi-objective FJSP very well. In this paper, a particle swarm optimization (PSO) algorithm and a tabu search (TS) algorithm are combined to solve the multi-objective FJSP with several conflicting and incommensurable objectives. PSO which integrates local search and global search scheme possesses high search efficiency. And, TS is a meta-heuristic which is designed for finding a near optimal solution of combinatorial optimization problems. Through reasonably hybridizing the two optimization algorithms, an effective hybrid approach for the multi-objective FJSP has been proposed. The computational results have proved that the proposed hybrid algorithm is an efficient and effective approach to solve the multi-objective FJSP, especially for the problems on a large scale.}
}

@article{frutos2010memetic,
  title={A memetic algorithm based on a NSGAII scheme for the flexible job-shop scheduling problem},
  author={Frutos, Mariano and Olivera, Ana Carolina and Tohm{\'e}, Fernando},
  journal={Annals of Operations Research},
  volume={181},
  pages={745--765},
  year={2010},
  publisher={Springer}
}

@Inbook{Yamada1996,
  author="Yamada, Takeshi
  and Nakano, Ryohei",
  editor="Osman, Ibrahim H.
  and Kelly, James P.",
  title="Job-Shop Scheduling by Simulated Annealing Combined with Deterministic Local Search",
  bookTitle="Meta-Heuristics: Theory and Applications",
  year="1996",
  publisher="Springer US",
  address="Boston, MA",
  pages="237--248",
  abstract="The Job-Shop Scheduling Problem (JSSP) is one of the most difficult NP-hard combinatorial optimization problems. This paper proposes a new method for solving JSSPs based on simulated annealing (SA), a stochastic local search, enhanced by shifting bottleneck (SB), a problem specific deterministic local search. In our method new schedules are generated by a variant of Giffler and Thompson's active scheduler with operation permutations on the critical path. SA selects a new schedule and probabilistically accepts or rejects it. The modified SB is applied to repair the rejected schedule; the new schedule is accepted if an improvement is made. Experimental results showed the proposed method found near optimal schedules for the difficult benchmark problems and outperformed other existing local search algorithms.",
  isbn="978-1-4613-1361-8",
  doi="10.1007/978-1-4613-1361-8_15",
  url="https://doi.org/10.1007/978-1-4613-1361-8_15"
}

@article{DBLP:journals/corr/SchulmanWDRK17,
  author       = {John Schulman and
                  Filip Wolski and
                  Prafulla Dhariwal and
                  Alec Radford and
                  Oleg Klimov},
  title        = {Proximal Policy Optimization Algorithms},
  journal      = {CoRR},
  volume       = {abs/1707.06347},
  year         = {2017},
  url          = {http://arxiv.org/abs/1707.06347},
  eprinttype    = {arXiv},
  eprint       = {1707.06347},
  timestamp    = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/HasseltGS15,
  author       = {Hado van Hasselt and
                  Arthur Guez and
                  David Silver},
  title        = {Deep Reinforcement Learning with Double Q-learning},
  journal      = {CoRR},
  volume       = {abs/1509.06461},
  year         = {2015},
  url          = {http://arxiv.org/abs/1509.06461},
  eprinttype    = {arXiv},
  eprint       = {1509.06461},
  timestamp    = {Mon, 13 Aug 2018 16:47:32 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HasseltGS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/Li17b,
  author       = {Yuxi Li},
  title        = {Deep Reinforcement Learning: An Overview},
  journal      = {CoRR},
  volume       = {abs/1701.07274},
  year         = {2017},
  url          = {http://arxiv.org/abs/1701.07274},
  eprinttype    = {arXiv},
  eprint       = {1701.07274},
  timestamp    = {Mon, 13 Aug 2018 16:48:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/Li17b.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald and others},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{sarsa,
  author = {Rummery, G. and Niranjan, Mahesan},
  year = {1994},
  month = {11},
  pages = {},
  title = {On-Line Q-Learning Using Connectionist Systems},
  journal = {Technical Report CUED/F-INFENG/TR 166}
}

@article{bertsekas2011approximate,
  title={Approximate policy iteration: A survey and some new methods},
  author={Bertsekas, Dimitri P},
  journal={Journal of Control Theory and Applications},
  volume={9},
  number={3},
  pages={310--335},
  year={2011},
  publisher={Springer}
}

@book{barto1989learning,
  title={Learning and sequential decision making},
  author={Barto, Andrew Gehret and Sutton, Richard S and Watkins, CJCH},
  volume={89},
  year={1989},
  publisher={University of Massachusetts Amherst, MA}
}

@inproceedings{Howard1960DynamicPA,
  title={Dynamic Programming and Markov Processes},
  author={Ronald A. Howard},
  year={1960},
  url={https://api.semanticscholar.org/CorpusID:62124406}
}

@misc{openai_policy_optimization,
  author       = {OpenAI},
  title        = {Part 3: Intro to Policy Optimization},
  howpublished = {OpenAI Spinning Up},
  year         = {2024},
  month        = {3},
  url = {https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@article{Hasselt_Guez_Silver_2016, title={Deep Reinforcement Learning with Double Q-Learning}, volume={30}, url={https://ojs.aaai.org/index.php/AAAI/article/view/10295}, DOI={10.1609/aaai.v30i1.10295}, abstractNote={ &lt;p&gt; The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={van Hasselt, Hado and Guez, Arthur and Silver, David}, year={2016}, month={Mar.} }

@misc{github_ieee_icce_rl_jsp,
  author = {Jerry-Github-Cloud},
  title = {IEEE-ICCE-RL-JSP},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Jerry-Github-Cloud/IEEE-ICCE-RL-JSP}},
  note = {Accessed 2024-03-17},
}

@misc{github_l2d,
  author = {Cong Zhang},
  title = {L2D},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/zcaicaros/L2D}},
  note = {Accessed 2024-03-17},
}

@misc{github_end_to_end_drl_for_fjsp,
  author = {Lei Kun},
  title = {End-to-end-DRL-for-FJSP},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Lei-Kun/End-to-end-DRL-for-FJSP}},
  note = {Accessed 2024-03-17},
}

@article{leman1968reduction,
  title={A reduction of a graph to a canonical form and an algebra arising during this reduction},
  author={Leman, AA and Weisfeiler, Boris},
  journal={Nauchno-Technicheskaya Informatsiya},
  volume={2},
  number={9},
  pages={12--16},
  year={1968}
}

@misc{github_fjsp_drl,
  author = {Wen Song},
  title = {fjsp-drl},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/songwenas12/fjsp-drl}},
  note = {Accessed 2024-03-22},
}

@misc{github_wheatley,
  author = {jolibrain},
  title = {wheatley},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jolibrain/wheatley/}},
  note = {Accessed 2024-01-09},
}

@article{DBLP:journals/corr/abs-2104-03760,
  author       = {Pierre Tassel and
                  Martin Gebser and
                  Konstantin Schekotihin},
  title        = {A Reinforcement Learning Environment For Job-Shop Scheduling},
  journal      = {CoRR},
  volume       = {abs/2104.03760},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.03760},
  eprinttype    = {arXiv},
  eprint       = {2104.03760},
  timestamp    = {Tue, 13 Apr 2021 16:46:17 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2104-03760.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2004-05718,
  author       = {Gabriele Corso and
                  Luca Cavalleri and
                  Dominique Beaini and
                  Pietro Li{\`{o}} and
                  Petar Velickovic},
  title        = {Principal Neighbourhood Aggregation for Graph Nets},
  journal      = {CoRR},
  volume       = {abs/2004.05718},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.05718},
  eprinttype    = {arXiv},
  eprint       = {2004.05718},
  timestamp    = {Tue, 14 Apr 2020 16:40:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-05718.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2010-02863,
  author       = {Dominique Beaini and
                  Saro Passaro and
                  Vincent L{\'{e}}tourneau and
                  William L. Hamilton and
                  Gabriele Corso and
                  Pietro Li{\`{o}}},
  title        = {Directional Graph Networks},
  journal      = {CoRR},
  volume       = {abs/2010.02863},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.02863},
  eprinttype    = {arXiv},
  eprint       = {2010.02863},
  timestamp    = {Thu, 14 Oct 2021 09:17:19 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-02863.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2007-02133,
  author       = {Ming Chen and
                  Zhewei Wei and
                  Zengfeng Huang and
                  Bolin Ding and
                  Yaliang Li},
  title        = {Simple and Deep Graph Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/2007.02133},
  year         = {2020},
  url          = {https://arxiv.org/abs/2007.02133},
  eprinttype    = {arXiv},
  eprint       = {2007.02133},
  timestamp    = {Fri, 17 Jul 2020 15:39:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2007-02133.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wheatley,
  author = {Guillaume Infantes and St/'ephanie Roussel and Pierre
Pereira and Antoine Jacquet and Emmanuel Benazera},
  booktitle = {CPAIOR 2024: Integration of Constraint Programming,
Artificial Intelligence and Operations Research (20th International
Conference)},
  editor = {Bistra Dilkina},
  publisher = {Springer Nature},
  title = {Learning to Solve Job Shop Scheduling under Uncertainty},
  year = {2024}
}

@misc{github_wheatley_djsp,
  author = {jolibrain},
  title = {wheatley - Different arrival times feature request},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jolibrain/wheatley/issues/89}},
  note = {Accessed 2024-01-09},
}

@misc{jssp_benchmarks,
  title = {Job Shop Instances and Solutions},
  howpublished = {\url{http://jobshop.jjvh.nl/index.php}},
  note = {Accessed: 2024-03-28}
}

@article{taillard_specification,
  title = {Benchmarks for basic scheduling problems},
  journal = {European Journal of Operational Research},
  volume = {64},
  number = {2},
  pages = {278-285},
  year = {1993},
  note = {Project Management anf Scheduling},
  issn = {0377-2217},
  doi = {https://doi.org/10.1016/0377-2217(93)90182-M},
  url = {https://www.sciencedirect.com/science/article/pii/037722179390182M},
  author = {E. Taillard},
  keywords = {Combinatorial optimization, Scheduling, Benchmarks},
  abstract = {In this paper, we propose 260 randomly generated scheduling problems whose size is greater than that of the rare examples published. Such sizes correspond to real dimensions of industrial problems. The types of problems that we propose are: the permutation flow shop, the job shop and the open shop scheduling problems. We restrict ourselves to basic problems: the processing times are fixed, there are neither set-up times nor due dates nor release dates, etc. Then, the objective is the minimization of the makespan.}
}