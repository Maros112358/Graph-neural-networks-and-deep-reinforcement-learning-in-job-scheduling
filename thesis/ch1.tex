\chapter{Job scheduling}
\label{chap:refs}

Job scheduling allocates jobs to machines. There are many different variants of job scheduling, each with different constraints and assumptions. This thesis deals with three particular variants: JSSP, FJSP, and DJSP. This chapter defines each variant and discusses relevant graph representations and Markov Decision Process (MDP) formulations.

\section{Job-Shop Scheduling Problem}

The simplest variant of job scheduling called JSSP consists of a set of jobs $\mathcal{J}$ and a set of machines $\mathcal{M}$ \cite{YamadaNakanoJSSP}. Each job has an associated ordered sequence of non-overlapping operations $O_{ij}$ to be processed. Operation $\mathcal{O}_{ij}$ represents uninterrupted processing of job $J_i \in \mathcal{J}$ on machine $M_j \in \mathcal{M}$ with processing time $p_{ij}$. Each machine can process only one operation at a time. A schedule is a set of start times $S_{ij}$ for each operation $O_{ij}$ that satisfies these constraints. Completion times $C_{ij} = S_{ij} + p_{ij}$ denote the end of each operation. The JSSP solution is a schedule minimizing total makespan $C_\text{max} = \text{max}_{i,j} \{C_{ij}\}$ \cite{zhang2020learning}. An example of a JSSP instance with three jobs and three machines (3x3) is shown in table 1.1 \cite{YamadaNakanoJSSP}.
\begin{table}[htbp]
    Table 1.1: 3x3 example JSSP instance \cite{YamadaNakanoJSSP}\\
    \vspace{1mm}
    \begin{tabular}{cccc}
    \hline
    job & \multicolumn{3}{c}{Machine (processing time)} \\ \hline
    1   & 1 (3)             & 2 (3)             & 3 (3)            \\
    2   & 1 (2)             & 3 (3)             & 2 (4)            \\
    3   & 2 (3)             & 1 (2)             & 3 (1)            \\ \hline
    \end{tabular}
\end{table}\\
The Gantt-Chart is a convenient tool for visualizing schedules \cite{WILSON2003430}. An example of a solution for the 3x3 problem from Table 1.1 is shown in Figure 1.1.
\begin{center}
    \includegraphics[width=0.8\linewidth]{images/gantt-charrt.pdf}\\
    Figure 1.1: Gantt-Chart of a solution for a 3x3 problem in table 1.1, reproduced from \cite{YamadaNakanoJSSP}
\end{center}

\subsection{JSSP as a disjunctive graph} \label{JSSP as a disjunctive graph}

JSSP can be represented by a disjunctive graph \cite{YamadaNakanoJSSP, BLAZEWICZ2000317} $G = ( O, A \cup E )$, where $O$ denotes a set of vertices corresponding to different operations $O_{ij}$ together with \textit{source} node and \textit{sink} node representing start and end of the schedule, respectively. The source node can be interpreted as a dummy operation preceding all other operations, and the sink node as a dummy operation succeeding all other operations. Both dummy operations have a processing time equal to zero. Nodes $O$ are weighted by the processing time of their corresponding operation. $A$ is a set of conjunctive arcs representing precedence constraints between operations, and between the jobs and dummy operations. $E = \bigcup_{k} E_k$ is a set of disjunctive edges, where $E_k$ is a clique connecting operations that require the same machine $M_k$ for their execution.
\begin{center}
    \includegraphics[width=0.75\linewidth]{images/jssp_disjunctive_graph.pdf}\\
    Figure 1.2: Disjunctive graph representation of 3x3 instance in table 1.1, retrieved from \cite{YamadaNakanoJSSP}
\end{center}

Finding a solution to the job-shop scheduling problem can be viewed as defining the ordering between operations requiring the same machine. In the disjunctive graph, this is done by turning all disjunctive edges into conjunctive arcs \cite{YamadaNakanoJSSP, BLAZEWICZ2000317} in such a way that the resulting graph is a direct acyclic graph (DAG) \cite{doi:10.1287/opre.17.6.941}. The makespan $C_\text{max}$ is then given by the longest weighted path from source to sink.

\subsection{JSSP as a heterogenous graph} \label{JSSP as a heterogenous graph}

In \cite{10226873}, authors represent JSSP as a heterogenous graph $H = (O, M, E)$, where $O$ is a set of operation nodes, $M$ is a set of machines nodes, and $E$ is a set of edges.
\par
Features of operation nodes include the status of the operation, the processing time, the remaining time of the operation, and the number of remaining operations in the current job. Features of machine nodes include the status of the corresponding machine and the remaining time of the operation being processed.
\par
Each edge can be either operation-to-operation ($O-O$) edge, machine-to-machine ($M-M$) edge, or operation-to-machine ($O-M$) edge. $O-O$ edges fully connect all operations in the same job, and all machines are fully connected via $M-M$ edges. $O-M$ edge connects operations with machines on which they can be processed.

\section{Flexible Job-shop Scheduling Problem}

FJSP is an extended version of JSSP with the only difference being that each operation $O_{ij} \in \mathcal{O}$ can be processed on any machine $M_k$ from the given subset of machines $\mathcal{M}_{ij} \subseteq \mathcal{M}$ with processing time $p_{ijk}$ \cite{9826438}. Solving FJSP then consists of selecting the appropriate machine for each operation (machine selection) and determining its start time (operation sequencing) \cite{https://doi.org/10.1049/iet-cim.2018.0009}. 

\subsection{FJSP as a disjunctive graph}

Similarly, as in \ref{JSSP as a disjunctive graph}, the disjunctive graph representation for the FJSP can be written as $G = (O, A, E)$ \cite{Brandimarte_1993, 9826438, LEI2022117796}, where $O$ is a set of nodes representing operations and two dummy operations representing start and end, $A$ is a set of conjunctive arcs representing precedence constraints between operations, and $E = \bigcup_{k} E_k$ is a set of disjunctive edges. The only difference with respect to JSSP is that each operation can be part of multiple cliques. An example of disjunctive graph representation for FJSP is shown in Figure 1.3.
\begin{center}
    \includegraphics[width=0.75\linewidth]{images/fjsp_disjunctive_graph.pdf}\\
    Figure 1.3: Disjunctive graph representation of FJSP, reproduced from \cite{LEI2022117796}
\end{center}

\subsection{FJSP as a heterogenous graph}

In \cite{9826438}, authors represent FJSP as a heterogenous graph defined as $H = (O, M, A, \Sigma)$. Set of operation nodes $O$ and set of conjunctive arcs $A$ is the same as in the disjunctive graph. A set of machine nodes $M$ is added representing machines, and a set of disjunctive edges $E$ is replaced by a set of $O-M$ edges $\Sigma$ connecting operation nodes and machine nodes. An example of a heterogeneous graph for FJSP is shown in Figure 1.4 \cite{9826438}.
\begin{center}
    \includegraphics[width=0.75\linewidth]{images/fjsp_heterogenous_graph.pdf}\\
    Figure 1.4: Heterogeneous graph of FJSP, reproduced from \cite{LEI2022117796}
\end{center}

\section{Dynamic job-shop scheduling problem}

Dynamic job-shop scheduling problem (DJSP) is a dynamic version of JSSP where $n$ jobs are known at the beginning of the schedule, i.e., the start time of the first operation is $S_{ij} \geq 0$, and $n'$ jobs arrive after the start of the schedule, i.e., the corresponding start time is $S_{ij} \geq t_a$, where $t_a > 0$ is time of arrival \cite{KUNDAKCI201631, Haupt_1989a}.

\section{Priority Dispatching Rules}
Priority dispatching rules (PDRs) are a greedy heuristic method for solving JSSP in $\left|\mathcal{O}\right|$ steps \cite{zhang2020learning}. Each step identifies a set of eligible operations by selecting unscheduled operations whose precedent operation has already been scheduled. Then, for each eligible operation, PDR computes a priority index and selects the one with the highest priority to be dispatched \cite{zhang2020learning}. The start time must also be determined for the selected operation, but it is sensible to start it as soon as possible \cite{discovering_dispatching_rules}. In FJSP, PDR also selects the machine by computing the priority index for each eligible machine after selecting an operation.
\par
Traditional PDRs compute the priority index based on the set of features for each operation \cite{Haupt_1989a}. In the literature, many PDRs have been studied over time \cite{7232991, discovering_dispatching_rules, doi:10.1080/00207543.2011.611539, Haupt_1989a}. In this thesis, only a few of them will be mentioned, notably \cite{Haupt_1989a, 10226873}:
\begin{itemize}
    \item \textit{First in first out} (FIFO) - select earliest available operation 
    \item \textit{Most operation remaining} (MOR) - select operation of a job with most remaining operations
    \item \textit{Shortest process-time} (SPT) - select operation with shortest processing time $p_{ij}$
    \item \textit{Most work remaining} (MWKR) - select operation of a job with the largest sum of processing times $p_{ij}$ of remaining operations
\end{itemize}
As mentioned in \ref{JSSP as a disjunctive graph}, solving job scheduling can be viewed as turning each disjunctive edge into the conjunctive arc. Decisions made by PDRs can then be viewed as actions changing the disjunctive graph. This process can then be formulated as a Markov Decision Process (MDP) \cite{zhang2020learning, jssp_rl_env}, allowing PDRs to be learned automatically via (deep) reinforcement learning techniques.

\subsection{MDP for JSSP}

MDP is a stochastic decision-making process defined as a tuple $(\mathcal{S}, \mathcal{A}, \mathcal{R}, \mathcal{P}, \gamma)$, where $\mathcal{S}$ is a finite set of possible states, $\mathcal{A}$ is the set of possible actions, $\mathcal{R}$ is the reward function,  $\mathcal{P}$ is the transition probability, and $\gamma$ is the discount factor \cite{10226873, jssp_rl_env}. 
\par
\textit{State} $S_t \in \mathcal{S}$ at timestep $t$ is a graph, either a disjunctive graph presented in \ref{JSSP as a disjunctive graph} \cite{zhang2020learning} or heterogeneous graph in \ref{JSSP as a heterogenous graph} \cite{10226873}. For the disjunctive graph, the initial state is the JSSP representation described in \ref{JSSP as a disjunctive graph}, and the final state is the disjunctive graph with all disjunctive edges $E$ turned into conjunctive arcs $A$ \cite{zhang2020learning}. For a heterogeneous graph, partial schedule $S_{ij}(t)$ is maintained, where $S_{ij}(t)$ is real dispatch time $S_{ij}$ if operation $O_{ij}$ has been already dispatched \cite{9826438}. Otherwise, $S_{ij}$ is a recursive estimate calculated by precedence constraints.
\par
\textit{Action} $a_t \in \mathcal{A}$ is an eligible operation at time step $t$. Since there is at most one eligible operation from each job, action space is $\left|\mathcal{J}\right|$ \cite{zhang2020learning}.
\par
A state transition from state $S_t$ to $S_{t+1}$ after executing $a_t$ in the disjunctive graph is done by updating the direction of the corresponding disjunctive edge \cite{zhang2020learning}. Schedule $S_{ij}(t)$ is updated in a heterogeneous graph.
\par
\textit{Reward} for each action is the difference between the lower bound of the schedule makespan $C_{LB}(s_t)$ and $C_{LB}(s_{t+1})$  Summing over all rewards gives us \textit{cumulative reward} $C_{LB}(s_0) - C_\text{max}$. Since the $C_{LB}(s_0)$ is a constant, maximizing cumulative reward minimizes total makespan $C_\text{max}$ \cite{zhang2020learning, 10226873}. 




% \subsection{Priority dispatching rules as Markov Decision Process}